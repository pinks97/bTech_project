{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qIN3tCCmq93",
        "outputId": "51955277-c84c-430f-9664-fa58a547f514",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oC3JHwbfmyka",
        "outputId": "8963c71a-7f54-445f-c1e5-3b537434bbad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd drive/My Drive/darkflowwww"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/darkflowwww\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "diyuHfj6lljR",
        "outputId": "8931ae96-9eb0-47be-8bd3-b152e103293b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shell-init: error retrieving current directory: getcwd: cannot access parent directories: Transport endpoint is not connected\n",
            "ls: cannot open directory '.': Transport endpoint is not connected\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPrPKubOoUCX",
        "outputId": "24b91684-b998-41c4-bb29-1fc5edd62a74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "pip install -e ."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Obtaining file:///content/drive/My%20Drive/darkflowwww\n",
            "Installing collected packages: darkflow\n",
            "  Running setup.py develop for darkflow\n",
            "Successfully installed darkflow\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSCYKNMFnEAB",
        "outputId": "a7da0906-8f9d-4165-b09e-3bb1f6b0f7a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd .."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHyWAX8KnHWt",
        "outputId": "118f6768-ab23-4ff7-830f-6d12ee7c260f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3131
        }
      },
      "source": [
        "!flow --model cfg/yolov2-vocmine.cfg --load bin/yolov2-voc.weights --train --annotation SelectiveBDDnew --dataset SelectiveBDD --gpu 1.0 --lr 1e-6 --epoch 5000 --load 18548"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Parsing cfg/yolov2-vocmine.cfg\n",
            "Loading None ...\n",
            "Finished in 0.00013256072998046875s\n",
            "\n",
            "Building net ...\n",
            "Source | Train? | Layer description                | Output size\n",
            "-------+--------+----------------------------------+---------------\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "       |        | input                            | (?, 416, 416, 3)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 416, 416, 32)\n",
            " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 208, 208, 32)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 208, 208, 64)\n",
            " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 104, 104, 64)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 104, 104, 128)\n",
            " Init  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 104, 104, 64)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 104, 104, 128)\n",
            " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 52, 52, 128)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 52, 52, 256)\n",
            " Init  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 52, 52, 128)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 52, 52, 256)\n",
            " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 26, 26, 256)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 26, 26, 512)\n",
            " Init  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 26, 26, 256)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 26, 26, 512)\n",
            " Init  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 26, 26, 256)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 26, 26, 512)\n",
            " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 13, 13, 512)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 13, 13, 1024)\n",
            " Init  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 13, 13, 512)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 13, 13, 1024)\n",
            " Init  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 13, 13, 512)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 13, 13, 1024)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 13, 13, 1024)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 13, 13, 1024)\n",
            " Load  |  Yep!  | concat [16]                      | (?, 26, 26, 512)\n",
            " Init  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 26, 26, 64)\n",
            " Load  |  Yep!  | local flatten 2x2                | (?, 13, 13, 256)\n",
            " Load  |  Yep!  | concat [27, 24]                  | (?, 13, 13, 1280)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 13, 13, 1024)\n",
            " Init  |  Yep!  | conv 1x1p0_1    linear           | (?, 13, 13, 75)\n",
            "-------+--------+----------------------------------+---------------\n",
            "GPU mode with 1.0 usage\n",
            "cfg/yolov2-vocmine.cfg loss hyper-parameters:\n",
            "\tH       = 13\n",
            "\tW       = 13\n",
            "\tbox     = 5\n",
            "\tclasses = 10\n",
            "\tscales  = [1.0, 5.0, 1.0, 1.0]\n",
            "WARNING:tensorflow:From /content/drive/My Drive/darkflowwww/darkflow/net/yolov2/train.py:87: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Building cfg/yolov2-vocmine.cfg loss\n",
            "Building cfg/yolov2-vocmine.cfg train op\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "2019-04-17 09:10:13.750014: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2019-04-17 09:10:13.750377: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x3261440 executing computations on platform Host. Devices:\n",
            "2019-04-17 09:10:13.750412: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2019-04-17 09:10:13.964853: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-04-17 09:10:13.965706: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x3261180 executing computations on platform CUDA. Devices:\n",
            "2019-04-17 09:10:13.965746: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2019-04-17 09:10:13.966346: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "totalMemory: 14.73GiB freeMemory: 14.60GiB\n",
            "2019-04-17 09:10:13.966379: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n",
            "2019-04-17 09:10:14.513512: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-04-17 09:10:14.513581: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n",
            "2019-04-17 09:10:14.513601: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n",
            "2019-04-17 09:10:14.514058: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2019-04-17 09:10:14.514137: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15079 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "Loading from ./ckpt/yolov2-vocmine-18548\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "Finished in 24.860453605651855s\n",
            "\n",
            "Enter training ...\n",
            "\n",
            "cfg/yolov2-vocmine.cfg parsing SelectiveBDDnew\n",
            "Parsing for ['bus', 'traffic light', 'traffic sign', 'person', 'bike', 'truck', 'motor', 'car', 'train', 'rider'] \n",
            "[====================>]100%  b4fe9ed37e469f87.xml\n",
            "Statistics:\n",
            "traffic light: 33\n",
            "traffic sign: 43\n",
            "car: 76\n",
            "bus: 6\n",
            "truck: 4\n",
            "bike: 6\n",
            "rider: 6\n",
            "person: 27\n",
            "motor: 7\n",
            "train: 1\n",
            "Dataset size: 10\n",
            "Dataset of 10 instance(s)\n",
            "Training statistics: \n",
            "\tLearning rate : 1e-06\n",
            "\tBatch size    : 10\n",
            "\tEpoch number  : 5000\n",
            "\tBackup every  : 2000\n",
            "step 18549 - loss 23.033769607543945 - moving ave loss 23.033769607543945\n",
            "Finish 1 epoch(es)\n",
            "step 18550 - loss 22.793376922607422 - moving ave loss 23.009730339050293\n",
            "Finish 2 epoch(es)\n",
            "step 18551 - loss 24.675392150878906 - moving ave loss 23.17629652023316\n",
            "Finish 3 epoch(es)\n",
            "step 18552 - loss 16.012466430664062 - moving ave loss 22.459913511276252\n",
            "Finish 4 epoch(es)\n",
            "step 18553 - loss 22.095048904418945 - moving ave loss 22.423427050590522\n",
            "Finish 5 epoch(es)\n",
            "step 18554 - loss 21.954357147216797 - moving ave loss 22.37652006025315\n",
            "Finish 6 epoch(es)\n",
            "step 18555 - loss 23.927804946899414 - moving ave loss 22.531648548917776\n",
            "Finish 7 epoch(es)\n",
            "step 18556 - loss 21.660751342773438 - moving ave loss 22.44455882830334\n",
            "Finish 8 epoch(es)\n",
            "step 18557 - loss 26.57025146484375 - moving ave loss 22.85712809195738\n",
            "Finish 9 epoch(es)\n",
            "step 18558 - loss 22.863393783569336 - moving ave loss 22.85775466111858\n",
            "Finish 10 epoch(es)\n",
            "step 18559 - loss 23.78701400756836 - moving ave loss 22.950680595763558\n",
            "Finish 11 epoch(es)\n",
            "step 18560 - loss 24.5175724029541 - moving ave loss 23.107369776482614\n",
            "Finish 12 epoch(es)\n",
            "step 18561 - loss 26.818511962890625 - moving ave loss 23.478483995123415\n",
            "Finish 13 epoch(es)\n",
            "step 18562 - loss 23.24321937561035 - moving ave loss 23.45495753317211\n",
            "Finish 14 epoch(es)\n",
            "step 18563 - loss 23.692405700683594 - moving ave loss 23.47870234992326\n",
            "Finish 15 epoch(es)\n",
            "step 18564 - loss 23.08009147644043 - moving ave loss 23.43884126257498\n",
            "Finish 16 epoch(es)\n",
            "step 18565 - loss 23.27501678466797 - moving ave loss 23.422458814784278\n",
            "Finish 17 epoch(es)\n",
            "step 18566 - loss 21.14230728149414 - moving ave loss 23.194443661455267\n",
            "Finish 18 epoch(es)\n",
            "step 18567 - loss 19.82497787475586 - moving ave loss 22.85749708278533\n",
            "Finish 19 epoch(es)\n",
            "step 18568 - loss 23.912630081176758 - moving ave loss 22.96301038262447\n",
            "Finish 20 epoch(es)\n",
            "step 18569 - loss 21.930753707885742 - moving ave loss 22.8597847151506\n",
            "Finish 21 epoch(es)\n",
            "step 18570 - loss 18.86979103088379 - moving ave loss 22.46078534672392\n",
            "Finish 22 epoch(es)\n",
            "step 18571 - loss 21.15741729736328 - moving ave loss 22.330448541787856\n",
            "Finish 23 epoch(es)\n",
            "step 18572 - loss 19.300745010375977 - moving ave loss 22.02747818864667\n",
            "Finish 24 epoch(es)\n",
            "step 18573 - loss 30.022539138793945 - moving ave loss 22.826984283661396\n",
            "Finish 25 epoch(es)\n",
            "step 18574 - loss 21.90044403076172 - moving ave loss 22.73433025837143\n",
            "Finish 26 epoch(es)\n",
            "step 18575 - loss 22.226455688476562 - moving ave loss 22.683542801381943\n",
            "Finish 27 epoch(es)\n",
            "step 18576 - loss 22.581623077392578 - moving ave loss 22.673350828983008\n",
            "Finish 28 epoch(es)\n",
            "step 18577 - loss 23.331039428710938 - moving ave loss 22.739119688955803\n",
            "Finish 29 epoch(es)\n",
            "step 18578 - loss 22.174278259277344 - moving ave loss 22.68263554598796\n",
            "Finish 30 epoch(es)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/flow\", line 7, in <module>\n",
            "    exec(compile(f.read(), __file__, 'exec'))\n",
            "  File \"/content/drive/My Drive/darkflowwww/flow\", line 6, in <module>\n",
            "    cliHandler(sys.argv)\n",
            "  File \"/content/drive/My Drive/darkflowwww/darkflow/cli.py\", line 33, in cliHandler\n",
            "    print('Enter training ...'); tfnet.train()\n",
            "  File \"/content/drive/My Drive/darkflowwww/darkflow/net/flow.py\", line 39, in train\n",
            "    for i, (x_batch, datum) in enumerate(batches):\n",
            "  File \"/content/drive/My Drive/darkflowwww/darkflow/net/yolo/data.py\", line 114, in shuffle\n",
            "    inp, new_feed = self._batch(train_instance)\n",
            "  File \"/content/drive/My Drive/darkflowwww/darkflow/net/yolov2/data.py\", line 28, in _batch\n",
            "    img = self.preprocess(path, allobj)\n",
            "  File \"/content/drive/My Drive/darkflowwww/darkflow/net/yolo/predict.py\", line 71, in preprocess\n",
            "    im = imcv2_recolor(im)\n",
            "  File \"/content/drive/My Drive/darkflowwww/darkflow/utils/im_transform.py\", line 15, in imcv2_recolor\n",
            "    im = cv2.pow(im/mx, 1. + up * .5)\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1RRHDxP7eqE",
        "outputId": "962fd452-96b4-42dd-bac9-bff8626814f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1244
        }
      },
      "source": [
        "!flow --imgdir sample_img/ --model cfg/yolov2-vocmine.cfg --load 16275 --gpu 1.0\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Parsing cfg/yolov2-vocmine.cfg\n",
            "Loading None ...\n",
            "Finished in 0.00019121170043945312s\n",
            "\n",
            "Building net ...\n",
            "Source | Train? | Layer description                | Output size\n",
            "-------+--------+----------------------------------+---------------\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "       |        | input                            | (?, 416, 416, 3)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 416, 416, 32)\n",
            " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 208, 208, 32)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 208, 208, 64)\n",
            " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 104, 104, 64)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 104, 104, 128)\n",
            " Init  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 104, 104, 64)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 104, 104, 128)\n",
            " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 52, 52, 128)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 52, 52, 256)\n",
            " Init  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 52, 52, 128)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 52, 52, 256)\n",
            " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 26, 26, 256)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 26, 26, 512)\n",
            " Init  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 26, 26, 256)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 26, 26, 512)\n",
            " Init  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 26, 26, 256)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 26, 26, 512)\n",
            " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 13, 13, 512)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 13, 13, 1024)\n",
            " Init  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 13, 13, 512)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 13, 13, 1024)\n",
            " Init  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 13, 13, 512)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 13, 13, 1024)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 13, 13, 1024)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 13, 13, 1024)\n",
            " Load  |  Yep!  | concat [16]                      | (?, 26, 26, 512)\n",
            " Init  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 26, 26, 64)\n",
            " Load  |  Yep!  | local flatten 2x2                | (?, 13, 13, 256)\n",
            " Load  |  Yep!  | concat [27, 24]                  | (?, 13, 13, 1280)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 13, 13, 1024)\n",
            " Init  |  Yep!  | conv 1x1p0_1    linear           | (?, 13, 13, 75)\n",
            "-------+--------+----------------------------------+---------------\n",
            "GPU mode with 1.0 usage\n",
            "2019-04-08 10:37:13.356166: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2019-04-08 10:37:13.356521: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x2497700 executing computations on platform Host. Devices:\n",
            "2019-04-08 10:37:13.356563: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2019-04-08 10:37:13.460167: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-04-08 10:37:13.460763: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x24972e0 executing computations on platform CUDA. Devices:\n",
            "2019-04-08 10:37:13.460804: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2019-04-08 10:37:13.461241: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "totalMemory: 11.17GiB freeMemory: 11.10GiB\n",
            "2019-04-08 10:37:13.461276: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n",
            "2019-04-08 10:37:13.793732: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-04-08 10:37:13.793806: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n",
            "2019-04-08 10:37:13.793838: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n",
            "2019-04-08 10:37:13.794175: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2019-04-08 10:37:13.794244: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11441 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "Loading from ./ckpt/yolov2-vocmine-16275\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "Finished in 7.946608066558838s\n",
            "\n",
            "Forwarding 10 inputs ...\n",
            "Total time = 2.436923027038574s / 10 inps = 4.103535437535881 ips\n",
            "Post processing 10 inputs ...\n",
            "Total time = 0.2591686248779297s / 10 inps = 38.584917463331344 ips\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kczW_ORUsR6D",
        "outputId": "592449d4-fd9f-489b-b533-367347c5b962",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1261
        }
      },
      "source": [
        "!flow --model cfg/yolov2-vocmine.cfg --load 19298 --demo Night.mp4 --gpu 1.0 --saveVideo --threshold 0.45\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Parsing cfg/yolov2-vocmine.cfg\n",
            "Loading None ...\n",
            "Finished in 0.00012040138244628906s\n",
            "\n",
            "Building net ...\n",
            "Source | Train? | Layer description                | Output size\n",
            "-------+--------+----------------------------------+---------------\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "       |        | input                            | (?, 416, 416, 3)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 416, 416, 32)\n",
            " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 208, 208, 32)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 208, 208, 64)\n",
            " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 104, 104, 64)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 104, 104, 128)\n",
            " Init  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 104, 104, 64)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 104, 104, 128)\n",
            " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 52, 52, 128)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 52, 52, 256)\n",
            " Init  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 52, 52, 128)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 52, 52, 256)\n",
            " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 26, 26, 256)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 26, 26, 512)\n",
            " Init  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 26, 26, 256)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 26, 26, 512)\n",
            " Init  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 26, 26, 256)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 26, 26, 512)\n",
            " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 13, 13, 512)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 13, 13, 1024)\n",
            " Init  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 13, 13, 512)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 13, 13, 1024)\n",
            " Init  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 13, 13, 512)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 13, 13, 1024)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 13, 13, 1024)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 13, 13, 1024)\n",
            " Load  |  Yep!  | concat [16]                      | (?, 26, 26, 512)\n",
            " Init  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 26, 26, 64)\n",
            " Load  |  Yep!  | local flatten 2x2                | (?, 13, 13, 256)\n",
            " Load  |  Yep!  | concat [27, 24]                  | (?, 13, 13, 1280)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 13, 13, 1024)\n",
            " Init  |  Yep!  | conv 1x1p0_1    linear           | (?, 13, 13, 75)\n",
            "-------+--------+----------------------------------+---------------\n",
            "GPU mode with 1.0 usage\n",
            "2019-05-17 06:53:25.989902: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2019-05-17 06:53:25.990146: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x31ad5a0 executing computations on platform Host. Devices:\n",
            "2019-05-17 06:53:25.990175: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2019-05-17 06:53:26.154170: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-05-17 06:53:26.154682: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x31ad2e0 executing computations on platform CUDA. Devices:\n",
            "2019-05-17 06:53:26.154710: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2019-05-17 06:53:26.155040: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "totalMemory: 14.73GiB freeMemory: 14.60GiB\n",
            "2019-05-17 06:53:26.155071: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n",
            "2019-05-17 06:53:26.540518: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-05-17 06:53:26.540590: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n",
            "2019-05-17 06:53:26.540602: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n",
            "2019-05-17 06:53:26.540882: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2019-05-17 06:53:26.540943: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15079 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "Loading from ./ckpt/yolov2-vocmine-19298\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "Finished in 7.340269088745117s\n",
            "\n",
            "Press [ESC] to quit demo\n",
            "38.712 FPS\n",
            "End of Video\n",
            "\n",
            "Demo stopped, exit.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKWtpbJekmH8",
        "outputId": "95e831f6-7e32-4119-a5d8-d137cf7351a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        }
      },
      "source": [
        "!flow --pbLoad built_graph/yolov2-vocmine.pb --metaLoad built_graph/yolov2-vocmine.meta --imgdir sample_img/ --gpu 1.0 --json\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Loading from .pb and .meta\n",
            "WARNING:tensorflow:From /content/drive/My Drive/darkflow-master/darkflow/net/build.py:81: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.gfile.GFile.\n",
            "GPU mode with 1.0 usage\n",
            "2019-04-08 10:28:08.370244: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2019-04-08 10:28:08.370551: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x29c6680 executing computations on platform Host. Devices:\n",
            "2019-04-08 10:28:08.370618: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2019-04-08 10:28:08.472124: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-04-08 10:28:08.472859: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x29c6260 executing computations on platform CUDA. Devices:\n",
            "2019-04-08 10:28:08.472899: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2019-04-08 10:28:08.473317: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "totalMemory: 11.17GiB freeMemory: 11.10GiB\n",
            "2019-04-08 10:28:08.473355: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n",
            "2019-04-08 10:28:08.802649: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-04-08 10:28:08.802744: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n",
            "2019-04-08 10:28:08.802770: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n",
            "2019-04-08 10:28:08.803099: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2019-04-08 10:28:08.803166: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11441 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "Forwarding 10 inputs ...\n",
            "Total time = 3.9933266639709473s / 10 inps = 2.5041778049923025 ips\n",
            "Post processing 10 inputs ...\n",
            "Total time = 0.1465778350830078s / 10 inps = 68.22313888274408 ips\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-R8Fs-ooQQ2",
        "outputId": "69a46bc9-dbb8-4803-da73-d0a5fd1733b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37483
        }
      },
      "source": [
        "!flow --model cfg/yolov2-vocmine.cfg --load 18923 --train --annotation motor_anno/ --dataset motor_images/ --gpu 1.0 "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Parsing cfg/yolov2-vocmine.cfg\n",
            "Loading None ...\n",
            "Finished in 0.00012540817260742188s\n",
            "\n",
            "Building net ...\n",
            "Source | Train? | Layer description                | Output size\n",
            "-------+--------+----------------------------------+---------------\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "       |        | input                            | (?, 416, 416, 3)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 416, 416, 32)\n",
            " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 208, 208, 32)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 208, 208, 64)\n",
            " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 104, 104, 64)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 104, 104, 128)\n",
            " Init  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 104, 104, 64)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 104, 104, 128)\n",
            " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 52, 52, 128)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 52, 52, 256)\n",
            " Init  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 52, 52, 128)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 52, 52, 256)\n",
            " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 26, 26, 256)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 26, 26, 512)\n",
            " Init  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 26, 26, 256)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 26, 26, 512)\n",
            " Init  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 26, 26, 256)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 26, 26, 512)\n",
            " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 13, 13, 512)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 13, 13, 1024)\n",
            " Init  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 13, 13, 512)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 13, 13, 1024)\n",
            " Init  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 13, 13, 512)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 13, 13, 1024)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 13, 13, 1024)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 13, 13, 1024)\n",
            " Load  |  Yep!  | concat [16]                      | (?, 26, 26, 512)\n",
            " Init  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 26, 26, 64)\n",
            " Load  |  Yep!  | local flatten 2x2                | (?, 13, 13, 256)\n",
            " Load  |  Yep!  | concat [27, 24]                  | (?, 13, 13, 1280)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 13, 13, 1024)\n",
            " Init  |  Yep!  | conv 1x1p0_1    linear           | (?, 13, 13, 75)\n",
            "-------+--------+----------------------------------+---------------\n",
            "GPU mode with 1.0 usage\n",
            "cfg/yolov2-vocmine.cfg loss hyper-parameters:\n",
            "\tH       = 13\n",
            "\tW       = 13\n",
            "\tbox     = 5\n",
            "\tclasses = 10\n",
            "\tscales  = [1.0, 5.0, 1.0, 1.0]\n",
            "WARNING:tensorflow:From /content/drive/My Drive/darkflowwww/darkflow/net/yolov2/train.py:87: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Building cfg/yolov2-vocmine.cfg loss\n",
            "Building cfg/yolov2-vocmine.cfg train op\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "2019-04-21 08:03:28.164543: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2019-04-21 08:03:28.165007: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x2c8d440 executing computations on platform Host. Devices:\n",
            "2019-04-21 08:03:28.165047: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2019-04-21 08:03:28.358925: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-04-21 08:03:28.359463: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x2c8d180 executing computations on platform CUDA. Devices:\n",
            "2019-04-21 08:03:28.359495: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2019-04-21 08:03:28.359855: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "totalMemory: 14.73GiB freeMemory: 14.60GiB\n",
            "2019-04-21 08:03:28.359879: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n",
            "2019-04-21 08:03:28.763908: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-04-21 08:03:28.764015: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n",
            "2019-04-21 08:03:28.764043: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n",
            "2019-04-21 08:03:28.764313: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2019-04-21 08:03:28.764389: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15079 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "Loading from ./ckpt/yolov2-vocmine-18923\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "Finished in 16.2601637840271s\n",
            "\n",
            "Enter training ...\n",
            "\n",
            "cfg/yolov2-vocmine.cfg parsing motor_anno/\n",
            "Parsing for ['bus', 'traffic light', 'traffic sign', 'person', 'bike', 'truck', 'motor', 'car', 'train', 'rider'] \n",
            "[====================>]100%  3af146be791fec25.xml\n",
            "Statistics:\n",
            "car: 23697\n",
            "rider: 1634\n",
            "bike: 768\n",
            "traffic light: 6904\n",
            "person: 5429\n",
            "motor: 3002\n",
            "bus: 538\n",
            "traffic sign: 8440\n",
            "truck: 894\n",
            "train: 5\n",
            "Dataset size: 2284\n",
            "Dataset of 2284 instance(s)\n",
            "Training statistics: \n",
            "\tLearning rate : 1e-05\n",
            "\tBatch size    : 16\n",
            "\tEpoch number  : 1000\n",
            "\tBackup every  : 2000\n",
            "2019-04-21 08:03:46.639626: E tensorflow/stream_executor/cuda/cuda_driver.cc:806] failed to allocate 6.72G (7219183616 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
            "step 18924 - loss 24.225772857666016 - moving ave loss 24.225772857666016\n",
            "step 18925 - loss 23.169994354248047 - moving ave loss 24.12019500732422\n",
            "step 18926 - loss 24.889244079589844 - moving ave loss 24.197099914550783\n",
            "step 18927 - loss 22.026227951049805 - moving ave loss 23.980012718200683\n",
            "step 18928 - loss 20.924678802490234 - moving ave loss 23.67447932662964\n",
            "step 18929 - loss 23.491594314575195 - moving ave loss 23.656190825424197\n",
            "step 18930 - loss 24.580249786376953 - moving ave loss 23.748596721519473\n",
            "step 18931 - loss 22.446788787841797 - moving ave loss 23.618415928151705\n",
            "step 18932 - loss 25.7883243560791 - moving ave loss 23.835406770944445\n",
            "step 18933 - loss 17.76910400390625 - moving ave loss 23.228776494240627\n",
            "step 18934 - loss 20.892797470092773 - moving ave loss 22.995178591825844\n",
            "step 18935 - loss 18.141145706176758 - moving ave loss 22.509775303260938\n",
            "step 18936 - loss 23.620473861694336 - moving ave loss 22.620845159104277\n",
            "step 18937 - loss 18.926788330078125 - moving ave loss 22.251439476201664\n",
            "step 18938 - loss 21.509796142578125 - moving ave loss 22.177275142839314\n",
            "step 18939 - loss 31.886817932128906 - moving ave loss 23.148229421768274\n",
            "step 18940 - loss 21.32085418701172 - moving ave loss 22.96549189829262\n",
            "step 18941 - loss 22.468652725219727 - moving ave loss 22.91580798098533\n",
            "step 18942 - loss 22.844058990478516 - moving ave loss 22.90863308193465\n",
            "step 18943 - loss 18.146102905273438 - moving ave loss 22.43238006426853\n",
            "step 18944 - loss 17.443174362182617 - moving ave loss 21.933459494059935\n",
            "step 18945 - loss 23.485340118408203 - moving ave loss 22.08864755649476\n",
            "step 18946 - loss 21.1370849609375 - moving ave loss 21.993491296939034\n",
            "step 18947 - loss 26.63421630859375 - moving ave loss 22.457563798104506\n",
            "step 18948 - loss 24.785419464111328 - moving ave loss 22.690349364705188\n",
            "step 18949 - loss 20.335628509521484 - moving ave loss 22.454877279186817\n",
            "step 18950 - loss 18.140132904052734 - moving ave loss 22.02340284167341\n",
            "step 18951 - loss 22.737873077392578 - moving ave loss 22.094849865245326\n",
            "step 18952 - loss 26.73175811767578 - moving ave loss 22.55854069048837\n",
            "step 18953 - loss 19.38330841064453 - moving ave loss 22.241017462503986\n",
            "step 18954 - loss 23.82266616821289 - moving ave loss 22.39918233307488\n",
            "step 18955 - loss 23.999338150024414 - moving ave loss 22.559197914769832\n",
            "step 18956 - loss 23.583919525146484 - moving ave loss 22.661670075807496\n",
            "step 18957 - loss 19.491992950439453 - moving ave loss 22.344702363270695\n",
            "step 18958 - loss 23.28030014038086 - moving ave loss 22.43826214098171\n",
            "step 18959 - loss 21.5073299407959 - moving ave loss 22.34516892096313\n",
            "step 18960 - loss 23.232730865478516 - moving ave loss 22.433925115414667\n",
            "step 18961 - loss 22.690080642700195 - moving ave loss 22.45954066814322\n",
            "step 18962 - loss 26.52461814880371 - moving ave loss 22.86604841620927\n",
            "step 18963 - loss 20.180889129638672 - moving ave loss 22.59753248755221\n",
            "step 18964 - loss 27.424633026123047 - moving ave loss 23.080242541409294\n",
            "step 18965 - loss 21.61555290222168 - moving ave loss 22.933773577490534\n",
            "step 18966 - loss 21.200109481811523 - moving ave loss 22.760407167922637\n",
            "step 18967 - loss 15.422834396362305 - moving ave loss 22.026649890766603\n",
            "step 18968 - loss 26.13254737854004 - moving ave loss 22.437239639543947\n",
            "step 18969 - loss 27.05536460876465 - moving ave loss 22.89905213646602\n",
            "step 18970 - loss 22.28256607055664 - moving ave loss 22.83740352987508\n",
            "step 18971 - loss 26.06368637084961 - moving ave loss 23.160031813972534\n",
            "step 18972 - loss 24.219606399536133 - moving ave loss 23.265989272528895\n",
            "step 18973 - loss 21.192174911499023 - moving ave loss 23.05860783642591\n",
            "step 18974 - loss 26.398591995239258 - moving ave loss 23.392606252307246\n",
            "step 18975 - loss 27.480188369750977 - moving ave loss 23.80136446405162\n",
            "step 18976 - loss 17.735204696655273 - moving ave loss 23.194748487311987\n",
            "step 18977 - loss 20.0467529296875 - moving ave loss 22.87994893154954\n",
            "step 18978 - loss 27.006608963012695 - moving ave loss 23.292614934695855\n",
            "step 18979 - loss 19.44292640686035 - moving ave loss 22.907646081912308\n",
            "step 18980 - loss 24.039152145385742 - moving ave loss 23.02079668825965\n",
            "step 18981 - loss 24.84481430053711 - moving ave loss 23.2031984494874\n",
            "step 18982 - loss 21.474817276000977 - moving ave loss 23.03036033213876\n",
            "step 18983 - loss 23.80419158935547 - moving ave loss 23.10774345786043\n",
            "step 18984 - loss 25.603492736816406 - moving ave loss 23.357318385756027\n",
            "step 18985 - loss 18.80353546142578 - moving ave loss 22.901940093323006\n",
            "step 18986 - loss 21.504085540771484 - moving ave loss 22.762154638067855\n",
            "step 18987 - loss 32.03471755981445 - moving ave loss 23.689410930242516\n",
            "step 18988 - loss 22.285533905029297 - moving ave loss 23.549023227721197\n",
            "step 18989 - loss 28.001232147216797 - moving ave loss 23.994244119670757\n",
            "step 18990 - loss 19.786510467529297 - moving ave loss 23.57347075445661\n",
            "step 18991 - loss 27.270816802978516 - moving ave loss 23.943205359308806\n",
            "step 18992 - loss 21.31454849243164 - moving ave loss 23.680339672621088\n",
            "step 18993 - loss 21.397268295288086 - moving ave loss 23.45203253488779\n",
            "step 18994 - loss 19.626245498657227 - moving ave loss 23.06945383126473\n",
            "step 18995 - loss 21.94649314880371 - moving ave loss 22.957157763018632\n",
            "step 18996 - loss 19.873703002929688 - moving ave loss 22.64881228700974\n",
            "step 18997 - loss 26.081682205200195 - moving ave loss 22.99209927882879\n",
            "step 18998 - loss 24.94537353515625 - moving ave loss 23.187426704461537\n",
            "step 18999 - loss 22.996009826660156 - moving ave loss 23.1682850166814\n",
            "step 19000 - loss 24.27303123474121 - moving ave loss 23.27875963848738\n",
            "step 19001 - loss 22.17147445678711 - moving ave loss 23.168031120317355\n",
            "step 19002 - loss 23.308366775512695 - moving ave loss 23.182064685836888\n",
            "step 19003 - loss 24.931072235107422 - moving ave loss 23.356965440763943\n",
            "step 19004 - loss 21.69898796081543 - moving ave loss 23.191167692769092\n",
            "step 19005 - loss 17.37911605834961 - moving ave loss 22.60996252932714\n",
            "step 19006 - loss 27.62214469909668 - moving ave loss 23.111180746304097\n",
            "step 19007 - loss 22.896190643310547 - moving ave loss 23.089681736004742\n",
            "step 19008 - loss 25.376148223876953 - moving ave loss 23.318328384791965\n",
            "step 19009 - loss 23.43198585510254 - moving ave loss 23.32969413182302\n",
            "step 19010 - loss 21.240947723388672 - moving ave loss 23.12081949097959\n",
            "step 19011 - loss 29.768896102905273 - moving ave loss 23.785627152172157\n",
            "step 19012 - loss 22.97228240966797 - moving ave loss 23.70429267792174\n",
            "step 19013 - loss 25.55044937133789 - moving ave loss 23.888908347263357\n",
            "step 19014 - loss 18.70131492614746 - moving ave loss 23.370149005151767\n",
            "step 19015 - loss 24.16183853149414 - moving ave loss 23.449317957786008\n",
            "step 19016 - loss 22.852012634277344 - moving ave loss 23.389587425435142\n",
            "step 19017 - loss 20.977949142456055 - moving ave loss 23.14842359713723\n",
            "step 19018 - loss 16.382749557495117 - moving ave loss 22.47185619317302\n",
            "step 19019 - loss 20.03107452392578 - moving ave loss 22.227778026248295\n",
            "step 19020 - loss 20.650634765625 - moving ave loss 22.070063700185965\n",
            "step 19021 - loss 28.3719482421875 - moving ave loss 22.70025215438612\n",
            "step 19022 - loss 20.865070343017578 - moving ave loss 22.516733973249266\n",
            "step 19023 - loss 19.817556381225586 - moving ave loss 22.2468162140469\n",
            "step 19024 - loss 23.83883285522461 - moving ave loss 22.406017878164672\n",
            "step 19025 - loss 20.897502899169922 - moving ave loss 22.255166380265198\n",
            "step 19026 - loss 22.164674758911133 - moving ave loss 22.246117218129793\n",
            "step 19027 - loss 22.435428619384766 - moving ave loss 22.26504835825529\n",
            "step 19028 - loss 21.584749221801758 - moving ave loss 22.197018444609935\n",
            "step 19029 - loss 24.80472183227539 - moving ave loss 22.457788783376483\n",
            "step 19030 - loss 25.62119483947754 - moving ave loss 22.774129388986587\n",
            "step 19031 - loss 24.828340530395508 - moving ave loss 22.97955050312748\n",
            "step 19032 - loss 25.552120208740234 - moving ave loss 23.236807473688756\n",
            "step 19033 - loss 20.201387405395508 - moving ave loss 22.93326546685943\n",
            "step 19034 - loss 20.169206619262695 - moving ave loss 22.65685958209976\n",
            "step 19035 - loss 20.80882453918457 - moving ave loss 22.47205607780824\n",
            "step 19036 - loss 20.144088745117188 - moving ave loss 22.239259344539136\n",
            "step 19037 - loss 22.96358299255371 - moving ave loss 22.311691709340593\n",
            "step 19038 - loss 27.424184799194336 - moving ave loss 22.822941018325967\n",
            "step 19039 - loss 23.89290428161621 - moving ave loss 22.92993734465499\n",
            "step 19040 - loss 21.638883590698242 - moving ave loss 22.800831969259317\n",
            "step 19041 - loss 26.097209930419922 - moving ave loss 23.130469765375377\n",
            "step 19042 - loss 28.771724700927734 - moving ave loss 23.69459525893061\n",
            "step 19043 - loss 22.282899856567383 - moving ave loss 23.55342571869429\n",
            "step 19044 - loss 17.082059860229492 - moving ave loss 22.90628913284781\n",
            "step 19045 - loss 25.64858055114746 - moving ave loss 23.180518274677777\n",
            "step 19046 - loss 22.701820373535156 - moving ave loss 23.132648484563514\n",
            "step 19047 - loss 25.232206344604492 - moving ave loss 23.342604270567612\n",
            "step 19048 - loss 22.419355392456055 - moving ave loss 23.250279382756457\n",
            "Checkpoint at step 19048\n",
            "step 19049 - loss 21.96547508239746 - moving ave loss 23.121798952720557\n",
            "step 19050 - loss 19.104768753051758 - moving ave loss 22.720095932753676\n",
            "step 19051 - loss 22.289752960205078 - moving ave loss 22.677061635498816\n",
            "step 19052 - loss 26.293439865112305 - moving ave loss 23.038699458460165\n",
            "step 19053 - loss 19.783498764038086 - moving ave loss 22.713179389017956\n",
            "step 19054 - loss 24.082963943481445 - moving ave loss 22.850157844464306\n",
            "step 19055 - loss 17.270606994628906 - moving ave loss 22.292202759480766\n",
            "step 19056 - loss 26.530061721801758 - moving ave loss 22.715988655712867\n",
            "step 19057 - loss 21.630168914794922 - moving ave loss 22.607406681621075\n",
            "step 19058 - loss 22.734708786010742 - moving ave loss 22.620136892060042\n",
            "step 19059 - loss 28.58635139465332 - moving ave loss 23.21675834231937\n",
            "step 19060 - loss 25.504785537719727 - moving ave loss 23.445561061859408\n",
            "step 19061 - loss 23.81230926513672 - moving ave loss 23.48223588218714\n",
            "step 19062 - loss 21.956087112426758 - moving ave loss 23.329621005211106\n",
            "step 19063 - loss 22.99053192138672 - moving ave loss 23.295712096828666\n",
            "step 19064 - loss 25.29758644104004 - moving ave loss 23.495899531249805\n",
            "step 19065 - loss 22.161161422729492 - moving ave loss 23.362425720397773\n",
            "Finish 1 epoch(es)\n",
            "step 19066 - loss 24.022335052490234 - moving ave loss 23.428416653607023\n",
            "step 19067 - loss 21.86557960510254 - moving ave loss 23.272132948756575\n",
            "step 19068 - loss 28.576608657836914 - moving ave loss 23.80258051966461\n",
            "step 19069 - loss 20.81658935546875 - moving ave loss 23.503981403245024\n",
            "step 19070 - loss 17.462444305419922 - moving ave loss 22.899827693462516\n",
            "step 19071 - loss 14.821290969848633 - moving ave loss 22.091974021101127\n",
            "step 19072 - loss 24.818241119384766 - moving ave loss 22.36460073092949\n",
            "step 19073 - loss 19.346426010131836 - moving ave loss 22.062783258849723\n",
            "step 19074 - loss 21.57819938659668 - moving ave loss 22.014324871624417\n",
            "step 19075 - loss 24.707494735717773 - moving ave loss 22.283641858033754\n",
            "step 19076 - loss 23.874671936035156 - moving ave loss 22.442744865833895\n",
            "step 19077 - loss 28.692895889282227 - moving ave loss 23.067759968178727\n",
            "step 19078 - loss 29.10207748413086 - moving ave loss 23.67119171977394\n",
            "step 19079 - loss 20.849544525146484 - moving ave loss 23.389027000311195\n",
            "step 19080 - loss 18.78577995300293 - moving ave loss 22.92870229558037\n",
            "step 19081 - loss 19.561382293701172 - moving ave loss 22.59197029539245\n",
            "step 19082 - loss 23.463899612426758 - moving ave loss 22.67916322709588\n",
            "step 19083 - loss 21.535982131958008 - moving ave loss 22.56484511758209\n",
            "step 19084 - loss 20.45015525817871 - moving ave loss 22.353376131641753\n",
            "step 19085 - loss 24.825542449951172 - moving ave loss 22.600592763472697\n",
            "step 19086 - loss 22.591876983642578 - moving ave loss 22.599721185489685\n",
            "step 19087 - loss 26.22183609008789 - moving ave loss 22.961932675949505\n",
            "step 19088 - loss 21.86370277404785 - moving ave loss 22.852109685759338\n",
            "step 19089 - loss 26.014055252075195 - moving ave loss 23.168304242390924\n",
            "step 19090 - loss 16.801172256469727 - moving ave loss 22.531591043798805\n",
            "step 19091 - loss 20.331880569458008 - moving ave loss 22.311619996364726\n",
            "step 19092 - loss 19.775989532470703 - moving ave loss 22.058056949975324\n",
            "step 19093 - loss 23.51481819152832 - moving ave loss 22.20373307413062\n",
            "step 19094 - loss 26.324670791625977 - moving ave loss 22.615826845880157\n",
            "step 19095 - loss 23.66693878173828 - moving ave loss 22.72093803946597\n",
            "step 19096 - loss 26.09029197692871 - moving ave loss 23.057873433212244\n",
            "step 19097 - loss 20.68502426147461 - moving ave loss 22.82058851603848\n",
            "step 19098 - loss 22.388439178466797 - moving ave loss 22.777373582281314\n",
            "step 19099 - loss 22.98056411743164 - moving ave loss 22.79769263579635\n",
            "step 19100 - loss 28.801132202148438 - moving ave loss 23.39803659243156\n",
            "step 19101 - loss 20.685216903686523 - moving ave loss 23.126754623557055\n",
            "step 19102 - loss 24.9002628326416 - moving ave loss 23.30410544446551\n",
            "step 19103 - loss 18.294586181640625 - moving ave loss 22.80315351818302\n",
            "step 19104 - loss 21.842451095581055 - moving ave loss 22.707083275922823\n",
            "step 19105 - loss 18.95477294921875 - moving ave loss 22.331852243252417\n",
            "step 19106 - loss 18.318355560302734 - moving ave loss 21.93050257495745\n",
            "step 19107 - loss 23.561660766601562 - moving ave loss 22.09361839412186\n",
            "step 19108 - loss 24.685285568237305 - moving ave loss 22.352785111533407\n",
            "step 19109 - loss 22.470497131347656 - moving ave loss 22.364556313514832\n",
            "step 19110 - loss 22.289033889770508 - moving ave loss 22.357004071140402\n",
            "step 19111 - loss 21.396202087402344 - moving ave loss 22.260923872766597\n",
            "step 19112 - loss 24.170072555541992 - moving ave loss 22.45183874104414\n",
            "step 19113 - loss 20.001848220825195 - moving ave loss 22.206839689022246\n",
            "step 19114 - loss 24.824193954467773 - moving ave loss 22.4685751155668\n",
            "step 19115 - loss 20.54936981201172 - moving ave loss 22.276654585211293\n",
            "step 19116 - loss 29.17597198486328 - moving ave loss 22.966586325176493\n",
            "step 19117 - loss 20.639400482177734 - moving ave loss 22.73386774087662\n",
            "step 19118 - loss 25.4580020904541 - moving ave loss 23.006281175834367\n",
            "step 19119 - loss 27.142972946166992 - moving ave loss 23.41995035286763\n",
            "step 19120 - loss 20.933582305908203 - moving ave loss 23.17131354817169\n",
            "step 19121 - loss 21.51521873474121 - moving ave loss 23.005704066828642\n",
            "step 19122 - loss 18.254209518432617 - moving ave loss 22.530554611989043\n",
            "step 19123 - loss 31.543718338012695 - moving ave loss 23.43187098459141\n",
            "step 19124 - loss 28.362394332885742 - moving ave loss 23.924923319420845\n",
            "step 19125 - loss 25.262527465820312 - moving ave loss 24.058683734060793\n",
            "step 19126 - loss 22.737016677856445 - moving ave loss 23.926517028440358\n",
            "step 19127 - loss 19.24497413635254 - moving ave loss 23.45836273923158\n",
            "step 19128 - loss 22.094640731811523 - moving ave loss 23.321990538489572\n",
            "step 19129 - loss 24.056367874145508 - moving ave loss 23.395428272055167\n",
            "step 19130 - loss 26.21307945251465 - moving ave loss 23.677193390101117\n",
            "step 19131 - loss 17.888700485229492 - moving ave loss 23.098344099613954\n",
            "step 19132 - loss 21.231792449951172 - moving ave loss 22.911688934647678\n",
            "step 19133 - loss 27.08997344970703 - moving ave loss 23.329517386153615\n",
            "step 19134 - loss 18.887500762939453 - moving ave loss 22.8853157238322\n",
            "step 19135 - loss 24.495817184448242 - moving ave loss 23.046365869893805\n",
            "step 19136 - loss 29.92765235900879 - moving ave loss 23.734494518805306\n",
            "step 19137 - loss 24.727916717529297 - moving ave loss 23.833836738677707\n",
            "step 19138 - loss 23.684722900390625 - moving ave loss 23.818925354849\n",
            "step 19139 - loss 24.496570587158203 - moving ave loss 23.886689878079924\n",
            "step 19140 - loss 23.366018295288086 - moving ave loss 23.83462271980074\n",
            "step 19141 - loss 24.59202766418457 - moving ave loss 23.910363214239126\n",
            "step 19142 - loss 23.16658592224121 - moving ave loss 23.835985485039338\n",
            "step 19143 - loss 20.208202362060547 - moving ave loss 23.47320717274146\n",
            "step 19144 - loss 25.995105743408203 - moving ave loss 23.725397029808136\n",
            "step 19145 - loss 24.863279342651367 - moving ave loss 23.83918526109246\n",
            "step 19146 - loss 24.837726593017578 - moving ave loss 23.939039394284976\n",
            "step 19147 - loss 21.568580627441406 - moving ave loss 23.70199351760062\n",
            "step 19148 - loss 21.071504592895508 - moving ave loss 23.43894462513011\n",
            "step 19149 - loss 24.017925262451172 - moving ave loss 23.496842688862216\n",
            "step 19150 - loss 23.359256744384766 - moving ave loss 23.483084094414473\n",
            "step 19151 - loss 19.364501953125 - moving ave loss 23.071225880285525\n",
            "step 19152 - loss 28.164379119873047 - moving ave loss 23.580541204244277\n",
            "step 19153 - loss 27.31071662902832 - moving ave loss 23.95355874672268\n",
            "step 19154 - loss 23.0067138671875 - moving ave loss 23.858874258769163\n",
            "step 19155 - loss 24.83620262145996 - moving ave loss 23.956607095038244\n",
            "step 19156 - loss 30.042884826660156 - moving ave loss 24.565234868200438\n",
            "step 19157 - loss 24.105562210083008 - moving ave loss 24.519267602388695\n",
            "step 19158 - loss 23.6624813079834 - moving ave loss 24.433588972948165\n",
            "step 19159 - loss 17.796354293823242 - moving ave loss 23.769865505035675\n",
            "step 19160 - loss 19.117599487304688 - moving ave loss 23.30463890326258\n",
            "step 19161 - loss 21.33758544921875 - moving ave loss 23.107933557858196\n",
            "step 19162 - loss 20.191804885864258 - moving ave loss 22.816320690658802\n",
            "step 19163 - loss 26.680877685546875 - moving ave loss 23.202776390147612\n",
            "step 19164 - loss 19.962846755981445 - moving ave loss 22.878783426730994\n",
            "step 19165 - loss 23.307777404785156 - moving ave loss 22.92168282453641\n",
            "step 19166 - loss 19.474340438842773 - moving ave loss 22.57694858596705\n",
            "step 19167 - loss 18.786327362060547 - moving ave loss 22.1978864635764\n",
            "step 19168 - loss 21.66724967956543 - moving ave loss 22.144822785175304\n",
            "step 19169 - loss 25.98581886291504 - moving ave loss 22.52892239294928\n",
            "step 19170 - loss 24.26919937133789 - moving ave loss 22.702950090788143\n",
            "step 19171 - loss 20.985734939575195 - moving ave loss 22.531228575666848\n",
            "step 19172 - loss 22.784753799438477 - moving ave loss 22.556581098044013\n",
            "step 19173 - loss 23.3005428314209 - moving ave loss 22.630977271381703\n",
            "Checkpoint at step 19173\n",
            "step 19174 - loss 22.152957916259766 - moving ave loss 22.58317533586951\n",
            "step 19175 - loss 24.55498504638672 - moving ave loss 22.78035630692123\n",
            "step 19176 - loss 26.406665802001953 - moving ave loss 23.142987256429304\n",
            "step 19177 - loss 23.691925048828125 - moving ave loss 23.197881035669184\n",
            "step 19178 - loss 22.104372024536133 - moving ave loss 23.088530134555878\n",
            "step 19179 - loss 26.16234588623047 - moving ave loss 23.39591170972334\n",
            "step 19180 - loss 26.236244201660156 - moving ave loss 23.679944958917023\n",
            "step 19181 - loss 20.659400939941406 - moving ave loss 23.377890557019462\n",
            "step 19182 - loss 25.07094955444336 - moving ave loss 23.547196456761853\n",
            "step 19183 - loss 18.71011734008789 - moving ave loss 23.063488545094458\n",
            "step 19184 - loss 28.24058723449707 - moving ave loss 23.58119841403472\n",
            "step 19185 - loss 23.32078742980957 - moving ave loss 23.555157315612206\n",
            "step 19186 - loss 20.46378517150879 - moving ave loss 23.246020101201864\n",
            "step 19187 - loss 26.418935775756836 - moving ave loss 23.563311668657363\n",
            "step 19188 - loss 21.30117416381836 - moving ave loss 23.337097918173463\n",
            "step 19189 - loss 24.556486129760742 - moving ave loss 23.45903673933219\n",
            "step 19190 - loss 24.24585723876953 - moving ave loss 23.537718789275928\n",
            "step 19191 - loss 25.876996994018555 - moving ave loss 23.771646609750192\n",
            "step 19192 - loss 23.3310489654541 - moving ave loss 23.727586845320584\n",
            "step 19193 - loss 16.098752975463867 - moving ave loss 22.964703458334913\n",
            "step 19194 - loss 20.678268432617188 - moving ave loss 22.736059955763142\n",
            "step 19195 - loss 24.012325286865234 - moving ave loss 22.863686488873352\n",
            "step 19196 - loss 19.956520080566406 - moving ave loss 22.572969848042657\n",
            "step 19197 - loss 21.46268653869629 - moving ave loss 22.46194151710802\n",
            "step 19198 - loss 23.931364059448242 - moving ave loss 22.60888377134204\n",
            "step 19199 - loss 20.918304443359375 - moving ave loss 22.439825838543772\n",
            "step 19200 - loss 27.80792236328125 - moving ave loss 22.97663549101752\n",
            "step 19201 - loss 19.49365234375 - moving ave loss 22.62833717629077\n",
            "step 19202 - loss 20.939912796020508 - moving ave loss 22.459494738263746\n",
            "step 19203 - loss 21.466501235961914 - moving ave loss 22.360195388033564\n",
            "step 19204 - loss 24.48602867126465 - moving ave loss 22.572778716356673\n",
            "step 19205 - loss 20.368764877319336 - moving ave loss 22.352377332452942\n",
            "step 19206 - loss 20.03316307067871 - moving ave loss 22.120455906275517\n",
            "step 19207 - loss 22.25301170349121 - moving ave loss 22.133711485997086\n",
            "Finish 2 epoch(es)\n",
            "step 19208 - loss 19.904001235961914 - moving ave loss 21.91074046099357\n",
            "step 19209 - loss 23.76621437072754 - moving ave loss 22.096287851966967\n",
            "step 19210 - loss 22.354324340820312 - moving ave loss 22.122091500852303\n",
            "step 19211 - loss 25.95265007019043 - moving ave loss 22.505147357786118\n",
            "step 19212 - loss 17.636119842529297 - moving ave loss 22.018244606260435\n",
            "step 19213 - loss 27.71383285522461 - moving ave loss 22.587803431156853\n",
            "step 19214 - loss 21.21759605407715 - moving ave loss 22.450782693448883\n",
            "step 19215 - loss 22.669605255126953 - moving ave loss 22.47266494961669\n",
            "step 19216 - loss 20.801855087280273 - moving ave loss 22.30558396338305\n",
            "step 19217 - loss 26.161760330200195 - moving ave loss 22.691201600064765\n",
            "step 19218 - loss 21.009876251220703 - moving ave loss 22.52306906518036\n",
            "step 19219 - loss 29.041385650634766 - moving ave loss 23.1749007237258\n",
            "step 19220 - loss 22.74535369873047 - moving ave loss 23.131946021226266\n",
            "step 19221 - loss 21.394935607910156 - moving ave loss 22.95824497989466\n",
            "step 19222 - loss 24.835824966430664 - moving ave loss 23.14600297854826\n",
            "step 19223 - loss 24.180265426635742 - moving ave loss 23.249429223357012\n",
            "step 19224 - loss 29.742881774902344 - moving ave loss 23.898774478511545\n",
            "step 19225 - loss 22.001840591430664 - moving ave loss 23.709081089803455\n",
            "step 19226 - loss 25.107982635498047 - moving ave loss 23.848971244372915\n",
            "step 19227 - loss 20.485193252563477 - moving ave loss 23.51259344519197\n",
            "step 19228 - loss 20.610139846801758 - moving ave loss 23.22234808535295\n",
            "step 19229 - loss 22.946189880371094 - moving ave loss 23.194732264854764\n",
            "step 19230 - loss 25.01059913635254 - moving ave loss 23.376318952004546\n",
            "step 19231 - loss 26.594884872436523 - moving ave loss 23.698175544047746\n",
            "step 19232 - loss 26.355125427246094 - moving ave loss 23.96387053236758\n",
            "step 19233 - loss 23.028051376342773 - moving ave loss 23.870288616765098\n",
            "step 19234 - loss 31.05775260925293 - moving ave loss 24.58903501601388\n",
            "step 19235 - loss 26.685453414916992 - moving ave loss 24.798676855904194\n",
            "step 19236 - loss 25.2947998046875 - moving ave loss 24.848289150782524\n",
            "step 19237 - loss 20.991634368896484 - moving ave loss 24.462623672593917\n",
            "step 19238 - loss 24.845155715942383 - moving ave loss 24.500876876928764\n",
            "step 19239 - loss 25.82604217529297 - moving ave loss 24.633393406765187\n",
            "step 19240 - loss 21.760087966918945 - moving ave loss 24.346062862780563\n",
            "step 19241 - loss 19.872356414794922 - moving ave loss 23.898692217982003\n",
            "step 19242 - loss 22.069568634033203 - moving ave loss 23.715779859587123\n",
            "step 19243 - loss 21.34903907775879 - moving ave loss 23.47910578140429\n",
            "step 19244 - loss 25.821022033691406 - moving ave loss 23.713297406633004\n",
            "step 19245 - loss 20.32744598388672 - moving ave loss 23.374712264358376\n",
            "step 19246 - loss 25.617515563964844 - moving ave loss 23.59899259431902\n",
            "step 19247 - loss 20.92995834350586 - moving ave loss 23.332089169237705\n",
            "step 19248 - loss 20.196788787841797 - moving ave loss 23.018559131098115\n",
            "step 19249 - loss 21.13606834411621 - moving ave loss 22.830310052399923\n",
            "step 19250 - loss 24.99740982055664 - moving ave loss 23.047020029215595\n",
            "step 19251 - loss 22.41721534729004 - moving ave loss 22.98403956102304\n",
            "step 19252 - loss 20.920286178588867 - moving ave loss 22.777664222779624\n",
            "step 19253 - loss 21.853368759155273 - moving ave loss 22.68523467641719\n",
            "step 19254 - loss 24.996829986572266 - moving ave loss 22.9163942074327\n",
            "step 19255 - loss 27.216115951538086 - moving ave loss 23.34636638184324\n",
            "step 19256 - loss 22.23604965209961 - moving ave loss 23.235334708868876\n",
            "step 19257 - loss 22.474300384521484 - moving ave loss 23.159231276434138\n",
            "step 19258 - loss 22.8031005859375 - moving ave loss 23.123618207384474\n",
            "step 19259 - loss 21.742544174194336 - moving ave loss 22.985510804065463\n",
            "step 19260 - loss 25.472972869873047 - moving ave loss 23.23425701064622\n",
            "step 19261 - loss 24.545927047729492 - moving ave loss 23.36542401435455\n",
            "step 19262 - loss 19.630168914794922 - moving ave loss 22.991898504398584\n",
            "step 19263 - loss 23.35008430480957 - moving ave loss 23.027717084439683\n",
            "step 19264 - loss 20.16716194152832 - moving ave loss 22.741661570148548\n",
            "step 19265 - loss 28.93882942199707 - moving ave loss 23.3613783553334\n",
            "step 19266 - loss 19.539287567138672 - moving ave loss 22.97916927651393\n",
            "step 19267 - loss 22.7195987701416 - moving ave loss 22.953212225876698\n",
            "step 19268 - loss 22.554704666137695 - moving ave loss 22.913361469902796\n",
            "step 19269 - loss 26.83304214477539 - moving ave loss 23.305329537390058\n",
            "step 19270 - loss 16.903656005859375 - moving ave loss 22.66516218423699\n",
            "step 19271 - loss 21.78443145751953 - moving ave loss 22.577089111565243\n",
            "step 19272 - loss 22.976551055908203 - moving ave loss 22.61703530599954\n",
            "step 19273 - loss 29.662479400634766 - moving ave loss 23.321579715463066\n",
            "step 19274 - loss 20.91098976135254 - moving ave loss 23.080520720052014\n",
            "step 19275 - loss 21.22011947631836 - moving ave loss 22.89448059567865\n",
            "step 19276 - loss 20.915441513061523 - moving ave loss 22.69657668741694\n",
            "step 19277 - loss 17.246198654174805 - moving ave loss 22.151538884092727\n",
            "step 19278 - loss 19.19287109375 - moving ave loss 21.855672105058453\n",
            "step 19279 - loss 22.900060653686523 - moving ave loss 21.96011095992126\n",
            "step 19280 - loss 20.612449645996094 - moving ave loss 21.825344828528742\n",
            "step 19281 - loss 20.833894729614258 - moving ave loss 21.726199818637294\n",
            "step 19282 - loss 20.25620460510254 - moving ave loss 21.57920029728382\n",
            "step 19283 - loss 17.788021087646484 - moving ave loss 21.200082376320086\n",
            "step 19284 - loss 26.432098388671875 - moving ave loss 21.72328397755527\n",
            "step 19285 - loss 19.373655319213867 - moving ave loss 21.48832111172113\n",
            "step 19286 - loss 20.833904266357422 - moving ave loss 21.42287942718476\n",
            "step 19287 - loss 23.469343185424805 - moving ave loss 21.627525803008766\n",
            "step 19288 - loss 19.938570022583008 - moving ave loss 21.458630224966193\n",
            "step 19289 - loss 21.327131271362305 - moving ave loss 21.445480329605804\n",
            "step 19290 - loss 20.70003890991211 - moving ave loss 21.370936187636435\n",
            "step 19291 - loss 16.254043579101562 - moving ave loss 20.859246926782948\n",
            "step 19292 - loss 20.686683654785156 - moving ave loss 20.84199059958317\n",
            "step 19293 - loss 18.16382598876953 - moving ave loss 20.574174138501807\n",
            "step 19294 - loss 25.57888412475586 - moving ave loss 21.074645137127213\n",
            "step 19295 - loss 19.99475860595703 - moving ave loss 20.966656484010194\n",
            "step 19296 - loss 27.203292846679688 - moving ave loss 21.590320120277145\n",
            "step 19297 - loss 22.381248474121094 - moving ave loss 21.66941295566154\n",
            "step 19298 - loss 22.928192138671875 - moving ave loss 21.79529087396257\n",
            "Checkpoint at step 19298\n",
            "step 19299 - loss 20.310840606689453 - moving ave loss 21.64684584723526\n",
            "step 19300 - loss 19.598194122314453 - moving ave loss 21.44198067474318\n",
            "step 19301 - loss 20.26402473449707 - moving ave loss 21.32418508071857\n",
            "step 19302 - loss 25.39573860168457 - moving ave loss 21.73134043281517\n",
            "step 19303 - loss 23.852582931518555 - moving ave loss 21.94346468268551\n",
            "step 19304 - loss 27.773826599121094 - moving ave loss 22.52650087432907\n",
            "step 19305 - loss 23.34005355834961 - moving ave loss 22.607856142731123\n",
            "step 19306 - loss 23.36363983154297 - moving ave loss 22.683434511612308\n",
            "step 19307 - loss 22.71243667602539 - moving ave loss 22.68633472805362\n",
            "step 19308 - loss 23.459548950195312 - moving ave loss 22.76365615026779\n",
            "step 19309 - loss 19.708898544311523 - moving ave loss 22.45818038967216\n",
            "step 19310 - loss 21.39293098449707 - moving ave loss 22.351655449154652\n",
            "step 19311 - loss 24.971155166625977 - moving ave loss 22.613605420901784\n",
            "step 19312 - loss 21.171947479248047 - moving ave loss 22.469439626736413\n",
            "step 19313 - loss 16.780540466308594 - moving ave loss 21.90054971069363\n",
            "step 19314 - loss 22.63104820251465 - moving ave loss 21.973599559875733\n",
            "step 19315 - loss 21.382400512695312 - moving ave loss 21.91447965515769\n",
            "step 19316 - loss 18.12286376953125 - moving ave loss 21.53531806659505\n",
            "step 19317 - loss 26.097457885742188 - moving ave loss 21.991532048509765\n",
            "step 19318 - loss 18.588451385498047 - moving ave loss 21.65122398220859\n",
            "step 19319 - loss 25.53046226501465 - moving ave loss 22.039147810489197\n",
            "step 19320 - loss 27.976825714111328 - moving ave loss 22.632915600851412\n",
            "step 19321 - loss 20.754804611206055 - moving ave loss 22.445104501886878\n",
            "step 19322 - loss 25.735795974731445 - moving ave loss 22.774173649171335\n",
            "step 19323 - loss 20.92681121826172 - moving ave loss 22.58943740608037\n",
            "step 19324 - loss 23.087072372436523 - moving ave loss 22.639200902715988\n",
            "step 19325 - loss 21.42739486694336 - moving ave loss 22.518020299138726\n",
            "step 19326 - loss 22.685012817382812 - moving ave loss 22.534719550963136\n",
            "step 19327 - loss 21.545196533203125 - moving ave loss 22.435767249187137\n",
            "step 19328 - loss 18.3320255279541 - moving ave loss 22.025393077063832\n",
            "step 19329 - loss 18.290517807006836 - moving ave loss 21.651905550058135\n",
            "step 19330 - loss 25.981658935546875 - moving ave loss 22.08488088860701\n",
            "step 19331 - loss 26.163984298706055 - moving ave loss 22.492791229616916\n",
            "step 19332 - loss 24.22220802307129 - moving ave loss 22.665732908962354\n",
            "step 19333 - loss 24.952085494995117 - moving ave loss 22.89436816756563\n",
            "step 19334 - loss 23.806623458862305 - moving ave loss 22.985593696695297\n",
            "step 19335 - loss 26.577295303344727 - moving ave loss 23.344763857360242\n",
            "step 19336 - loss 22.578556060791016 - moving ave loss 23.268143077703318\n",
            "step 19337 - loss 21.048084259033203 - moving ave loss 23.04613719583631\n",
            "step 19338 - loss 25.090312957763672 - moving ave loss 23.250554772029044\n",
            "step 19339 - loss 19.44683837890625 - moving ave loss 22.870183132716765\n",
            "step 19340 - loss 25.524303436279297 - moving ave loss 23.135595163073017\n",
            "step 19341 - loss 23.750513076782227 - moving ave loss 23.19708695444394\n",
            "step 19342 - loss 22.23210906982422 - moving ave loss 23.10058916598197\n",
            "step 19343 - loss 26.326107025146484 - moving ave loss 23.423140951898418\n",
            "step 19344 - loss 23.12841796875 - moving ave loss 23.393668653583575\n",
            "step 19345 - loss 22.50503158569336 - moving ave loss 23.304804946794555\n",
            "step 19346 - loss 26.11273765563965 - moving ave loss 23.585598217679063\n",
            "step 19347 - loss 19.710878372192383 - moving ave loss 23.198126233130395\n",
            "step 19348 - loss 17.82396697998047 - moving ave loss 22.660710307815403\n",
            "step 19349 - loss 22.45281219482422 - moving ave loss 22.639920496516286\n",
            "Finish 3 epoch(es)\n",
            "step 19350 - loss 26.416555404663086 - moving ave loss 23.01758398733097\n",
            "step 19351 - loss 24.433183670043945 - moving ave loss 23.159143955602268\n",
            "step 19352 - loss 26.17457389831543 - moving ave loss 23.460686949873583\n",
            "step 19353 - loss 30.625364303588867 - moving ave loss 24.17715468524511\n",
            "step 19354 - loss 21.225902557373047 - moving ave loss 23.882029472457905\n",
            "step 19355 - loss 18.692325592041016 - moving ave loss 23.363059084416214\n",
            "step 19356 - loss 22.81351089477539 - moving ave loss 23.308104265452133\n",
            "step 19357 - loss 22.855321884155273 - moving ave loss 23.262826027322447\n",
            "step 19358 - loss 28.028837203979492 - moving ave loss 23.739427144988152\n",
            "step 19359 - loss 22.844057083129883 - moving ave loss 23.649890138802327\n",
            "step 19360 - loss 18.639543533325195 - moving ave loss 23.148855478254614\n",
            "step 19361 - loss 28.0672550201416 - moving ave loss 23.640695432443312\n",
            "step 19362 - loss 18.461185455322266 - moving ave loss 23.12274443473121\n",
            "step 19363 - loss 18.045679092407227 - moving ave loss 22.615037900498812\n",
            "step 19364 - loss 19.609952926635742 - moving ave loss 22.31452940311251\n",
            "step 19365 - loss 21.774076461791992 - moving ave loss 22.260484108980457\n",
            "step 19366 - loss 18.65976905822754 - moving ave loss 21.900412603905167\n",
            "step 19367 - loss 17.59539031982422 - moving ave loss 21.469910375497072\n",
            "step 19368 - loss 27.617713928222656 - moving ave loss 22.08469073076963\n",
            "step 19369 - loss 31.610477447509766 - moving ave loss 23.037269402443645\n",
            "step 19370 - loss 24.255992889404297 - moving ave loss 23.15914175113971\n",
            "step 19371 - loss 23.15036964416504 - moving ave loss 23.158264540442243\n",
            "step 19372 - loss 21.547189712524414 - moving ave loss 22.997157057650462\n",
            "step 19373 - loss 23.482791900634766 - moving ave loss 23.045720541948892\n",
            "step 19374 - loss 21.026172637939453 - moving ave loss 22.84376575154795\n",
            "step 19375 - loss 24.15779685974121 - moving ave loss 22.975168862367276\n",
            "step 19376 - loss 23.477611541748047 - moving ave loss 23.025413130305353\n",
            "step 19377 - loss 21.607702255249023 - moving ave loss 22.88364204279972\n",
            "step 19378 - loss 28.020734786987305 - moving ave loss 23.39735131721848\n",
            "step 19379 - loss 19.747419357299805 - moving ave loss 23.03235812122661\n",
            "step 19380 - loss 21.95403480529785 - moving ave loss 22.924525789633734\n",
            "step 19381 - loss 24.42043113708496 - moving ave loss 23.074116324378856\n",
            "step 19382 - loss 24.476200103759766 - moving ave loss 23.21432470231695\n",
            "step 19383 - loss 25.46417999267578 - moving ave loss 23.439310231352835\n",
            "step 19384 - loss 22.03822135925293 - moving ave loss 23.299201344142844\n",
            "step 19385 - loss 24.248798370361328 - moving ave loss 23.394161046764694\n",
            "step 19386 - loss 21.71822166442871 - moving ave loss 23.226567108531096\n",
            "step 19387 - loss 19.08654022216797 - moving ave loss 22.812564419894784\n",
            "step 19388 - loss 17.619083404541016 - moving ave loss 22.29321631835941\n",
            "step 19389 - loss 19.13504409790039 - moving ave loss 21.97739909631351\n",
            "step 19390 - loss 18.04994773864746 - moving ave loss 21.584653960546902\n",
            "step 19391 - loss 24.474712371826172 - moving ave loss 21.87365980167483\n",
            "step 19392 - loss 22.587167739868164 - moving ave loss 21.945010595494164\n",
            "step 19393 - loss 24.532785415649414 - moving ave loss 22.20378807750969\n",
            "step 19394 - loss 22.52121925354004 - moving ave loss 22.235531195112724\n",
            "step 19395 - loss 22.59855079650879 - moving ave loss 22.27183315525233\n",
            "step 19396 - loss 18.471147537231445 - moving ave loss 21.891764593450244\n",
            "step 19397 - loss 18.961544036865234 - moving ave loss 21.598742537791743\n",
            "step 19398 - loss 16.217863082885742 - moving ave loss 21.060654592301145\n",
            "step 19399 - loss 21.904685974121094 - moving ave loss 21.145057730483142\n",
            "step 19400 - loss 17.19253158569336 - moving ave loss 20.749805116004165\n",
            "step 19401 - loss 22.696060180664062 - moving ave loss 20.944430622470154\n",
            "step 19402 - loss 24.669904708862305 - moving ave loss 21.316978031109368\n",
            "step 19403 - loss 21.71466064453125 - moving ave loss 21.356746292451557\n",
            "step 19404 - loss 26.588998794555664 - moving ave loss 21.87997154266197\n",
            "step 19405 - loss 20.392229080200195 - moving ave loss 21.731197296415793\n",
            "step 19406 - loss 23.895299911499023 - moving ave loss 21.94760755792412\n",
            "step 19407 - loss 21.37305450439453 - moving ave loss 21.89015225257116\n",
            "step 19408 - loss 26.00909996032715 - moving ave loss 22.30204702334676\n",
            "step 19409 - loss 28.523988723754883 - moving ave loss 22.924241193387573\n",
            "step 19410 - loss 21.74649429321289 - moving ave loss 22.806466503370103\n",
            "step 19411 - loss 28.329349517822266 - moving ave loss 23.358754804815323\n",
            "step 19412 - loss 25.883026123046875 - moving ave loss 23.611181936638477\n",
            "step 19413 - loss 29.275949478149414 - moving ave loss 24.17765869078957\n",
            "step 19414 - loss 21.045928955078125 - moving ave loss 23.86448571721843\n",
            "step 19415 - loss 23.3526611328125 - moving ave loss 23.813303258777836\n",
            "step 19416 - loss 16.461286544799805 - moving ave loss 23.078101587380033\n",
            "step 19417 - loss 19.878339767456055 - moving ave loss 22.758125405387634\n",
            "step 19418 - loss 25.30583953857422 - moving ave loss 23.012896818706295\n",
            "step 19419 - loss 19.8095703125 - moving ave loss 22.692564168085667\n",
            "step 19420 - loss 28.267366409301758 - moving ave loss 23.250044392207275\n",
            "step 19421 - loss 21.344343185424805 - moving ave loss 23.05947427152903\n",
            "step 19422 - loss 22.446882247924805 - moving ave loss 22.99821506916861\n",
            "step 19423 - loss 21.65937614440918 - moving ave loss 22.864331176692666\n",
            "Checkpoint at step 19423\n",
            "step 19424 - loss 20.809926986694336 - moving ave loss 22.658890757692834\n",
            "step 19425 - loss 23.97488784790039 - moving ave loss 22.79049046671359\n",
            "step 19426 - loss 22.306520462036133 - moving ave loss 22.742093466245844\n",
            "step 19427 - loss 26.98017120361328 - moving ave loss 23.16590123998259\n",
            "step 19428 - loss 21.397626876831055 - moving ave loss 22.989073803667438\n",
            "step 19429 - loss 24.255977630615234 - moving ave loss 23.11576418636222\n",
            "step 19430 - loss 26.53635597229004 - moving ave loss 23.457823364955004\n",
            "step 19431 - loss 28.880592346191406 - moving ave loss 24.000100263078647\n",
            "step 19432 - loss 20.22667694091797 - moving ave loss 23.62275793086258\n",
            "step 19433 - loss 28.33861541748047 - moving ave loss 24.094343679524368\n",
            "step 19434 - loss 20.36071014404297 - moving ave loss 23.720980325976228\n",
            "step 19435 - loss 21.586809158325195 - moving ave loss 23.507563209211124\n",
            "step 19436 - loss 23.19271469116211 - moving ave loss 23.476078357406223\n",
            "step 19437 - loss 21.64988136291504 - moving ave loss 23.293458657957107\n",
            "step 19438 - loss 21.033491134643555 - moving ave loss 23.067461905625752\n",
            "step 19439 - loss 23.933061599731445 - moving ave loss 23.15402187503632\n",
            "step 19440 - loss 25.289527893066406 - moving ave loss 23.367572476839328\n",
            "step 19441 - loss 23.17202377319336 - moving ave loss 23.348017606474734\n",
            "step 19442 - loss 23.574935913085938 - moving ave loss 23.370709437135854\n",
            "step 19443 - loss 23.583646774291992 - moving ave loss 23.39200317085147\n",
            "step 19444 - loss 19.623090744018555 - moving ave loss 23.015111928168178\n",
            "step 19445 - loss 23.070837020874023 - moving ave loss 23.020684437438764\n",
            "step 19446 - loss 22.720256805419922 - moving ave loss 22.99064167423688\n",
            "step 19447 - loss 23.364608764648438 - moving ave loss 23.028038383278037\n",
            "step 19448 - loss 24.19256019592285 - moving ave loss 23.14449056454252\n",
            "step 19449 - loss 23.549671173095703 - moving ave loss 23.18500862539784\n",
            "step 19450 - loss 16.521591186523438 - moving ave loss 22.5186668815104\n",
            "step 19451 - loss 21.138235092163086 - moving ave loss 22.38062370257567\n",
            "step 19452 - loss 24.079320907592773 - moving ave loss 22.55049342307738\n",
            "step 19453 - loss 27.995534896850586 - moving ave loss 23.0949975704547\n",
            "step 19454 - loss 21.481637954711914 - moving ave loss 22.933661608880424\n",
            "step 19455 - loss 21.03966522216797 - moving ave loss 22.74426197020918\n",
            "step 19456 - loss 16.5918025970459 - moving ave loss 22.129016032892853\n",
            "step 19457 - loss 23.195350646972656 - moving ave loss 22.235649494300834\n",
            "step 19458 - loss 23.431108474731445 - moving ave loss 22.355195392343894\n",
            "step 19459 - loss 22.064579010009766 - moving ave loss 22.326133754110483\n",
            "step 19460 - loss 25.074405670166016 - moving ave loss 22.600960945716036\n",
            "step 19461 - loss 22.876239776611328 - moving ave loss 22.628488828805565\n",
            "step 19462 - loss 28.602230072021484 - moving ave loss 23.22586295312716\n",
            "step 19463 - loss 23.19565200805664 - moving ave loss 23.222841858620107\n",
            "step 19464 - loss 20.443254470825195 - moving ave loss 22.94488311984062\n",
            "step 19465 - loss 21.711544036865234 - moving ave loss 22.82154921154308\n",
            "step 19466 - loss 22.339263916015625 - moving ave loss 22.773320681990334\n",
            "step 19467 - loss 20.395307540893555 - moving ave loss 22.535519367880656\n",
            "step 19468 - loss 24.23649787902832 - moving ave loss 22.705617218995425\n",
            "step 19469 - loss 19.415891647338867 - moving ave loss 22.37664466182977\n",
            "step 19470 - loss 17.15581512451172 - moving ave loss 21.854561708097965\n",
            "step 19471 - loss 22.384408950805664 - moving ave loss 21.907546432368733\n",
            "step 19472 - loss 17.626529693603516 - moving ave loss 21.479444758492214\n",
            "step 19473 - loss 26.795719146728516 - moving ave loss 22.011072197315844\n",
            "step 19474 - loss 21.369028091430664 - moving ave loss 21.946867786727328\n",
            "step 19475 - loss 18.886077880859375 - moving ave loss 21.640788796140534\n",
            "step 19476 - loss 20.74918556213379 - moving ave loss 21.55162847273986\n",
            "step 19477 - loss 19.051362991333008 - moving ave loss 21.301601924599176\n",
            "step 19478 - loss 23.457054138183594 - moving ave loss 21.517147145957615\n",
            "step 19479 - loss 21.522903442382812 - moving ave loss 21.517722775600134\n",
            "step 19480 - loss 18.497934341430664 - moving ave loss 21.215743932183187\n",
            "step 19481 - loss 17.48337745666504 - moving ave loss 20.842507284631374\n",
            "step 19482 - loss 26.497907638549805 - moving ave loss 21.40804732002322\n",
            "step 19483 - loss 30.74485969543457 - moving ave loss 22.341728557564352\n",
            "step 19484 - loss 22.021442413330078 - moving ave loss 22.309699943140927\n",
            "step 19485 - loss 28.0219669342041 - moving ave loss 22.880926642247246\n",
            "step 19486 - loss 25.958417892456055 - moving ave loss 23.18867576726813\n",
            "step 19487 - loss 24.037029266357422 - moving ave loss 23.27351111717706\n",
            "step 19488 - loss 21.228168487548828 - moving ave loss 23.068976854214238\n",
            "step 19489 - loss 21.03519058227539 - moving ave loss 22.865598227020357\n",
            "step 19490 - loss 26.011993408203125 - moving ave loss 23.180237745138633\n",
            "step 19491 - loss 15.868948936462402 - moving ave loss 22.44910886427101\n",
            "Finish 4 epoch(es)\n",
            "step 19492 - loss 25.80481719970703 - moving ave loss 22.784679697814614\n",
            "step 19493 - loss 24.004337310791016 - moving ave loss 22.906645459112255\n",
            "step 19494 - loss 19.97028923034668 - moving ave loss 22.6130098362357\n",
            "step 19495 - loss 21.300052642822266 - moving ave loss 22.481714116894356\n",
            "step 19496 - loss 19.21596336364746 - moving ave loss 22.15513904156967\n",
            "step 19497 - loss 18.589031219482422 - moving ave loss 21.798528259360943\n",
            "step 19498 - loss 23.944292068481445 - moving ave loss 22.013104640272992\n",
            "step 19499 - loss 19.803747177124023 - moving ave loss 21.792168893958095\n",
            "step 19500 - loss 23.543920516967773 - moving ave loss 21.967344056259062\n",
            "step 19501 - loss 20.01633071899414 - moving ave loss 21.772242722532567\n",
            "step 19502 - loss 15.873147010803223 - moving ave loss 21.182333151359636\n",
            "step 19503 - loss 31.258724212646484 - moving ave loss 22.18997225748832\n",
            "step 19504 - loss 24.14107322692871 - moving ave loss 22.38508235443236\n",
            "step 19505 - loss 24.43183135986328 - moving ave loss 22.589757254975453\n",
            "step 19506 - loss 24.013511657714844 - moving ave loss 22.73213269524939\n",
            "step 19507 - loss 16.77109718322754 - moving ave loss 22.136029144047207\n",
            "step 19508 - loss 27.29091453552246 - moving ave loss 22.651517683194733\n",
            "step 19509 - loss 19.919343948364258 - moving ave loss 22.378300309711687\n",
            "step 19510 - loss 21.661182403564453 - moving ave loss 22.306588519096966\n",
            "step 19511 - loss 20.768552780151367 - moving ave loss 22.15278494520241\n",
            "step 19512 - loss 19.32667350769043 - moving ave loss 21.870173801451212\n",
            "step 19513 - loss 28.123531341552734 - moving ave loss 22.495509555461364\n",
            "step 19514 - loss 22.43097496032715 - moving ave loss 22.48905609594794\n",
            "step 19515 - loss 23.482519149780273 - moving ave loss 22.588402401331177\n",
            "step 19516 - loss 21.717567443847656 - moving ave loss 22.501318905582824\n",
            "step 19517 - loss 20.783540725708008 - moving ave loss 22.32954108759534\n",
            "step 19518 - loss 21.592256546020508 - moving ave loss 22.25581263343786\n",
            "step 19519 - loss 21.307165145874023 - moving ave loss 22.160947884681477\n",
            "step 19520 - loss 19.53733253479004 - moving ave loss 21.898586349692334\n",
            "step 19521 - loss 23.4208984375 - moving ave loss 22.0508175584731\n",
            "step 19522 - loss 17.675525665283203 - moving ave loss 21.61328836915411\n",
            "step 19523 - loss 25.065433502197266 - moving ave loss 21.958502882458426\n",
            "step 19524 - loss 23.551250457763672 - moving ave loss 22.11777763998895\n",
            "step 19525 - loss 19.856361389160156 - moving ave loss 21.89163601490607\n",
            "step 19526 - loss 19.195037841796875 - moving ave loss 21.621976197595153\n",
            "step 19527 - loss 17.96739387512207 - moving ave loss 21.256517965347847\n",
            "step 19528 - loss 24.81126594543457 - moving ave loss 21.611992763356522\n",
            "step 19529 - loss 19.682083129882812 - moving ave loss 21.419001800009152\n",
            "step 19530 - loss 23.941059112548828 - moving ave loss 21.67120753126312\n",
            "step 19531 - loss 25.57515525817871 - moving ave loss 22.06160230395468\n",
            "step 19532 - loss 24.394304275512695 - moving ave loss 22.29487250111048\n",
            "step 19533 - loss 17.605894088745117 - moving ave loss 21.825974659873943\n",
            "step 19534 - loss 24.89745330810547 - moving ave loss 22.133122524697097\n",
            "step 19535 - loss 29.604564666748047 - moving ave loss 22.880266738902193\n",
            "step 19536 - loss 25.595550537109375 - moving ave loss 23.151795118722912\n",
            "step 19537 - loss 22.22551918029785 - moving ave loss 23.059167524880408\n",
            "step 19538 - loss 25.21406364440918 - moving ave loss 23.274657136833284\n",
            "step 19539 - loss 21.322301864624023 - moving ave loss 23.079421609612357\n",
            "step 19540 - loss 22.137187957763672 - moving ave loss 22.985198244427487\n",
            "step 19541 - loss 23.52239990234375 - moving ave loss 23.03891841021911\n",
            "step 19542 - loss 23.389955520629883 - moving ave loss 23.07402212126019\n",
            "step 19543 - loss 26.902751922607422 - moving ave loss 23.456895101394913\n",
            "step 19544 - loss 20.215110778808594 - moving ave loss 23.132716669136283\n",
            "step 19545 - loss 32.873985290527344 - moving ave loss 24.106843531275388\n",
            "step 19546 - loss 23.96368980407715 - moving ave loss 24.092528158555563\n",
            "step 19547 - loss 24.435522079467773 - moving ave loss 24.126827550646784\n",
            "step 19548 - loss 19.193330764770508 - moving ave loss 23.633477872059157\n",
            "Checkpoint at step 19548\n",
            "step 19549 - loss 26.834627151489258 - moving ave loss 23.95359280000217\n",
            "step 19550 - loss 22.578882217407227 - moving ave loss 23.816121741742673\n",
            "step 19551 - loss 20.50439453125 - moving ave loss 23.484949020693406\n",
            "step 19552 - loss 22.947845458984375 - moving ave loss 23.431238664522503\n",
            "step 19553 - loss 16.22148895263672 - moving ave loss 22.710263693333925\n",
            "step 19554 - loss 23.453283309936523 - moving ave loss 22.784565654994186\n",
            "step 19555 - loss 20.286357879638672 - moving ave loss 22.534744877458635\n",
            "step 19556 - loss 17.51657485961914 - moving ave loss 22.032927875674687\n",
            "step 19557 - loss 30.2386474609375 - moving ave loss 22.85349983420097\n",
            "step 19558 - loss 23.095876693725586 - moving ave loss 22.87773752015343\n",
            "step 19559 - loss 26.587587356567383 - moving ave loss 23.248722503794827\n",
            "step 19560 - loss 19.845706939697266 - moving ave loss 22.90842094738507\n",
            "step 19561 - loss 20.91790771484375 - moving ave loss 22.70936962413094\n",
            "step 19562 - loss 18.304847717285156 - moving ave loss 22.26891743344636\n",
            "step 19563 - loss 21.94355010986328 - moving ave loss 22.236380701088056\n",
            "step 19564 - loss 20.461454391479492 - moving ave loss 22.0588880701272\n",
            "step 19565 - loss 25.928407669067383 - moving ave loss 22.44584003002122\n",
            "step 19566 - loss 23.46288299560547 - moving ave loss 22.547544326579647\n",
            "step 19567 - loss 22.47109031677246 - moving ave loss 22.53989892559893\n",
            "step 19568 - loss 22.757556915283203 - moving ave loss 22.561664724567358\n",
            "step 19569 - loss 25.28791618347168 - moving ave loss 22.83428987045779\n",
            "step 19570 - loss 24.082426071166992 - moving ave loss 22.95910349052871\n",
            "step 19571 - loss 22.73493766784668 - moving ave loss 22.93668690826051\n",
            "step 19572 - loss 21.733779907226562 - moving ave loss 22.816396208157116\n",
            "step 19573 - loss 20.39124870300293 - moving ave loss 22.573881457641697\n",
            "step 19574 - loss 22.472265243530273 - moving ave loss 22.563719836230558\n",
            "step 19575 - loss 22.665237426757812 - moving ave loss 22.573871595283283\n",
            "step 19576 - loss 25.389556884765625 - moving ave loss 22.855440124231517\n",
            "step 19577 - loss 24.26594352722168 - moving ave loss 22.996490464530535\n",
            "step 19578 - loss 19.2371768951416 - moving ave loss 22.620559107591642\n",
            "step 19579 - loss 18.64888572692871 - moving ave loss 22.22339176952535\n",
            "step 19580 - loss 21.09496307373047 - moving ave loss 22.11054889994586\n",
            "step 19581 - loss 21.055002212524414 - moving ave loss 22.004994231203717\n",
            "step 19582 - loss 24.488252639770508 - moving ave loss 22.253320072060397\n",
            "step 19583 - loss 28.028932571411133 - moving ave loss 22.830881321995474\n",
            "step 19584 - loss 23.148822784423828 - moving ave loss 22.862675468238308\n",
            "step 19585 - loss 18.653793334960938 - moving ave loss 22.441787254910572\n",
            "step 19586 - loss 17.399396896362305 - moving ave loss 21.937548219055746\n",
            "step 19587 - loss 19.963624954223633 - moving ave loss 21.740155892572535\n",
            "step 19588 - loss 20.50867462158203 - moving ave loss 21.617007765473485\n",
            "step 19589 - loss 23.275358200073242 - moving ave loss 21.78284280893346\n",
            "step 19590 - loss 31.25545310974121 - moving ave loss 22.730103839014237\n",
            "step 19591 - loss 23.24281883239746 - moving ave loss 22.78137533835256\n",
            "step 19592 - loss 20.724172592163086 - moving ave loss 22.575655063733613\n",
            "step 19593 - loss 21.48850440979004 - moving ave loss 22.466939998339257\n",
            "step 19594 - loss 24.41227912902832 - moving ave loss 22.661473911408162\n",
            "step 19595 - loss 22.832157135009766 - moving ave loss 22.678542233768322\n",
            "step 19596 - loss 23.6373291015625 - moving ave loss 22.77442092054774\n",
            "step 19597 - loss 24.139232635498047 - moving ave loss 22.91090209204277\n",
            "step 19598 - loss 23.41215705871582 - moving ave loss 22.961027588710078\n",
            "step 19599 - loss 19.402198791503906 - moving ave loss 22.60514470898946\n",
            "step 19600 - loss 24.98412322998047 - moving ave loss 22.84304256108856\n",
            "step 19601 - loss 23.208194732666016 - moving ave loss 22.87955777824631\n",
            "step 19602 - loss 27.802133560180664 - moving ave loss 23.371815356439743\n",
            "step 19603 - loss 20.61768913269043 - moving ave loss 23.09640273406481\n",
            "step 19604 - loss 20.04078483581543 - moving ave loss 22.790840944239875\n",
            "step 19605 - loss 25.81965446472168 - moving ave loss 23.093722296288057\n",
            "step 19606 - loss 22.51810073852539 - moving ave loss 23.03616014051179\n",
            "step 19607 - loss 21.77720832824707 - moving ave loss 22.910264959285318\n",
            "step 19608 - loss 26.59725570678711 - moving ave loss 23.278964034035496\n",
            "step 19609 - loss 18.13574981689453 - moving ave loss 22.7646426123214\n",
            "step 19610 - loss 21.47775650024414 - moving ave loss 22.635954001113674\n",
            "step 19611 - loss 22.270198822021484 - moving ave loss 22.599378483204458\n",
            "step 19612 - loss 24.612695693969727 - moving ave loss 22.800710204280985\n",
            "step 19613 - loss 17.98014259338379 - moving ave loss 22.318653443191266\n",
            "step 19614 - loss 27.985517501831055 - moving ave loss 22.885339849055246\n",
            "step 19615 - loss 26.215869903564453 - moving ave loss 23.218392854506167\n",
            "step 19616 - loss 24.989116668701172 - moving ave loss 23.39546523592567\n",
            "step 19617 - loss 18.765884399414062 - moving ave loss 22.93250715227451\n",
            "step 19618 - loss 25.734041213989258 - moving ave loss 23.212660558445986\n",
            "step 19619 - loss 15.60023307800293 - moving ave loss 22.45141781040168\n",
            "step 19620 - loss 24.00668716430664 - moving ave loss 22.606944745792177\n",
            "step 19621 - loss 21.536212921142578 - moving ave loss 22.49987156332722\n",
            "step 19622 - loss 30.171457290649414 - moving ave loss 23.26703013605944\n",
            "step 19623 - loss 22.6947078704834 - moving ave loss 23.209797909501837\n",
            "step 19624 - loss 24.308279037475586 - moving ave loss 23.319646022299214\n",
            "step 19625 - loss 21.60170555114746 - moving ave loss 23.14785197518404\n",
            "step 19626 - loss 18.991323471069336 - moving ave loss 22.73219912477257\n",
            "step 19627 - loss 21.129932403564453 - moving ave loss 22.57197245265176\n",
            "step 19628 - loss 16.943296432495117 - moving ave loss 22.009104850636096\n",
            "step 19629 - loss 19.76692008972168 - moving ave loss 21.784886374544655\n",
            "step 19630 - loss 17.94862937927246 - moving ave loss 21.401260675017436\n",
            "step 19631 - loss 23.497270584106445 - moving ave loss 21.610861665926336\n",
            "step 19632 - loss 23.10027503967285 - moving ave loss 21.759803003300988\n",
            "step 19633 - loss 16.39077377319336 - moving ave loss 21.222900080290223\n",
            "Finish 5 epoch(es)\n",
            "step 19634 - loss 22.12823486328125 - moving ave loss 21.313433558589328\n",
            "step 19635 - loss 26.410900115966797 - moving ave loss 21.823180214327078\n",
            "step 19636 - loss 19.843338012695312 - moving ave loss 21.625195994163903\n",
            "step 19637 - loss 24.372318267822266 - moving ave loss 21.899908221529742\n",
            "step 19638 - loss 20.454486846923828 - moving ave loss 21.75536608406915\n",
            "step 19639 - loss 19.084543228149414 - moving ave loss 21.488283798477173\n",
            "step 19640 - loss 24.344066619873047 - moving ave loss 21.77386208061676\n",
            "step 19641 - loss 19.431154251098633 - moving ave loss 21.539591297664945\n",
            "step 19642 - loss 22.555219650268555 - moving ave loss 21.641154132925305\n",
            "step 19643 - loss 25.01778793334961 - moving ave loss 21.978817512967733\n",
            "step 19644 - loss 18.236949920654297 - moving ave loss 21.60463075373639\n",
            "step 19645 - loss 25.983163833618164 - moving ave loss 22.04248406172457\n",
            "step 19646 - loss 22.216535568237305 - moving ave loss 22.059889212375843\n",
            "step 19647 - loss 23.266889572143555 - moving ave loss 22.180589248352614\n",
            "step 19648 - loss 23.575937271118164 - moving ave loss 22.32012405062917\n",
            "step 19649 - loss 28.136341094970703 - moving ave loss 22.90174575506332\n",
            "step 19650 - loss 22.11421012878418 - moving ave loss 22.822992192435407\n",
            "step 19651 - loss 18.836530685424805 - moving ave loss 22.424346041734346\n",
            "step 19652 - loss 22.360363006591797 - moving ave loss 22.417947738220093\n",
            "step 19653 - loss 26.755611419677734 - moving ave loss 22.851714106365858\n",
            "step 19654 - loss 25.698776245117188 - moving ave loss 23.13642032024099\n",
            "step 19655 - loss 18.300628662109375 - moving ave loss 22.65284115442783\n",
            "step 19656 - loss 19.413297653198242 - moving ave loss 22.328886804304872\n",
            "step 19657 - loss 24.981456756591797 - moving ave loss 22.594143799533565\n",
            "step 19658 - loss 17.967937469482422 - moving ave loss 22.131523166528453\n",
            "step 19659 - loss 20.18056869506836 - moving ave loss 21.936427719382444\n",
            "step 19660 - loss 21.485124588012695 - moving ave loss 21.89129740624547\n",
            "step 19661 - loss 20.293298721313477 - moving ave loss 21.731497537752272\n",
            "step 19662 - loss 21.303972244262695 - moving ave loss 21.688745008403313\n",
            "step 19663 - loss 26.009063720703125 - moving ave loss 22.120776879633294\n",
            "step 19664 - loss 18.197864532470703 - moving ave loss 21.728485644917033\n",
            "step 19665 - loss 24.77231216430664 - moving ave loss 22.032868296855995\n",
            "step 19666 - loss 21.511762619018555 - moving ave loss 21.980757729072252\n",
            "step 19667 - loss 19.241716384887695 - moving ave loss 21.706853594653797\n",
            "step 19668 - loss 22.349437713623047 - moving ave loss 21.77111200655072\n",
            "step 19669 - loss 22.672639846801758 - moving ave loss 21.861264790575824\n",
            "step 19670 - loss 23.786340713500977 - moving ave loss 22.053772382868342\n",
            "step 19671 - loss 25.58941078186035 - moving ave loss 22.407336222767544\n",
            "step 19672 - loss 22.227169036865234 - moving ave loss 22.389319504177315\n",
            "step 19673 - loss 20.521940231323242 - moving ave loss 22.20258157689191\n",
            "Checkpoint at step 19673\n",
            "step 19674 - loss 24.672983169555664 - moving ave loss 22.449621736158285\n",
            "step 19675 - loss 23.565288543701172 - moving ave loss 22.561188416912575\n",
            "step 19676 - loss 26.071311950683594 - moving ave loss 22.912200770289676\n",
            "step 19677 - loss 23.51555633544922 - moving ave loss 22.97253632680563\n",
            "step 19678 - loss 18.440610885620117 - moving ave loss 22.51934378268708\n",
            "step 19679 - loss 22.754812240600586 - moving ave loss 22.542890628478432\n",
            "step 19680 - loss 21.972957611083984 - moving ave loss 22.48589732673899\n",
            "step 19681 - loss 24.005701065063477 - moving ave loss 22.637877700571437\n",
            "step 19682 - loss 22.426525115966797 - moving ave loss 22.616742442110976\n",
            "step 19683 - loss 19.820308685302734 - moving ave loss 22.337099066430152\n",
            "step 19684 - loss 18.208866119384766 - moving ave loss 21.924275771725615\n",
            "step 19685 - loss 21.70332908630371 - moving ave loss 21.902181103183423\n",
            "step 19686 - loss 21.41917610168457 - moving ave loss 21.853880603033538\n",
            "step 19687 - loss 22.772308349609375 - moving ave loss 21.945723377691124\n",
            "step 19688 - loss 18.043676376342773 - moving ave loss 21.55551867755629\n",
            "step 19689 - loss 25.50736427307129 - moving ave loss 21.95070323710779\n",
            "step 19690 - loss 21.1414737701416 - moving ave loss 21.86978029041117\n",
            "step 19691 - loss 25.214752197265625 - moving ave loss 22.204277481096618\n",
            "step 19692 - loss 19.724836349487305 - moving ave loss 21.956333367935688\n",
            "step 19693 - loss 21.698732376098633 - moving ave loss 21.93057326875198\n",
            "step 19694 - loss 27.785070419311523 - moving ave loss 22.516022983807936\n",
            "step 19695 - loss 18.479936599731445 - moving ave loss 22.11241434540029\n",
            "step 19696 - loss 19.962263107299805 - moving ave loss 21.89739922159024\n",
            "step 19697 - loss 19.71088218688965 - moving ave loss 21.678747518120183\n",
            "step 19698 - loss 23.92487907409668 - moving ave loss 21.90336067371783\n",
            "step 19699 - loss 28.494415283203125 - moving ave loss 22.562466134666362\n",
            "step 19700 - loss 22.40239715576172 - moving ave loss 22.5464592367759\n",
            "step 19701 - loss 23.51451873779297 - moving ave loss 22.643265186877606\n",
            "step 19702 - loss 26.844100952148438 - moving ave loss 23.06334876340469\n",
            "step 19703 - loss 18.428855895996094 - moving ave loss 22.599899476663833\n",
            "step 19704 - loss 21.84430694580078 - moving ave loss 22.52434022357753\n",
            "step 19705 - loss 20.573490142822266 - moving ave loss 22.329255215502002\n",
            "step 19706 - loss 24.71207046508789 - moving ave loss 22.56753674046059\n",
            "step 19707 - loss 21.952381134033203 - moving ave loss 22.50602117981785\n",
            "step 19708 - loss 18.651639938354492 - moving ave loss 22.120583055671514\n",
            "step 19709 - loss 21.50579833984375 - moving ave loss 22.059104584088736\n",
            "step 19710 - loss 22.03954315185547 - moving ave loss 22.05714844086541\n",
            "step 19711 - loss 21.768531799316406 - moving ave loss 22.028286776710512\n",
            "step 19712 - loss 26.12936782836914 - moving ave loss 22.438394881876377\n",
            "step 19713 - loss 22.88059425354004 - moving ave loss 22.482614819042745\n",
            "step 19714 - loss 17.146718978881836 - moving ave loss 21.949025235026657\n",
            "step 19715 - loss 20.082035064697266 - moving ave loss 21.762326217993717\n",
            "step 19716 - loss 25.044071197509766 - moving ave loss 22.09050071594532\n",
            "step 19717 - loss 18.457347869873047 - moving ave loss 21.727185431338093\n",
            "step 19718 - loss 24.299983978271484 - moving ave loss 21.984465286031433\n",
            "step 19719 - loss 20.77972412109375 - moving ave loss 21.863991169537666\n",
            "step 19720 - loss 20.585819244384766 - moving ave loss 21.73617397702238\n",
            "step 19721 - loss 21.25217628479004 - moving ave loss 21.687774207799144\n",
            "step 19722 - loss 19.45625877380371 - moving ave loss 21.464622664399602\n",
            "step 19723 - loss 21.19618797302246 - moving ave loss 21.437779195261886\n",
            "step 19724 - loss 27.993730545043945 - moving ave loss 22.093374330240096\n",
            "step 19725 - loss 21.867305755615234 - moving ave loss 22.07076747277761\n",
            "step 19726 - loss 24.943241119384766 - moving ave loss 22.358014837438326\n",
            "step 19727 - loss 18.476123809814453 - moving ave loss 21.96982573467594\n",
            "step 19728 - loss 27.601835250854492 - moving ave loss 22.533026686293795\n",
            "step 19729 - loss 19.944721221923828 - moving ave loss 22.2741961398568\n",
            "step 19730 - loss 21.85726547241211 - moving ave loss 22.23250307311233\n",
            "step 19731 - loss 27.995166778564453 - moving ave loss 22.808769443657543\n",
            "step 19732 - loss 22.431467056274414 - moving ave loss 22.77103920491923\n",
            "step 19733 - loss 19.808910369873047 - moving ave loss 22.474826321414614\n",
            "step 19734 - loss 26.77303695678711 - moving ave loss 22.904647384951865\n",
            "step 19735 - loss 19.038114547729492 - moving ave loss 22.51799410122963\n",
            "step 19736 - loss 23.506092071533203 - moving ave loss 22.616803898259985\n",
            "step 19737 - loss 23.947839736938477 - moving ave loss 22.749907482127835\n",
            "step 19738 - loss 24.494384765625 - moving ave loss 22.92435521047755\n",
            "step 19739 - loss 25.656370162963867 - moving ave loss 23.197556705726186\n",
            "step 19740 - loss 21.776762008666992 - moving ave loss 23.055477236020266\n",
            "step 19741 - loss 20.69740104675293 - moving ave loss 22.819669617093535\n",
            "step 19742 - loss 27.63750648498535 - moving ave loss 23.301453303882717\n",
            "step 19743 - loss 18.921545028686523 - moving ave loss 22.8634624763631\n",
            "step 19744 - loss 22.40448570251465 - moving ave loss 22.817564798978257\n",
            "step 19745 - loss 21.81916618347168 - moving ave loss 22.717724937427597\n",
            "step 19746 - loss 21.624460220336914 - moving ave loss 22.60839846571853\n",
            "step 19747 - loss 23.216840744018555 - moving ave loss 22.669242693548533\n",
            "step 19748 - loss 22.062116622924805 - moving ave loss 22.608530086486162\n",
            "step 19749 - loss 21.41449737548828 - moving ave loss 22.489126815386374\n",
            "step 19750 - loss 18.884899139404297 - moving ave loss 22.128704047788165\n",
            "step 19751 - loss 28.672256469726562 - moving ave loss 22.783059289982006\n",
            "step 19752 - loss 22.530485153198242 - moving ave loss 22.75780187630363\n",
            "step 19753 - loss 25.393383026123047 - moving ave loss 23.02135999128557\n",
            "step 19754 - loss 17.891630172729492 - moving ave loss 22.508387009429963\n",
            "step 19755 - loss 25.85665512084961 - moving ave loss 22.84321382057193\n",
            "step 19756 - loss 21.101282119750977 - moving ave loss 22.669020650489834\n",
            "step 19757 - loss 19.013675689697266 - moving ave loss 22.303486154410578\n",
            "step 19758 - loss 26.541303634643555 - moving ave loss 22.72726790243388\n",
            "step 19759 - loss 26.41680145263672 - moving ave loss 23.096221257454168\n",
            "step 19760 - loss 24.95199966430664 - moving ave loss 23.281799098139416\n",
            "step 19761 - loss 17.61905860900879 - moving ave loss 22.715525049226354\n",
            "step 19762 - loss 26.876102447509766 - moving ave loss 23.131582789054697\n",
            "step 19763 - loss 18.05169677734375 - moving ave loss 22.623594187883604\n",
            "step 19764 - loss 28.713756561279297 - moving ave loss 23.232610425223175\n",
            "step 19765 - loss 20.342517852783203 - moving ave loss 22.94360116797918\n",
            "step 19766 - loss 31.711212158203125 - moving ave loss 23.820362267001574\n",
            "step 19767 - loss 24.756288528442383 - moving ave loss 23.913954893145654\n",
            "step 19768 - loss 26.235397338867188 - moving ave loss 24.14609913771781\n",
            "step 19769 - loss 22.76155662536621 - moving ave loss 24.007644886482648\n",
            "step 19770 - loss 20.339900970458984 - moving ave loss 23.640870494880282\n",
            "step 19771 - loss 19.07036590576172 - moving ave loss 23.183820035968427\n",
            "step 19772 - loss 18.422462463378906 - moving ave loss 22.707684278709475\n",
            "step 19773 - loss 20.310487747192383 - moving ave loss 22.467964625557766\n",
            "step 19774 - loss 19.67756462097168 - moving ave loss 22.18892462509916\n",
            "step 19775 - loss 24.86485481262207 - moving ave loss 22.45651764385145\n",
            "Finish 6 epoch(es)\n",
            "step 19776 - loss 19.838254928588867 - moving ave loss 22.19469137232519\n",
            "step 19777 - loss 22.296167373657227 - moving ave loss 22.204838972458397\n",
            "step 19778 - loss 20.826663970947266 - moving ave loss 22.067021472307285\n",
            "step 19779 - loss 29.54791259765625 - moving ave loss 22.81511058484218\n",
            "step 19780 - loss 22.835784912109375 - moving ave loss 22.817178017568903\n",
            "step 19781 - loss 21.656997680664062 - moving ave loss 22.70115998387842\n",
            "step 19782 - loss 26.174556732177734 - moving ave loss 23.04849965870835\n",
            "step 19783 - loss 20.29841423034668 - moving ave loss 22.773491115872186\n",
            "step 19784 - loss 21.938751220703125 - moving ave loss 22.690017126355283\n",
            "step 19785 - loss 22.455472946166992 - moving ave loss 22.666562708336453\n",
            "step 19786 - loss 24.685293197631836 - moving ave loss 22.868435757265992\n",
            "step 19787 - loss 20.41658592224121 - moving ave loss 22.623250773763512\n",
            "step 19788 - loss 15.278532981872559 - moving ave loss 21.88877899457442\n",
            "step 19789 - loss 23.01267433166504 - moving ave loss 22.001168528283483\n",
            "step 19790 - loss 24.18524742126465 - moving ave loss 22.2195764175816\n",
            "step 19791 - loss 26.11871337890625 - moving ave loss 22.609490113714067\n",
            "step 19792 - loss 19.326231002807617 - moving ave loss 22.281164202623422\n",
            "step 19793 - loss 21.298429489135742 - moving ave loss 22.182890731274654\n",
            "step 19794 - loss 20.21578598022461 - moving ave loss 21.98618025616965\n",
            "step 19795 - loss 22.623775482177734 - moving ave loss 22.049939778770458\n",
            "step 19796 - loss 22.677642822265625 - moving ave loss 22.112710083119975\n",
            "step 19797 - loss 17.45391082763672 - moving ave loss 21.64683015757165\n",
            "step 19798 - loss 22.531280517578125 - moving ave loss 21.7352751935723\n",
            "Checkpoint at step 19798\n",
            "step 19799 - loss 21.075326919555664 - moving ave loss 21.669280366170636\n",
            "step 19800 - loss 28.54408073425293 - moving ave loss 22.356760402978868\n",
            "step 19801 - loss 22.14591407775879 - moving ave loss 22.33567577045686\n",
            "step 19802 - loss 27.947256088256836 - moving ave loss 22.896833802236856\n",
            "step 19803 - loss 23.56302833557129 - moving ave loss 22.9634532555703\n",
            "step 19804 - loss 21.794315338134766 - moving ave loss 22.846539463826748\n",
            "step 19805 - loss 15.731535911560059 - moving ave loss 22.13503910860008\n",
            "step 19806 - loss 21.42840576171875 - moving ave loss 22.064375773911944\n",
            "step 19807 - loss 16.228593826293945 - moving ave loss 21.480797579150142\n",
            "step 19808 - loss 23.856218338012695 - moving ave loss 21.7183396550364\n",
            "step 19809 - loss 22.850690841674805 - moving ave loss 21.83157477370024\n",
            "step 19810 - loss 20.921146392822266 - moving ave loss 21.74053193561244\n",
            "step 19811 - loss 20.924375534057617 - moving ave loss 21.65891629545696\n",
            "step 19812 - loss 21.37176513671875 - moving ave loss 21.630201179583143\n",
            "step 19813 - loss 25.364349365234375 - moving ave loss 22.003615998148266\n",
            "step 19814 - loss 19.60618782043457 - moving ave loss 21.763873180376898\n",
            "step 19815 - loss 26.67745590209961 - moving ave loss 22.255231452549168\n",
            "step 19816 - loss 22.339906692504883 - moving ave loss 22.26369897654474\n",
            "step 19817 - loss 22.46800422668457 - moving ave loss 22.284129501558724\n",
            "step 19818 - loss 25.062679290771484 - moving ave loss 22.56198448048\n",
            "step 19819 - loss 24.180463790893555 - moving ave loss 22.723832411521357\n",
            "step 19820 - loss 24.806217193603516 - moving ave loss 22.932070889729573\n",
            "step 19821 - loss 21.756193161010742 - moving ave loss 22.81448311685769\n",
            "step 19822 - loss 22.756269454956055 - moving ave loss 22.80866175066753\n",
            "step 19823 - loss 16.36805534362793 - moving ave loss 22.16460110996357\n",
            "step 19824 - loss 26.266992568969727 - moving ave loss 22.57484025586419\n",
            "step 19825 - loss 25.27047348022461 - moving ave loss 22.84440357830023\n",
            "step 19826 - loss 22.3585205078125 - moving ave loss 22.79581527125146\n",
            "step 19827 - loss 22.041643142700195 - moving ave loss 22.720398058396334\n",
            "step 19828 - loss 19.614784240722656 - moving ave loss 22.409836676628967\n",
            "step 19829 - loss 22.259258270263672 - moving ave loss 22.394778835992437\n",
            "step 19830 - loss 22.304759979248047 - moving ave loss 22.385776950318\n",
            "step 19831 - loss 22.206491470336914 - moving ave loss 22.36784840231989\n",
            "step 19832 - loss 24.053882598876953 - moving ave loss 22.536451821975596\n",
            "step 19833 - loss 23.867919921875 - moving ave loss 22.66959863196554\n",
            "step 19834 - loss 18.716135025024414 - moving ave loss 22.274252271271425\n",
            "step 19835 - loss 20.369962692260742 - moving ave loss 22.083823313370356\n",
            "step 19836 - loss 20.51308250427246 - moving ave loss 21.92674923246057\n",
            "step 19837 - loss 23.424148559570312 - moving ave loss 22.076489165171544\n",
            "step 19838 - loss 19.399072647094727 - moving ave loss 21.808747513363862\n",
            "step 19839 - loss 23.82899284362793 - moving ave loss 22.01077204639027\n",
            "step 19840 - loss 20.714040756225586 - moving ave loss 21.8810989173738\n",
            "step 19841 - loss 23.100296020507812 - moving ave loss 22.003018627687204\n",
            "step 19842 - loss 24.647695541381836 - moving ave loss 22.26748631905667\n",
            "step 19843 - loss 27.66261100769043 - moving ave loss 22.806998787920044\n",
            "step 19844 - loss 17.389667510986328 - moving ave loss 22.265265660226675\n",
            "step 19845 - loss 18.571455001831055 - moving ave loss 21.895884594387113\n",
            "step 19846 - loss 20.642446517944336 - moving ave loss 21.770540786742835\n",
            "step 19847 - loss 16.382673263549805 - moving ave loss 21.231754034423535\n",
            "step 19848 - loss 23.11003303527832 - moving ave loss 21.419581934509015\n",
            "step 19849 - loss 19.998929977416992 - moving ave loss 21.277516738799815\n",
            "step 19850 - loss 19.86947250366211 - moving ave loss 21.136712315286044\n",
            "step 19851 - loss 25.587614059448242 - moving ave loss 21.581802489702266\n",
            "step 19852 - loss 14.834188461303711 - moving ave loss 20.90704108686241\n",
            "step 19853 - loss 22.116132736206055 - moving ave loss 21.027950251796778\n",
            "step 19854 - loss 22.572301864624023 - moving ave loss 21.1823854130795\n",
            "step 19855 - loss 21.01669692993164 - moving ave loss 21.165816564764715\n",
            "step 19856 - loss 16.865337371826172 - moving ave loss 20.735768645470863\n",
            "step 19857 - loss 22.678421020507812 - moving ave loss 20.93003388297456\n",
            "step 19858 - loss 24.789621353149414 - moving ave loss 21.315992629992046\n",
            "step 19859 - loss 24.930192947387695 - moving ave loss 21.677412661731612\n",
            "step 19860 - loss 23.979711532592773 - moving ave loss 21.90764254881773\n",
            "step 19861 - loss 24.828826904296875 - moving ave loss 22.199760984365643\n",
            "step 19862 - loss 21.366621017456055 - moving ave loss 22.116446987674685\n",
            "step 19863 - loss 22.98636245727539 - moving ave loss 22.203438534634756\n",
            "step 19864 - loss 19.779338836669922 - moving ave loss 21.961028564838273\n",
            "step 19865 - loss 20.737720489501953 - moving ave loss 21.838697757304644\n",
            "step 19866 - loss 19.215179443359375 - moving ave loss 21.57634592591012\n",
            "step 19867 - loss 21.975522994995117 - moving ave loss 21.61626363281862\n",
            "step 19868 - loss 25.46902084350586 - moving ave loss 22.001539353887345\n",
            "step 19869 - loss 18.790029525756836 - moving ave loss 21.680388371074294\n",
            "step 19870 - loss 23.314449310302734 - moving ave loss 21.84379446499714\n",
            "step 19871 - loss 21.339651107788086 - moving ave loss 21.793380129276237\n",
            "step 19872 - loss 23.738740921020508 - moving ave loss 21.987916208450663\n",
            "step 19873 - loss 26.168821334838867 - moving ave loss 22.406006721089486\n",
            "step 19874 - loss 18.792985916137695 - moving ave loss 22.044704640594308\n",
            "step 19875 - loss 21.213985443115234 - moving ave loss 21.961632720846403\n",
            "step 19876 - loss 27.697736740112305 - moving ave loss 22.535243122772993\n",
            "step 19877 - loss 24.052961349487305 - moving ave loss 22.687014945444425\n",
            "step 19878 - loss 18.637712478637695 - moving ave loss 22.282084698763754\n",
            "step 19879 - loss 21.244083404541016 - moving ave loss 22.178284569341482\n",
            "step 19880 - loss 18.46774673461914 - moving ave loss 21.80723078586925\n",
            "step 19881 - loss 26.01398468017578 - moving ave loss 22.227906175299903\n",
            "step 19882 - loss 22.203746795654297 - moving ave loss 22.225490237335343\n",
            "step 19883 - loss 21.537229537963867 - moving ave loss 22.156664167398194\n",
            "step 19884 - loss 13.69230842590332 - moving ave loss 21.31022859324871\n",
            "step 19885 - loss 30.16655158996582 - moving ave loss 22.19586089292042\n",
            "step 19886 - loss 22.96042251586914 - moving ave loss 22.272317055215296\n",
            "step 19887 - loss 23.183216094970703 - moving ave loss 22.363406959190836\n",
            "step 19888 - loss 20.03121566772461 - moving ave loss 22.130187830044214\n",
            "step 19889 - loss 17.51607894897461 - moving ave loss 21.668776941937253\n",
            "step 19890 - loss 27.74956512451172 - moving ave loss 22.2768557601947\n",
            "step 19891 - loss 22.839994430541992 - moving ave loss 22.33316962722943\n",
            "step 19892 - loss 28.24943733215332 - moving ave loss 22.92479639772182\n",
            "step 19893 - loss 20.357641220092773 - moving ave loss 22.668080879958914\n",
            "step 19894 - loss 20.285978317260742 - moving ave loss 22.429870623689098\n",
            "step 19895 - loss 24.201828002929688 - moving ave loss 22.60706636161316\n",
            "step 19896 - loss 23.037513732910156 - moving ave loss 22.650111098742858\n",
            "step 19897 - loss 16.904258728027344 - moving ave loss 22.075525861671306\n",
            "step 19898 - loss 27.621950149536133 - moving ave loss 22.63016829045779\n",
            "step 19899 - loss 27.38055419921875 - moving ave loss 23.105206881333885\n",
            "step 19900 - loss 20.953781127929688 - moving ave loss 22.890064305993466\n",
            "step 19901 - loss 23.03119659423828 - moving ave loss 22.904177534817947\n",
            "step 19902 - loss 22.253921508789062 - moving ave loss 22.83915193221506\n",
            "step 19903 - loss 21.341218948364258 - moving ave loss 22.68935863382998\n",
            "step 19904 - loss 20.775781631469727 - moving ave loss 22.498000933593957\n",
            "step 19905 - loss 17.803483963012695 - moving ave loss 22.028549236535834\n",
            "step 19906 - loss 24.888065338134766 - moving ave loss 22.31450084669573\n",
            "step 19907 - loss 21.09195327758789 - moving ave loss 22.19224608978495\n",
            "step 19908 - loss 17.456218719482422 - moving ave loss 21.718643352754697\n",
            "step 19909 - loss 20.102933883666992 - moving ave loss 21.557072405845926\n",
            "step 19910 - loss 24.773332595825195 - moving ave loss 21.87869842484385\n",
            "step 19911 - loss 19.78969955444336 - moving ave loss 21.6697985378038\n",
            "step 19912 - loss 23.983938217163086 - moving ave loss 21.90121250573973\n",
            "step 19913 - loss 22.897754669189453 - moving ave loss 22.0008667220847\n",
            "step 19914 - loss 26.648067474365234 - moving ave loss 22.465586797312753\n",
            "step 19915 - loss 26.848827362060547 - moving ave loss 22.903910853787533\n",
            "step 19916 - loss 26.789827346801758 - moving ave loss 23.292502503088954\n",
            "step 19917 - loss 24.30924415588379 - moving ave loss 23.394176668368438\n",
            "Finish 7 epoch(es)\n",
            "step 19918 - loss 21.368989944458008 - moving ave loss 23.191657995977394\n",
            "step 19919 - loss 22.50559425354004 - moving ave loss 23.123051621733662\n",
            "step 19920 - loss 24.409521102905273 - moving ave loss 23.251698569850824\n",
            "step 19921 - loss 19.805002212524414 - moving ave loss 22.907028934118184\n",
            "step 19922 - loss 22.464006423950195 - moving ave loss 22.862726683101386\n",
            "step 19923 - loss 26.229042053222656 - moving ave loss 23.199358220113517\n",
            "Checkpoint at step 19923\n",
            "step 19924 - loss 27.818830490112305 - moving ave loss 23.661305447113396\n",
            "step 19925 - loss 23.992778778076172 - moving ave loss 23.694452780209673\n",
            "step 19926 - loss 21.68783187866211 - moving ave loss 23.49379069005492\n",
            "step 19927 - loss 18.091800689697266 - moving ave loss 22.953591690019156\n",
            "step 19928 - loss 25.40285301208496 - moving ave loss 23.198517822225735\n",
            "step 19929 - loss 24.19451904296875 - moving ave loss 23.298117944300035\n",
            "step 19930 - loss 22.79092025756836 - moving ave loss 23.247398175626866\n",
            "step 19931 - loss 22.945682525634766 - moving ave loss 23.217226610627655\n",
            "step 19932 - loss 19.33099937438965 - moving ave loss 22.828603887003855\n",
            "step 19933 - loss 22.540292739868164 - moving ave loss 22.799772772290286\n",
            "step 19934 - loss 20.871376037597656 - moving ave loss 22.60693309882102\n",
            "step 19935 - loss 25.074827194213867 - moving ave loss 22.853722508360306\n",
            "step 19936 - loss 22.12306022644043 - moving ave loss 22.78065628016832\n",
            "step 19937 - loss 20.348936080932617 - moving ave loss 22.53748426024475\n",
            "step 19938 - loss 24.36041259765625 - moving ave loss 22.719777093985897\n",
            "step 19939 - loss 25.134737014770508 - moving ave loss 22.96127308606436\n",
            "step 19940 - loss 24.13949203491211 - moving ave loss 23.079094980949133\n",
            "step 19941 - loss 20.583772659301758 - moving ave loss 22.829562748784397\n",
            "step 19942 - loss 24.900659561157227 - moving ave loss 23.03667243002168\n",
            "step 19943 - loss 18.622692108154297 - moving ave loss 22.595274397834945\n",
            "step 19944 - loss 23.454303741455078 - moving ave loss 22.68117733219696\n",
            "step 19945 - loss 20.414424896240234 - moving ave loss 22.454502088601288\n",
            "step 19946 - loss 22.78771209716797 - moving ave loss 22.487823089457958\n",
            "step 19947 - loss 18.13681411743164 - moving ave loss 22.052722192255327\n",
            "step 19948 - loss 21.785701751708984 - moving ave loss 22.026020148200693\n",
            "step 19949 - loss 16.469133377075195 - moving ave loss 21.470331471088144\n",
            "step 19950 - loss 24.499160766601562 - moving ave loss 21.773214400639485\n",
            "step 19951 - loss 22.58123016357422 - moving ave loss 21.85401597693296\n",
            "step 19952 - loss 18.214012145996094 - moving ave loss 21.490015593839274\n",
            "step 19953 - loss 19.481266021728516 - moving ave loss 21.2891406366282\n",
            "step 19954 - loss 24.403806686401367 - moving ave loss 21.60060724160552\n",
            "step 19955 - loss 20.269041061401367 - moving ave loss 21.467450623585105\n",
            "step 19956 - loss 22.092151641845703 - moving ave loss 21.529920725411166\n",
            "step 19957 - loss 22.8065128326416 - moving ave loss 21.65757993613421\n",
            "step 19958 - loss 25.217620849609375 - moving ave loss 22.013584027481723\n",
            "step 19959 - loss 24.04144287109375 - moving ave loss 22.216369911842925\n",
            "step 19960 - loss 25.177959442138672 - moving ave loss 22.5125288648725\n",
            "step 19961 - loss 21.221569061279297 - moving ave loss 22.38343288451318\n",
            "step 19962 - loss 21.793787002563477 - moving ave loss 22.32446829631821\n",
            "step 19963 - loss 20.743125915527344 - moving ave loss 22.166334058239123\n",
            "step 19964 - loss 26.221336364746094 - moving ave loss 22.571834288889818\n",
            "step 19965 - loss 21.474342346191406 - moving ave loss 22.462085094619976\n",
            "step 19966 - loss 28.324657440185547 - moving ave loss 23.048342329176535\n",
            "step 19967 - loss 20.152257919311523 - moving ave loss 22.758733888190033\n",
            "step 19968 - loss 19.469207763671875 - moving ave loss 22.429781275738215\n",
            "step 19969 - loss 25.370281219482422 - moving ave loss 22.723831270112637\n",
            "step 19970 - loss 23.048309326171875 - moving ave loss 22.75627907571856\n",
            "step 19971 - loss 20.10091209411621 - moving ave loss 22.490742377558323\n",
            "step 19972 - loss 22.526376724243164 - moving ave loss 22.49430581222681\n",
            "step 19973 - loss 22.25252342224121 - moving ave loss 22.47012757322825\n",
            "step 19974 - loss 17.115665435791016 - moving ave loss 21.93468135948453\n",
            "step 19975 - loss 28.579833984375 - moving ave loss 22.599196621973576\n",
            "step 19976 - loss 21.257272720336914 - moving ave loss 22.46500423180991\n",
            "step 19977 - loss 26.694480895996094 - moving ave loss 22.88795189822853\n",
            "step 19978 - loss 28.314069747924805 - moving ave loss 23.43056368319816\n",
            "step 19979 - loss 28.960920333862305 - moving ave loss 23.983599348264576\n",
            "step 19980 - loss 21.429798126220703 - moving ave loss 23.72821922606019\n",
            "step 19981 - loss 17.37555694580078 - moving ave loss 23.09295299803425\n",
            "step 19982 - loss 19.039684295654297 - moving ave loss 22.687626127796257\n",
            "step 19983 - loss 27.090579986572266 - moving ave loss 23.127921513673858\n",
            "step 19984 - loss 24.34139633178711 - moving ave loss 23.24926899548518\n",
            "step 19985 - loss 19.971105575561523 - moving ave loss 22.921452653492814\n",
            "step 19986 - loss 18.418073654174805 - moving ave loss 22.471114753561015\n",
            "step 19987 - loss 21.283863067626953 - moving ave loss 22.35238958496761\n",
            "step 19988 - loss 19.750051498413086 - moving ave loss 22.092155776312158\n",
            "step 19989 - loss 18.16230010986328 - moving ave loss 21.69917020966727\n",
            "step 19990 - loss 22.776615142822266 - moving ave loss 21.80691470298277\n",
            "step 19991 - loss 21.370895385742188 - moving ave loss 21.76331277125871\n",
            "step 19992 - loss 22.605791091918945 - moving ave loss 21.847560603324734\n",
            "step 19993 - loss 22.8214054107666 - moving ave loss 21.944945084068923\n",
            "step 19994 - loss 27.302797317504883 - moving ave loss 22.48073030741252\n",
            "step 19995 - loss 21.28260040283203 - moving ave loss 22.36091731695447\n",
            "step 19996 - loss 24.912593841552734 - moving ave loss 22.6160849694143\n",
            "step 19997 - loss 27.527175903320312 - moving ave loss 23.1071940628049\n",
            "step 19998 - loss 19.766212463378906 - moving ave loss 22.773095902862302\n",
            "step 19999 - loss 21.231704711914062 - moving ave loss 22.61895678376748\n",
            "step 20000 - loss 18.85693359375 - moving ave loss 22.242754464765735\n",
            "step 20001 - loss 25.41693115234375 - moving ave loss 22.560172133523537\n",
            "step 20002 - loss 26.73771095275879 - moving ave loss 22.97792601544706\n",
            "step 20003 - loss 21.71826171875 - moving ave loss 22.851959585777355\n",
            "step 20004 - loss 19.496374130249023 - moving ave loss 22.516401040224522\n",
            "step 20005 - loss 25.23016357421875 - moving ave loss 22.787777293623947\n",
            "step 20006 - loss 23.72978401184082 - moving ave loss 22.881977965445635\n",
            "step 20007 - loss 26.917476654052734 - moving ave loss 23.285527834306347\n",
            "step 20008 - loss 19.281818389892578 - moving ave loss 22.88515688986497\n",
            "step 20009 - loss 21.94530487060547 - moving ave loss 22.79117168793902\n",
            "step 20010 - loss 20.65791893005371 - moving ave loss 22.57784641215049\n",
            "step 20011 - loss 19.035301208496094 - moving ave loss 22.22359189178505\n",
            "step 20012 - loss 22.968456268310547 - moving ave loss 22.298078329437597\n",
            "step 20013 - loss 27.06718635559082 - moving ave loss 22.77498913205292\n",
            "step 20014 - loss 21.855627059936523 - moving ave loss 22.68305292484128\n",
            "step 20015 - loss 18.869571685791016 - moving ave loss 22.301704800936253\n",
            "step 20016 - loss 24.073829650878906 - moving ave loss 22.478917285930518\n",
            "step 20017 - loss 19.05940818786621 - moving ave loss 22.13696637612409\n",
            "step 20018 - loss 23.240755081176758 - moving ave loss 22.247345246629358\n",
            "step 20019 - loss 21.94526481628418 - moving ave loss 22.21713720359484\n",
            "step 20020 - loss 20.95851707458496 - moving ave loss 22.091275190693853\n",
            "step 20021 - loss 20.163618087768555 - moving ave loss 21.898509480401326\n",
            "step 20022 - loss 17.179304122924805 - moving ave loss 21.426588944653677\n",
            "step 20023 - loss 18.941431045532227 - moving ave loss 21.178073154741533\n",
            "step 20024 - loss 19.985551834106445 - moving ave loss 21.058821022678025\n",
            "step 20025 - loss 26.450040817260742 - moving ave loss 21.597943002136297\n",
            "step 20026 - loss 22.795679092407227 - moving ave loss 21.71771661116339\n",
            "step 20027 - loss 21.896953582763672 - moving ave loss 21.73564030832342\n",
            "step 20028 - loss 29.382131576538086 - moving ave loss 22.500289435144886\n",
            "step 20029 - loss 23.06612205505371 - moving ave loss 22.55687269713577\n",
            "step 20030 - loss 22.866676330566406 - moving ave loss 22.587853060478835\n",
            "step 20031 - loss 24.64030647277832 - moving ave loss 22.793098401708782\n",
            "step 20032 - loss 19.71027946472168 - moving ave loss 22.484816508010073\n",
            "step 20033 - loss 21.815282821655273 - moving ave loss 22.417863139374592\n",
            "step 20034 - loss 16.702434539794922 - moving ave loss 21.846320279416624\n",
            "step 20035 - loss 19.634841918945312 - moving ave loss 21.625172443369493\n",
            "step 20036 - loss 20.6854248046875 - moving ave loss 21.531197679501293\n",
            "step 20037 - loss 20.46989631652832 - moving ave loss 21.425067543203994\n",
            "step 20038 - loss 21.577762603759766 - moving ave loss 21.440337049259572\n",
            "step 20039 - loss 22.12693214416504 - moving ave loss 21.50899655875012\n",
            "step 20040 - loss 21.52886962890625 - moving ave loss 21.510983865765734\n",
            "step 20041 - loss 28.350500106811523 - moving ave loss 22.19493548987031\n",
            "step 20042 - loss 21.784921646118164 - moving ave loss 22.153934105495097\n",
            "step 20043 - loss 20.636926651000977 - moving ave loss 22.002233360045686\n",
            "step 20044 - loss 23.04507064819336 - moving ave loss 22.106517088860453\n",
            "step 20045 - loss 23.800344467163086 - moving ave loss 22.27589982669072\n",
            "step 20046 - loss 20.856246948242188 - moving ave loss 22.133934538845867\n",
            "step 20047 - loss 24.368900299072266 - moving ave loss 22.35743111486851\n",
            "step 20048 - loss 19.29501724243164 - moving ave loss 22.051189727624823\n",
            "Checkpoint at step 20048\n",
            "step 20049 - loss 21.537870407104492 - moving ave loss 21.99985779557279\n",
            "step 20050 - loss 23.867862701416016 - moving ave loss 22.186658286157115\n",
            "step 20051 - loss 21.843473434448242 - moving ave loss 22.152339800986226\n",
            "step 20052 - loss 26.978544235229492 - moving ave loss 22.634960244410557\n",
            "step 20053 - loss 21.314645767211914 - moving ave loss 22.502928796690696\n",
            "step 20054 - loss 23.316356658935547 - moving ave loss 22.584271582915182\n",
            "step 20055 - loss 20.414621353149414 - moving ave loss 22.367306559938605\n",
            "step 20056 - loss 21.05489730834961 - moving ave loss 22.236065634779706\n",
            "step 20057 - loss 19.8117618560791 - moving ave loss 21.99363525690965\n",
            "step 20058 - loss 20.97991943359375 - moving ave loss 21.89226367457806\n",
            "step 20059 - loss 22.00286865234375 - moving ave loss 21.90332417235463\n",
            "Finish 8 epoch(es)\n",
            "step 20060 - loss 16.339614868164062 - moving ave loss 21.346953241935573\n",
            "step 20061 - loss 20.975955963134766 - moving ave loss 21.30985351405549\n",
            "step 20062 - loss 22.265865325927734 - moving ave loss 21.405454695242714\n",
            "step 20063 - loss 22.445478439331055 - moving ave loss 21.50945706965155\n",
            "step 20064 - loss 23.081363677978516 - moving ave loss 21.666647730484247\n",
            "step 20065 - loss 21.888521194458008 - moving ave loss 21.688835076881624\n",
            "step 20066 - loss 22.65231704711914 - moving ave loss 21.78518327390538\n",
            "step 20067 - loss 29.463836669921875 - moving ave loss 22.553048613507027\n",
            "step 20068 - loss 18.47762107849121 - moving ave loss 22.145505860005446\n",
            "step 20069 - loss 25.167543411254883 - moving ave loss 22.44770961513039\n",
            "step 20070 - loss 22.24331283569336 - moving ave loss 22.427269937186686\n",
            "step 20071 - loss 21.928369522094727 - moving ave loss 22.37737989567749\n",
            "step 20072 - loss 19.353435516357422 - moving ave loss 22.074985457745484\n",
            "step 20073 - loss 19.86928939819336 - moving ave loss 21.85441585179027\n",
            "step 20074 - loss 25.200359344482422 - moving ave loss 22.189010201059485\n",
            "step 20075 - loss 25.146947860717773 - moving ave loss 22.484803967025314\n",
            "step 20076 - loss 21.537919998168945 - moving ave loss 22.39011557013968\n",
            "step 20077 - loss 22.075284957885742 - moving ave loss 22.358632508914287\n",
            "step 20078 - loss 19.761547088623047 - moving ave loss 22.098923966885163\n",
            "step 20079 - loss 17.01211929321289 - moving ave loss 21.590243499517936\n",
            "step 20080 - loss 22.497304916381836 - moving ave loss 21.680949641204325\n",
            "step 20081 - loss 24.202838897705078 - moving ave loss 21.933138566854403\n",
            "step 20082 - loss 22.203107833862305 - moving ave loss 21.960135493555196\n",
            "step 20083 - loss 21.64175033569336 - moving ave loss 21.928296977769012\n",
            "step 20084 - loss 23.582748413085938 - moving ave loss 22.093742121300703\n",
            "step 20085 - loss 23.242992401123047 - moving ave loss 22.208667149282938\n",
            "step 20086 - loss 18.80328369140625 - moving ave loss 21.86812880349527\n",
            "step 20087 - loss 23.0411434173584 - moving ave loss 21.985430264881582\n",
            "step 20088 - loss 21.631549835205078 - moving ave loss 21.950042221913932\n",
            "step 20089 - loss 24.285232543945312 - moving ave loss 22.18356125411707\n",
            "step 20090 - loss 17.084442138671875 - moving ave loss 21.673649342572553\n",
            "step 20091 - loss 21.672374725341797 - moving ave loss 21.673521880849478\n",
            "step 20092 - loss 21.049665451049805 - moving ave loss 21.61113623786951\n",
            "step 20093 - loss 18.795194625854492 - moving ave loss 21.32954207666801\n",
            "step 20094 - loss 18.549659729003906 - moving ave loss 21.0515538419016\n",
            "step 20095 - loss 18.12433624267578 - moving ave loss 20.75883208197902\n",
            "step 20096 - loss 21.445507049560547 - moving ave loss 20.82749957873717\n",
            "step 20097 - loss 20.018964767456055 - moving ave loss 20.746646097609062\n",
            "step 20098 - loss 23.337854385375977 - moving ave loss 21.005766926385753\n",
            "step 20099 - loss 24.259275436401367 - moving ave loss 21.331117777387313\n",
            "step 20100 - loss 28.141923904418945 - moving ave loss 22.01219839009048\n",
            "step 20101 - loss 19.79640769958496 - moving ave loss 21.790619321039927\n",
            "step 20102 - loss 20.12791633605957 - moving ave loss 21.624349022541892\n",
            "step 20103 - loss 22.14507484436035 - moving ave loss 21.67642160472374\n",
            "step 20104 - loss 28.95565414428711 - moving ave loss 22.404344858680076\n",
            "step 20105 - loss 24.490873336791992 - moving ave loss 22.612997706491267\n",
            "step 20106 - loss 21.560508728027344 - moving ave loss 22.507748808644873\n",
            "step 20107 - loss 19.486265182495117 - moving ave loss 22.205600446029898\n",
            "step 20108 - loss 19.30868148803711 - moving ave loss 21.91590855023062\n",
            "step 20109 - loss 25.097766876220703 - moving ave loss 22.23409438282963\n",
            "step 20110 - loss 25.65381622314453 - moving ave loss 22.57606656686112\n",
            "step 20111 - loss 23.02496337890625 - moving ave loss 22.62095624806563\n",
            "step 20112 - loss 21.542884826660156 - moving ave loss 22.513149105925084\n",
            "step 20113 - loss 30.849966049194336 - moving ave loss 23.346830800252008\n",
            "step 20114 - loss 20.449705123901367 - moving ave loss 23.057118232616943\n",
            "step 20115 - loss 25.08393669128418 - moving ave loss 23.25980007848367\n",
            "step 20116 - loss 19.878664016723633 - moving ave loss 22.92168647230767\n",
            "step 20117 - loss 23.2175235748291 - moving ave loss 22.951270182559814\n",
            "step 20118 - loss 19.78074073791504 - moving ave loss 22.634217238095335\n",
            "step 20119 - loss 19.086902618408203 - moving ave loss 22.279485776126624\n",
            "step 20120 - loss 18.500961303710938 - moving ave loss 21.901633328885055\n",
            "step 20121 - loss 26.133838653564453 - moving ave loss 22.324853861352995\n",
            "step 20122 - loss 19.178224563598633 - moving ave loss 22.01019093157756\n",
            "step 20123 - loss 17.606266021728516 - moving ave loss 21.56979844059266\n",
            "step 20124 - loss 17.941638946533203 - moving ave loss 21.206982491186714\n",
            "step 20125 - loss 20.519012451171875 - moving ave loss 21.13818548718523\n",
            "step 20126 - loss 18.447546005249023 - moving ave loss 20.869121538991607\n",
            "step 20127 - loss 29.264610290527344 - moving ave loss 21.708670414145182\n",
            "step 20128 - loss 19.997390747070312 - moving ave loss 21.537542447437694\n",
            "step 20129 - loss 21.939517974853516 - moving ave loss 21.577740000179276\n",
            "step 20130 - loss 19.325870513916016 - moving ave loss 21.35255305155295\n",
            "step 20131 - loss 19.893985748291016 - moving ave loss 21.206696321226758\n",
            "step 20132 - loss 21.119457244873047 - moving ave loss 21.19797241359139\n",
            "step 20133 - loss 17.521385192871094 - moving ave loss 20.83031369151936\n",
            "step 20134 - loss 20.56691551208496 - moving ave loss 20.80397387357592\n",
            "step 20135 - loss 23.958396911621094 - moving ave loss 21.119416177380437\n",
            "step 20136 - loss 20.358623504638672 - moving ave loss 21.04333691010626\n",
            "step 20137 - loss 25.042598724365234 - moving ave loss 21.443263091532156\n",
            "step 20138 - loss 20.66275405883789 - moving ave loss 21.36521218826273\n",
            "step 20139 - loss 24.656494140625 - moving ave loss 21.69434038349896\n",
            "step 20140 - loss 19.668609619140625 - moving ave loss 21.491767307063128\n",
            "step 20141 - loss 22.027389526367188 - moving ave loss 21.545329528993534\n",
            "step 20142 - loss 24.770631790161133 - moving ave loss 21.867859755110295\n",
            "step 20143 - loss 22.950603485107422 - moving ave loss 21.976134128110008\n",
            "step 20144 - loss 25.737207412719727 - moving ave loss 22.35224145657098\n",
            "step 20145 - loss 26.301029205322266 - moving ave loss 22.74712023144611\n",
            "step 20146 - loss 27.68218231201172 - moving ave loss 23.240626439502673\n",
            "step 20147 - loss 17.448713302612305 - moving ave loss 22.661435125813636\n",
            "step 20148 - loss 23.978252410888672 - moving ave loss 22.79311685432114\n",
            "step 20149 - loss 26.806833267211914 - moving ave loss 23.19448849561022\n",
            "step 20150 - loss 19.870763778686523 - moving ave loss 22.862116023917853\n",
            "step 20151 - loss 21.55521583557129 - moving ave loss 22.731426005083197\n",
            "step 20152 - loss 19.28662872314453 - moving ave loss 22.386946276889333\n",
            "step 20153 - loss 16.823238372802734 - moving ave loss 21.830575486480672\n",
            "step 20154 - loss 24.121187210083008 - moving ave loss 22.05963665884091\n",
            "step 20155 - loss 26.952404022216797 - moving ave loss 22.548913395178495\n",
            "step 20156 - loss 18.934377670288086 - moving ave loss 22.187459822689455\n",
            "step 20157 - loss 27.841394424438477 - moving ave loss 22.752853282864358\n",
            "step 20158 - loss 19.179141998291016 - moving ave loss 22.395482154407024\n",
            "step 20159 - loss 23.949909210205078 - moving ave loss 22.55092485998683\n",
            "step 20160 - loss 24.504701614379883 - moving ave loss 22.746302535426135\n",
            "step 20161 - loss 20.23046875 - moving ave loss 22.49471915688352\n",
            "step 20162 - loss 22.667739868164062 - moving ave loss 22.512021228011577\n",
            "step 20163 - loss 30.899625778198242 - moving ave loss 23.350781683030245\n",
            "step 20164 - loss 21.342313766479492 - moving ave loss 23.14993489137517\n",
            "step 20165 - loss 18.823827743530273 - moving ave loss 22.71732417659068\n",
            "step 20166 - loss 26.48076057434082 - moving ave loss 23.093667816365695\n",
            "step 20167 - loss 27.142671585083008 - moving ave loss 23.498568193237425\n",
            "step 20168 - loss 22.780122756958008 - moving ave loss 23.426723649609485\n",
            "step 20169 - loss 22.062091827392578 - moving ave loss 23.290260467387796\n",
            "step 20170 - loss 22.23778533935547 - moving ave loss 23.185012954584565\n",
            "step 20171 - loss 25.14224624633789 - moving ave loss 23.380736283759898\n",
            "step 20172 - loss 19.062118530273438 - moving ave loss 22.94887450841125\n",
            "step 20173 - loss 21.266897201538086 - moving ave loss 22.780676777723937\n",
            "Checkpoint at step 20173\n",
            "step 20174 - loss 23.777063369750977 - moving ave loss 22.88031543692664\n",
            "step 20175 - loss 17.879011154174805 - moving ave loss 22.380185008651456\n",
            "step 20176 - loss 20.512428283691406 - moving ave loss 22.19340933615545\n",
            "step 20177 - loss 19.22395133972168 - moving ave loss 21.896463536512073\n",
            "step 20178 - loss 22.142742156982422 - moving ave loss 21.92109139855911\n",
            "step 20179 - loss 20.77764892578125 - moving ave loss 21.80674715128132\n",
            "step 20180 - loss 21.634794235229492 - moving ave loss 21.78955185967614\n",
            "step 20181 - loss 22.756893157958984 - moving ave loss 21.886285989504426\n",
            "step 20182 - loss 20.957490921020508 - moving ave loss 21.793406482656035\n",
            "step 20183 - loss 19.654727935791016 - moving ave loss 21.579538627969534\n",
            "step 20184 - loss 23.964021682739258 - moving ave loss 21.81798693344651\n",
            "step 20185 - loss 20.513164520263672 - moving ave loss 21.687504692128226\n",
            "step 20186 - loss 27.484914779663086 - moving ave loss 22.267245700881713\n",
            "step 20187 - loss 23.383420944213867 - moving ave loss 22.37886322521493\n",
            "step 20188 - loss 18.35915184020996 - moving ave loss 21.976892086714432\n",
            "step 20189 - loss 17.84749984741211 - moving ave loss 21.563952862784202\n",
            "step 20190 - loss 19.397533416748047 - moving ave loss 21.347310918180586\n",
            "step 20191 - loss 23.504173278808594 - moving ave loss 21.562997154243387\n",
            "step 20192 - loss 18.100419998168945 - moving ave loss 21.216739438635944\n",
            "step 20193 - loss 26.02764892578125 - moving ave loss 21.697830387350475\n",
            "step 20194 - loss 22.304840087890625 - moving ave loss 21.75853135740449\n",
            "step 20195 - loss 23.37485694885254 - moving ave loss 21.920163916549292\n",
            "step 20196 - loss 20.21009635925293 - moving ave loss 21.749157160819657\n",
            "step 20197 - loss 24.132701873779297 - moving ave loss 21.98751163211562\n",
            "step 20198 - loss 20.979015350341797 - moving ave loss 21.886662003938238\n",
            "step 20199 - loss 20.272737503051758 - moving ave loss 21.725269553849593\n",
            "step 20200 - loss 20.435319900512695 - moving ave loss 21.596274588515904\n",
            "step 20201 - loss 17.981098175048828 - moving ave loss 21.2347569471692\n",
            "Finish 9 epoch(es)\n",
            "step 20202 - loss 21.5361328125 - moving ave loss 21.26489453370228\n",
            "step 20203 - loss 21.274112701416016 - moving ave loss 21.265816350473653\n",
            "step 20204 - loss 23.739885330200195 - moving ave loss 21.513223248446305\n",
            "step 20205 - loss 27.525699615478516 - moving ave loss 22.114470885149526\n",
            "step 20206 - loss 18.3375186920166 - moving ave loss 21.736775665836234\n",
            "step 20207 - loss 21.107681274414062 - moving ave loss 21.673866226694017\n",
            "step 20208 - loss 22.85401725769043 - moving ave loss 21.791881329793657\n",
            "step 20209 - loss 18.403209686279297 - moving ave loss 21.45301416544222\n",
            "step 20210 - loss 19.285438537597656 - moving ave loss 21.236256602657765\n",
            "step 20211 - loss 17.079689025878906 - moving ave loss 20.820599844979878\n",
            "step 20212 - loss 22.293670654296875 - moving ave loss 20.967906925911578\n",
            "step 20213 - loss 21.127758026123047 - moving ave loss 20.983892035932726\n",
            "step 20214 - loss 21.53564453125 - moving ave loss 21.039067285464455\n",
            "step 20215 - loss 26.07671356201172 - moving ave loss 21.542831913119183\n",
            "step 20216 - loss 22.131267547607422 - moving ave loss 21.60167547656801\n",
            "step 20217 - loss 24.7503662109375 - moving ave loss 21.916544550004957\n",
            "step 20218 - loss 24.55825424194336 - moving ave loss 22.1807155191988\n",
            "step 20219 - loss 19.73046875 - moving ave loss 21.93569084227892\n",
            "step 20220 - loss 19.268800735473633 - moving ave loss 21.66900183159839\n",
            "step 20221 - loss 17.066364288330078 - moving ave loss 21.20873807727156\n",
            "step 20222 - loss 19.377565383911133 - moving ave loss 21.025620807935518\n",
            "step 20223 - loss 28.194913864135742 - moving ave loss 21.74255011355554\n",
            "step 20224 - loss 19.123334884643555 - moving ave loss 21.48062859066434\n",
            "step 20225 - loss 19.58994483947754 - moving ave loss 21.291560215545662\n",
            "step 20226 - loss 23.29756736755371 - moving ave loss 21.49216093074647\n",
            "step 20227 - loss 23.10563087463379 - moving ave loss 21.6535079251352\n",
            "step 20228 - loss 27.957765579223633 - moving ave loss 22.283933690544046\n",
            "step 20229 - loss 23.6043701171875 - moving ave loss 22.415977333208392\n",
            "step 20230 - loss 22.735002517700195 - moving ave loss 22.447879851657575\n",
            "step 20231 - loss 19.55767059326172 - moving ave loss 22.158858925817988\n",
            "step 20232 - loss 19.983060836791992 - moving ave loss 21.94127911691539\n",
            "step 20233 - loss 25.615774154663086 - moving ave loss 22.30872862069016\n",
            "step 20234 - loss 22.074947357177734 - moving ave loss 22.285350494338918\n",
            "step 20235 - loss 21.961524963378906 - moving ave loss 22.252967941242918\n",
            "step 20236 - loss 24.454442977905273 - moving ave loss 22.473115444909155\n",
            "step 20237 - loss 17.689008712768555 - moving ave loss 21.994704771695094\n",
            "step 20238 - loss 19.531982421875 - moving ave loss 21.748432536713086\n",
            "step 20239 - loss 24.215702056884766 - moving ave loss 21.995159488730252\n",
            "step 20240 - loss 21.717073440551758 - moving ave loss 21.967350883912403\n",
            "step 20241 - loss 20.867036819458008 - moving ave loss 21.857319477466962\n",
            "step 20242 - loss 14.862666130065918 - moving ave loss 21.15785414272686\n",
            "step 20243 - loss 21.464313507080078 - moving ave loss 21.18850007916218\n",
            "step 20244 - loss 22.38640022277832 - moving ave loss 21.30829009352379\n",
            "step 20245 - loss 28.422733306884766 - moving ave loss 22.01973441485989\n",
            "step 20246 - loss 17.629213333129883 - moving ave loss 21.58068230668689\n",
            "step 20247 - loss 23.482885360717773 - moving ave loss 21.770902612089976\n",
            "step 20248 - loss 24.357967376708984 - moving ave loss 22.02960908855188\n",
            "step 20249 - loss 20.211145401000977 - moving ave loss 21.84776271979679\n",
            "step 20250 - loss 24.14556884765625 - moving ave loss 22.077543332582735\n",
            "step 20251 - loss 24.433446884155273 - moving ave loss 22.31313368773999\n",
            "step 20252 - loss 21.945663452148438 - moving ave loss 22.276386664180837\n",
            "step 20253 - loss 19.76255226135254 - moving ave loss 22.025003223898008\n",
            "step 20254 - loss 23.467195510864258 - moving ave loss 22.169222452594635\n",
            "step 20255 - loss 26.194236755371094 - moving ave loss 22.57172388287228\n",
            "step 20256 - loss 19.57930564880371 - moving ave loss 22.272482059465425\n",
            "step 20257 - loss 23.562511444091797 - moving ave loss 22.401484997928062\n",
            "step 20258 - loss 16.378549575805664 - moving ave loss 21.79919145571582\n",
            "step 20259 - loss 21.20332908630371 - moving ave loss 21.73960521877461\n",
            "step 20260 - loss 20.307701110839844 - moving ave loss 21.596414807981134\n",
            "step 20261 - loss 25.065336227416992 - moving ave loss 21.94330694992472\n",
            "step 20262 - loss 19.26148796081543 - moving ave loss 21.67512505101379\n",
            "step 20263 - loss 22.731693267822266 - moving ave loss 21.78078187269464\n",
            "step 20264 - loss 24.58634376525879 - moving ave loss 22.061338061951055\n",
            "step 20265 - loss 27.06863784790039 - moving ave loss 22.562068040545988\n",
            "step 20266 - loss 25.20013427734375 - moving ave loss 22.825874664225765\n",
            "step 20267 - loss 22.695377349853516 - moving ave loss 22.81282493278854\n",
            "step 20268 - loss 22.12029266357422 - moving ave loss 22.743571705867108\n",
            "step 20269 - loss 23.046642303466797 - moving ave loss 22.773878765627078\n",
            "step 20270 - loss 21.441890716552734 - moving ave loss 22.640679960719645\n",
            "step 20271 - loss 24.087276458740234 - moving ave loss 22.785339610521703\n",
            "step 20272 - loss 17.83384895324707 - moving ave loss 22.290190544794243\n",
            "step 20273 - loss 19.666048049926758 - moving ave loss 22.027776295307497\n",
            "step 20274 - loss 20.60410499572754 - moving ave loss 21.8854091653495\n",
            "step 20275 - loss 25.666805267333984 - moving ave loss 22.26354877554795\n",
            "step 20276 - loss 22.682676315307617 - moving ave loss 22.305461529523917\n",
            "step 20277 - loss 27.933467864990234 - moving ave loss 22.868262163070547\n",
            "step 20278 - loss 22.576826095581055 - moving ave loss 22.839118556321598\n",
            "step 20279 - loss 26.535276412963867 - moving ave loss 23.208734341985824\n",
            "step 20280 - loss 17.35345458984375 - moving ave loss 22.62320636677162\n",
            "step 20281 - loss 20.25682830810547 - moving ave loss 22.386568560905005\n",
            "step 20282 - loss 23.94032859802246 - moving ave loss 22.54194456461675\n",
            "step 20283 - loss 22.001651763916016 - moving ave loss 22.487915284546673\n",
            "step 20284 - loss 25.309900283813477 - moving ave loss 22.770113784473352\n",
            "step 20285 - loss 22.690412521362305 - moving ave loss 22.76214365816225\n",
            "step 20286 - loss 18.8762264251709 - moving ave loss 22.373551934863116\n",
            "step 20287 - loss 18.9727725982666 - moving ave loss 22.033474001203462\n",
            "step 20288 - loss 21.261688232421875 - moving ave loss 21.956295424325305\n",
            "step 20289 - loss 18.363697052001953 - moving ave loss 21.597035587092968\n",
            "step 20290 - loss 20.089534759521484 - moving ave loss 21.44628550433582\n",
            "step 20291 - loss 23.383756637573242 - moving ave loss 21.640032617659564\n",
            "step 20292 - loss 20.69422149658203 - moving ave loss 21.54545150555181\n",
            "step 20293 - loss 21.283641815185547 - moving ave loss 21.519270536515187\n",
            "step 20294 - loss 20.925975799560547 - moving ave loss 21.459941062819723\n",
            "step 20295 - loss 22.05125617980957 - moving ave loss 21.51907257451871\n",
            "step 20296 - loss 22.98883056640625 - moving ave loss 21.666048373707465\n",
            "step 20297 - loss 22.792091369628906 - moving ave loss 21.77865267329961\n",
            "step 20298 - loss 22.869922637939453 - moving ave loss 21.887779669763596\n",
            "Checkpoint at step 20298\n",
            "step 20299 - loss 19.170583724975586 - moving ave loss 21.616060075284793\n",
            "step 20300 - loss 19.147506713867188 - moving ave loss 21.369204739143033\n",
            "step 20301 - loss 18.78411865234375 - moving ave loss 21.110696130463108\n",
            "step 20302 - loss 18.513845443725586 - moving ave loss 20.851011061789354\n",
            "step 20303 - loss 18.234283447265625 - moving ave loss 20.58933830033698\n",
            "step 20304 - loss 21.27762794494629 - moving ave loss 20.65816726479791\n",
            "step 20305 - loss 23.299421310424805 - moving ave loss 20.922292669360598\n",
            "step 20306 - loss 21.497432708740234 - moving ave loss 20.97980667329856\n",
            "step 20307 - loss 21.801734924316406 - moving ave loss 21.061999498400347\n",
            "step 20308 - loss 27.05374526977539 - moving ave loss 21.661174075537854\n",
            "step 20309 - loss 20.018735885620117 - moving ave loss 21.496930256546083\n",
            "step 20310 - loss 19.841960906982422 - moving ave loss 21.331433321589717\n",
            "step 20311 - loss 19.64797592163086 - moving ave loss 21.16308758159383\n",
            "step 20312 - loss 17.09552574157715 - moving ave loss 20.756331397592163\n",
            "step 20313 - loss 21.605899810791016 - moving ave loss 20.84128823891205\n",
            "step 20314 - loss 22.709482192993164 - moving ave loss 21.02810763432016\n",
            "step 20315 - loss 20.5909423828125 - moving ave loss 20.984391109169398\n",
            "step 20316 - loss 23.89788818359375 - moving ave loss 21.275740816611833\n",
            "step 20317 - loss 21.45278549194336 - moving ave loss 21.293445284144987\n",
            "step 20318 - loss 32.200923919677734 - moving ave loss 22.384193147698262\n",
            "step 20319 - loss 18.50603485107422 - moving ave loss 21.996377318035858\n",
            "step 20320 - loss 19.68700408935547 - moving ave loss 21.76543999516782\n",
            "step 20321 - loss 21.62725830078125 - moving ave loss 21.751621825729163\n",
            "step 20322 - loss 26.24471092224121 - moving ave loss 22.200930735380368\n",
            "step 20323 - loss 27.61995506286621 - moving ave loss 22.742833168128954\n",
            "step 20324 - loss 21.34870719909668 - moving ave loss 22.603420571225726\n",
            "step 20325 - loss 21.765933990478516 - moving ave loss 22.519671913151008\n",
            "step 20326 - loss 31.066020965576172 - moving ave loss 23.374306818393528\n",
            "step 20327 - loss 17.128408432006836 - moving ave loss 22.74971697975486\n",
            "step 20328 - loss 22.7885799407959 - moving ave loss 22.753603275858968\n",
            "step 20329 - loss 16.97376251220703 - moving ave loss 22.175619199493774\n",
            "step 20330 - loss 21.178213119506836 - moving ave loss 22.075878591495083\n",
            "step 20331 - loss 23.869033813476562 - moving ave loss 22.255194113693232\n",
            "step 20332 - loss 22.09588623046875 - moving ave loss 22.239263325370786\n",
            "step 20333 - loss 19.009296417236328 - moving ave loss 21.91626663455734\n",
            "step 20334 - loss 23.412443161010742 - moving ave loss 22.06588428720268\n",
            "step 20335 - loss 19.747892379760742 - moving ave loss 21.83408509645849\n",
            "step 20336 - loss 21.791019439697266 - moving ave loss 21.82977853078237\n",
            "step 20337 - loss 23.514432907104492 - moving ave loss 21.998243968414585\n",
            "step 20338 - loss 16.042049407958984 - moving ave loss 21.402624512369027\n",
            "step 20339 - loss 16.363759994506836 - moving ave loss 20.898738060582808\n",
            "step 20340 - loss 22.362346649169922 - moving ave loss 21.04509891944152\n",
            "step 20341 - loss 25.70015525817871 - moving ave loss 21.510604553315243\n",
            "step 20342 - loss 21.791826248168945 - moving ave loss 21.538726722800615\n",
            "step 20343 - loss 19.451335906982422 - moving ave loss 21.329987641218793\n",
            "Finish 10 epoch(es)\n",
            "step 20344 - loss 25.50250816345215 - moving ave loss 21.74723969344213\n",
            "step 20345 - loss 16.70692253112793 - moving ave loss 21.24320797721071\n",
            "step 20346 - loss 22.610233306884766 - moving ave loss 21.379910510178117\n",
            "step 20347 - loss 21.943267822265625 - moving ave loss 21.43624624138687\n",
            "step 20348 - loss 24.996192932128906 - moving ave loss 21.792240910461075\n",
            "step 20349 - loss 22.64594268798828 - moving ave loss 21.877611088213797\n",
            "step 20350 - loss 23.68319320678711 - moving ave loss 22.05816930007113\n",
            "step 20351 - loss 21.3799991607666 - moving ave loss 21.990352286140673\n",
            "step 20352 - loss 22.787370681762695 - moving ave loss 22.070054125702875\n",
            "step 20353 - loss 22.947097778320312 - moving ave loss 22.15775849096462\n",
            "step 20354 - loss 24.057178497314453 - moving ave loss 22.347700491599603\n",
            "step 20355 - loss 25.269826889038086 - moving ave loss 22.639913131343455\n",
            "step 20356 - loss 17.231924057006836 - moving ave loss 22.099114223909794\n",
            "step 20357 - loss 18.640453338623047 - moving ave loss 21.75324813538112\n",
            "step 20358 - loss 23.52569580078125 - moving ave loss 21.930492901921134\n",
            "step 20359 - loss 20.52749252319336 - moving ave loss 21.790192864048358\n",
            "step 20360 - loss 29.92011260986328 - moving ave loss 22.60318483862985\n",
            "step 20361 - loss 27.584739685058594 - moving ave loss 23.101340323272726\n",
            "step 20362 - loss 21.003664016723633 - moving ave loss 22.891572692617817\n",
            "step 20363 - loss 23.158843994140625 - moving ave loss 22.9182998227701\n",
            "step 20364 - loss 19.889081954956055 - moving ave loss 22.615378035988694\n",
            "step 20365 - loss 21.560047149658203 - moving ave loss 22.509844947355646\n",
            "step 20366 - loss 22.929325103759766 - moving ave loss 22.551792962996057\n",
            "step 20367 - loss 23.364778518676758 - moving ave loss 22.63309151856413\n",
            "step 20368 - loss 18.24325942993164 - moving ave loss 22.19410830970088\n",
            "step 20369 - loss 24.140361785888672 - moving ave loss 22.388733657319662\n",
            "step 20370 - loss 25.445960998535156 - moving ave loss 22.694456391441214\n",
            "step 20371 - loss 24.04227066040039 - moving ave loss 22.829237818337134\n",
            "step 20372 - loss 19.341215133666992 - moving ave loss 22.48043554987012\n",
            "step 20373 - loss 19.69582176208496 - moving ave loss 22.201974171091607\n",
            "step 20374 - loss 19.459274291992188 - moving ave loss 21.927704183181667\n",
            "step 20375 - loss 22.275596618652344 - moving ave loss 21.962493426728738\n",
            "step 20376 - loss 18.617698669433594 - moving ave loss 21.62801395099922\n",
            "step 20377 - loss 23.39101219177246 - moving ave loss 21.804313775076544\n",
            "step 20378 - loss 22.239362716674805 - moving ave loss 21.84781866923637\n",
            "step 20379 - loss 26.949270248413086 - moving ave loss 22.357963827154045\n",
            "step 20380 - loss 20.067197799682617 - moving ave loss 22.128887224406903\n",
            "step 20381 - loss 21.718263626098633 - moving ave loss 22.087824864576078\n",
            "step 20382 - loss 24.230953216552734 - moving ave loss 22.302137699773745\n",
            "step 20383 - loss 21.040725708007812 - moving ave loss 22.17599650059715\n",
            "step 20384 - loss 19.12109375 - moving ave loss 21.870506225537437\n",
            "step 20385 - loss 20.173385620117188 - moving ave loss 21.70079416499541\n",
            "step 20386 - loss 21.619117736816406 - moving ave loss 21.692626522177513\n",
            "step 20387 - loss 21.203250885009766 - moving ave loss 21.64368895846074\n",
            "step 20388 - loss 19.89454460144043 - moving ave loss 21.468774522758707\n",
            "step 20389 - loss 23.968339920043945 - moving ave loss 21.718731062487233\n",
            "step 20390 - loss 22.13431739807129 - moving ave loss 21.76028969604564\n",
            "step 20391 - loss 22.153093338012695 - moving ave loss 21.799570060242345\n",
            "step 20392 - loss 24.087060928344727 - moving ave loss 22.028319147052585\n",
            "step 20393 - loss 26.1126708984375 - moving ave loss 22.436754322191078\n",
            "step 20394 - loss 21.305017471313477 - moving ave loss 22.32358063710332\n",
            "step 20395 - loss 21.164827346801758 - moving ave loss 22.207705308073162\n",
            "step 20396 - loss 18.845388412475586 - moving ave loss 21.871473618513406\n",
            "step 20397 - loss 22.153512954711914 - moving ave loss 21.899677552133255\n",
            "step 20398 - loss 21.460453033447266 - moving ave loss 21.85575510026466\n",
            "step 20399 - loss 23.54019546508789 - moving ave loss 22.024199136746983\n",
            "step 20400 - loss 20.449054718017578 - moving ave loss 21.866684694874042\n",
            "step 20401 - loss 21.542890548706055 - moving ave loss 21.834305280257244\n",
            "step 20402 - loss 23.67991828918457 - moving ave loss 22.018866581149975\n",
            "step 20403 - loss 25.03413963317871 - moving ave loss 22.32039388635285\n",
            "step 20404 - loss 23.228862762451172 - moving ave loss 22.41124077396268\n",
            "step 20405 - loss 18.193349838256836 - moving ave loss 21.989451680392097\n",
            "step 20406 - loss 19.375276565551758 - moving ave loss 21.728034168908064\n",
            "step 20407 - loss 20.59332275390625 - moving ave loss 21.614563027407883\n",
            "step 20408 - loss 18.26830291748047 - moving ave loss 21.27993701641514\n",
            "step 20409 - loss 17.819082260131836 - moving ave loss 20.933851540786808\n",
            "step 20410 - loss 18.173290252685547 - moving ave loss 20.657795411976682\n",
            "step 20411 - loss 21.718917846679688 - moving ave loss 20.763907655446985\n",
            "step 20412 - loss 18.522197723388672 - moving ave loss 20.539736662241154\n",
            "step 20413 - loss 26.09974479675293 - moving ave loss 21.095737475692335\n",
            "step 20414 - loss 19.56714630126953 - moving ave loss 20.942878358250056\n",
            "step 20415 - loss 15.481654167175293 - moving ave loss 20.396755939142583\n",
            "step 20416 - loss 20.58588218688965 - moving ave loss 20.41566856391729\n",
            "step 20417 - loss 19.674827575683594 - moving ave loss 20.34158446509392\n",
            "step 20418 - loss 20.000713348388672 - moving ave loss 20.307497353423397\n",
            "step 20419 - loss 24.586252212524414 - moving ave loss 20.7353728393335\n",
            "step 20420 - loss 24.197628021240234 - moving ave loss 21.081598357524175\n",
            "step 20421 - loss 20.12727928161621 - moving ave loss 20.98616644993338\n",
            "step 20422 - loss 21.26313591003418 - moving ave loss 21.013863395943456\n",
            "step 20423 - loss 19.90789031982422 - moving ave loss 20.903266088331534\n",
            "Checkpoint at step 20423\n",
            "step 20424 - loss 23.086868286132812 - moving ave loss 21.121626308111665\n",
            "step 20425 - loss 18.27939796447754 - moving ave loss 20.837403473748253\n",
            "step 20426 - loss 23.28154182434082 - moving ave loss 21.081817308807512\n",
            "step 20427 - loss 24.028522491455078 - moving ave loss 21.376487827072268\n",
            "step 20428 - loss 25.104591369628906 - moving ave loss 21.74929818132793\n",
            "step 20429 - loss 24.868389129638672 - moving ave loss 22.061207276159006\n",
            "step 20430 - loss 21.323373794555664 - moving ave loss 21.987423927998673\n",
            "step 20431 - loss 19.273916244506836 - moving ave loss 21.71607315964949\n",
            "step 20432 - loss 20.974035263061523 - moving ave loss 21.641869369990694\n",
            "step 20433 - loss 15.871664047241211 - moving ave loss 21.064848837715747\n",
            "step 20434 - loss 20.289140701293945 - moving ave loss 20.987278024073568\n",
            "step 20435 - loss 24.912752151489258 - moving ave loss 21.37982543681514\n",
            "step 20436 - loss 21.869138717651367 - moving ave loss 21.42875676489876\n",
            "step 20437 - loss 21.227527618408203 - moving ave loss 21.408633850249707\n",
            "step 20438 - loss 21.806961059570312 - moving ave loss 21.44846657118177\n",
            "step 20439 - loss 20.6180477142334 - moving ave loss 21.365424685486932\n",
            "step 20440 - loss 18.603689193725586 - moving ave loss 21.089251136310796\n",
            "step 20441 - loss 21.471031188964844 - moving ave loss 21.1274291415762\n",
            "step 20442 - loss 20.412921905517578 - moving ave loss 21.05597841797034\n",
            "step 20443 - loss 18.61041259765625 - moving ave loss 20.81142183593893\n",
            "step 20444 - loss 20.87483787536621 - moving ave loss 20.817763439881656\n",
            "step 20445 - loss 23.183650970458984 - moving ave loss 21.05435219293939\n",
            "step 20446 - loss 31.411985397338867 - moving ave loss 22.090115513379338\n",
            "step 20447 - loss 23.265321731567383 - moving ave loss 22.207636135198143\n",
            "step 20448 - loss 21.906023025512695 - moving ave loss 22.1774748242296\n",
            "step 20449 - loss 20.455615997314453 - moving ave loss 22.005288941538087\n",
            "step 20450 - loss 17.353178024291992 - moving ave loss 21.54007784981348\n",
            "step 20451 - loss 17.068954467773438 - moving ave loss 21.092965511609478\n",
            "step 20452 - loss 16.571802139282227 - moving ave loss 20.64084917437675\n",
            "step 20453 - loss 17.53291893005371 - moving ave loss 20.330056149944447\n",
            "step 20454 - loss 18.94927215576172 - moving ave loss 20.191977750526174\n",
            "step 20455 - loss 24.90694236755371 - moving ave loss 20.663474212228927\n",
            "step 20456 - loss 21.82318115234375 - moving ave loss 20.779444906240407\n",
            "step 20457 - loss 21.228309631347656 - moving ave loss 20.824331378751133\n",
            "step 20458 - loss 22.87849235534668 - moving ave loss 21.029747476410687\n",
            "step 20459 - loss 21.02226448059082 - moving ave loss 21.0289991768287\n",
            "step 20460 - loss 26.789928436279297 - moving ave loss 21.605092102773764\n",
            "step 20461 - loss 21.71410369873047 - moving ave loss 21.615993262369436\n",
            "step 20462 - loss 18.27077865600586 - moving ave loss 21.28147180173308\n",
            "step 20463 - loss 19.629026412963867 - moving ave loss 21.11622726285616\n",
            "step 20464 - loss 20.267480850219727 - moving ave loss 21.031352621592514\n",
            "step 20465 - loss 23.577680587768555 - moving ave loss 21.285985418210117\n",
            "step 20466 - loss 23.540971755981445 - moving ave loss 21.511484051987253\n",
            "step 20467 - loss 23.067371368408203 - moving ave loss 21.667072783629347\n",
            "step 20468 - loss 22.405454635620117 - moving ave loss 21.740910968828423\n",
            "step 20469 - loss 17.74842071533203 - moving ave loss 21.341661943478787\n",
            "step 20470 - loss 23.612201690673828 - moving ave loss 21.568715918198293\n",
            "step 20471 - loss 22.26947021484375 - moving ave loss 21.63879134786284\n",
            "step 20472 - loss 25.186918258666992 - moving ave loss 21.993604038943253\n",
            "step 20473 - loss 21.247039794921875 - moving ave loss 21.918947614541118\n",
            "step 20474 - loss 29.547590255737305 - moving ave loss 22.68181187866074\n",
            "step 20475 - loss 19.6385498046875 - moving ave loss 22.377485671263415\n",
            "step 20476 - loss 23.673778533935547 - moving ave loss 22.50711495753063\n",
            "step 20477 - loss 23.386241912841797 - moving ave loss 22.595027653061745\n",
            "step 20478 - loss 22.69351577758789 - moving ave loss 22.604876465514362\n",
            "step 20479 - loss 18.80881690979004 - moving ave loss 22.22527050994193\n",
            "step 20480 - loss 20.131589889526367 - moving ave loss 22.015902447900373\n",
            "step 20481 - loss 22.77153778076172 - moving ave loss 22.09146598118651\n",
            "step 20482 - loss 25.76504898071289 - moving ave loss 22.458824281139147\n",
            "step 20483 - loss 23.5108699798584 - moving ave loss 22.56402885101107\n",
            "step 20484 - loss 23.486461639404297 - moving ave loss 22.656272129850393\n",
            "step 20485 - loss 22.58518409729004 - moving ave loss 22.64916332659436\n",
            "Finish 11 epoch(es)\n",
            "step 20486 - loss 27.434160232543945 - moving ave loss 23.127663017189317\n",
            "step 20487 - loss 27.598657608032227 - moving ave loss 23.57476247627361\n",
            "step 20488 - loss 18.31521987915039 - moving ave loss 23.048808216561287\n",
            "step 20489 - loss 22.961172103881836 - moving ave loss 23.040044605293343\n",
            "step 20490 - loss 21.98069953918457 - moving ave loss 22.934110098682464\n",
            "step 20491 - loss 21.169872283935547 - moving ave loss 22.75768631720777\n",
            "step 20492 - loss 23.315671920776367 - moving ave loss 22.81348487756463\n",
            "step 20493 - loss 28.340791702270508 - moving ave loss 23.366215560035215\n",
            "step 20494 - loss 21.089506149291992 - moving ave loss 23.138544618960893\n",
            "step 20495 - loss 16.13494873046875 - moving ave loss 22.43818503011168\n",
            "step 20496 - loss 20.912080764770508 - moving ave loss 22.285574603577565\n",
            "step 20497 - loss 25.36563491821289 - moving ave loss 22.5935806350411\n",
            "step 20498 - loss 22.013051986694336 - moving ave loss 22.535527770206425\n",
            "step 20499 - loss 22.019081115722656 - moving ave loss 22.48388310475805\n",
            "step 20500 - loss 23.21235466003418 - moving ave loss 22.556730260285665\n",
            "step 20501 - loss 22.865833282470703 - moving ave loss 22.587640562504166\n",
            "step 20502 - loss 23.941932678222656 - moving ave loss 22.723069774076016\n",
            "step 20503 - loss 25.560678482055664 - moving ave loss 23.00683064487398\n",
            "step 20504 - loss 20.673757553100586 - moving ave loss 22.77352333569664\n",
            "step 20505 - loss 27.024505615234375 - moving ave loss 23.198621563650416\n",
            "step 20506 - loss 18.177350997924805 - moving ave loss 22.696494507077855\n",
            "step 20507 - loss 23.012798309326172 - moving ave loss 22.728124887302688\n",
            "step 20508 - loss 23.685962677001953 - moving ave loss 22.823908666272615\n",
            "step 20509 - loss 20.75274658203125 - moving ave loss 22.61679245784848\n",
            "step 20510 - loss 23.358110427856445 - moving ave loss 22.690924254849275\n",
            "step 20511 - loss 17.47953987121582 - moving ave loss 22.16978581648593\n",
            "step 20512 - loss 23.270845413208008 - moving ave loss 22.279891776158138\n",
            "step 20513 - loss 25.378780364990234 - moving ave loss 22.589780635041347\n",
            "step 20514 - loss 23.8408145904541 - moving ave loss 22.714884030582624\n",
            "step 20515 - loss 20.647815704345703 - moving ave loss 22.508177197958933\n",
            "step 20516 - loss 20.651599884033203 - moving ave loss 22.32251946656636\n",
            "step 20517 - loss 22.56060791015625 - moving ave loss 22.346328310925347\n",
            "step 20518 - loss 25.730056762695312 - moving ave loss 22.684701156102346\n",
            "step 20519 - loss 22.82221221923828 - moving ave loss 22.698452262415937\n",
            "step 20520 - loss 21.033645629882812 - moving ave loss 22.531971599162627\n",
            "step 20521 - loss 23.292402267456055 - moving ave loss 22.60801466599197\n",
            "step 20522 - loss 17.307823181152344 - moving ave loss 22.077995517508008\n",
            "step 20523 - loss 18.775432586669922 - moving ave loss 21.7477392244242\n",
            "step 20524 - loss 24.868022918701172 - moving ave loss 22.0597675938519\n",
            "step 20525 - loss 20.372127532958984 - moving ave loss 21.891003587762604\n",
            "step 20526 - loss 23.39595603942871 - moving ave loss 22.041498832929218\n",
            "step 20527 - loss 20.38736343383789 - moving ave loss 21.876085293020086\n",
            "step 20528 - loss 19.201778411865234 - moving ave loss 21.6086546049046\n",
            "step 20529 - loss 25.9599609375 - moving ave loss 22.04378523816414\n",
            "step 20530 - loss 23.44069480895996 - moving ave loss 22.183476195243724\n",
            "step 20531 - loss 21.541973114013672 - moving ave loss 22.11932588712072\n",
            "step 20532 - loss 20.774843215942383 - moving ave loss 21.984877620002887\n",
            "step 20533 - loss 19.890869140625 - moving ave loss 21.7754767720651\n",
            "step 20534 - loss 25.86069679260254 - moving ave loss 22.183998774118848\n",
            "step 20535 - loss 18.660274505615234 - moving ave loss 21.83162634726849\n",
            "step 20536 - loss 18.80367088317871 - moving ave loss 21.528830800859513\n",
            "step 20537 - loss 22.43768882751465 - moving ave loss 21.619716603525028\n",
            "step 20538 - loss 22.171581268310547 - moving ave loss 21.67490307000358\n",
            "step 20539 - loss 21.426414489746094 - moving ave loss 21.65005421197783\n",
            "step 20540 - loss 22.521615982055664 - moving ave loss 21.737210388985616\n",
            "step 20541 - loss 21.43845558166504 - moving ave loss 21.70733490825356\n",
            "step 20542 - loss 26.785873413085938 - moving ave loss 22.2151887587368\n",
            "step 20543 - loss 17.355234146118164 - moving ave loss 21.729193297474936\n",
            "step 20544 - loss 19.44891357421875 - moving ave loss 21.501165325149316\n",
            "step 20545 - loss 20.544286727905273 - moving ave loss 21.405477465424912\n",
            "step 20546 - loss 29.269166946411133 - moving ave loss 22.191846413523535\n",
            "step 20547 - loss 21.58673095703125 - moving ave loss 22.13133486787431\n",
            "step 20548 - loss 24.634197235107422 - moving ave loss 22.38162110459762\n",
            "Checkpoint at step 20548\n",
            "step 20549 - loss 22.84288215637207 - moving ave loss 22.427747209775067\n",
            "step 20550 - loss 21.22205352783203 - moving ave loss 22.307177841580764\n",
            "step 20551 - loss 19.145597457885742 - moving ave loss 21.99101980321126\n",
            "step 20552 - loss 22.42255973815918 - moving ave loss 22.034173796706053\n",
            "step 20553 - loss 18.820785522460938 - moving ave loss 21.71283496928154\n",
            "step 20554 - loss 23.047698974609375 - moving ave loss 21.846321369814323\n",
            "step 20555 - loss 21.508726119995117 - moving ave loss 21.812561844832402\n",
            "step 20556 - loss 20.379695892333984 - moving ave loss 21.66927524958256\n",
            "step 20557 - loss 22.652761459350586 - moving ave loss 21.767623870559365\n",
            "step 20558 - loss 25.516508102416992 - moving ave loss 22.142512293745128\n",
            "step 20559 - loss 19.66459083557129 - moving ave loss 21.894720147927746\n",
            "step 20560 - loss 18.8250732421875 - moving ave loss 21.587755457353722\n",
            "step 20561 - loss 20.575801849365234 - moving ave loss 21.486560096554875\n",
            "step 20562 - loss 20.633939743041992 - moving ave loss 21.401298061203587\n",
            "step 20563 - loss 22.47012710571289 - moving ave loss 21.508180965654518\n",
            "step 20564 - loss 21.87418556213379 - moving ave loss 21.544781425302446\n",
            "step 20565 - loss 20.835609436035156 - moving ave loss 21.473864226375717\n",
            "step 20566 - loss 22.26343536376953 - moving ave loss 21.5528213401151\n",
            "step 20567 - loss 24.386932373046875 - moving ave loss 21.836232443408274\n",
            "step 20568 - loss 29.557392120361328 - moving ave loss 22.60834841110358\n",
            "step 20569 - loss 22.894229888916016 - moving ave loss 22.636936558884823\n",
            "step 20570 - loss 19.64366912841797 - moving ave loss 22.33760981583814\n",
            "step 20571 - loss 23.63191795349121 - moving ave loss 22.467040629603446\n",
            "step 20572 - loss 20.710031509399414 - moving ave loss 22.291339717583043\n",
            "step 20573 - loss 18.910371780395508 - moving ave loss 21.953242923864288\n",
            "step 20574 - loss 19.20407485961914 - moving ave loss 21.678326117439774\n",
            "step 20575 - loss 24.02492904663086 - moving ave loss 21.912986410358883\n",
            "step 20576 - loss 16.510833740234375 - moving ave loss 21.37277114334643\n",
            "step 20577 - loss 18.662694931030273 - moving ave loss 21.101763522114812\n",
            "step 20578 - loss 15.993856430053711 - moving ave loss 20.5909728129087\n",
            "step 20579 - loss 26.40073585510254 - moving ave loss 21.171949117128083\n",
            "step 20580 - loss 18.43831443786621 - moving ave loss 20.898585649201895\n",
            "step 20581 - loss 19.251075744628906 - moving ave loss 20.7338346587446\n",
            "step 20582 - loss 24.398983001708984 - moving ave loss 21.100349493041037\n",
            "step 20583 - loss 21.378597259521484 - moving ave loss 21.12817426968908\n",
            "step 20584 - loss 19.129364013671875 - moving ave loss 20.92829324408736\n",
            "step 20585 - loss 20.576759338378906 - moving ave loss 20.893139853516516\n",
            "step 20586 - loss 26.009506225585938 - moving ave loss 21.404776490723457\n",
            "step 20587 - loss 20.98674774169922 - moving ave loss 21.362973615821033\n",
            "step 20588 - loss 20.686279296875 - moving ave loss 21.295304183926433\n",
            "step 20589 - loss 22.727611541748047 - moving ave loss 21.438534919708594\n",
            "step 20590 - loss 21.948806762695312 - moving ave loss 21.489562104007266\n",
            "step 20591 - loss 20.201406478881836 - moving ave loss 21.360746541494724\n",
            "step 20592 - loss 17.730710983276367 - moving ave loss 20.99774298567289\n",
            "step 20593 - loss 21.050874710083008 - moving ave loss 21.0030561581139\n",
            "step 20594 - loss 21.022754669189453 - moving ave loss 21.005026009221456\n",
            "step 20595 - loss 23.64947509765625 - moving ave loss 21.269470918064936\n",
            "step 20596 - loss 17.5105037689209 - moving ave loss 20.893574203150532\n",
            "step 20597 - loss 21.628860473632812 - moving ave loss 20.96710283019876\n",
            "step 20598 - loss 19.923229217529297 - moving ave loss 20.862715468931814\n",
            "step 20599 - loss 22.134496688842773 - moving ave loss 20.98989359092291\n",
            "step 20600 - loss 28.94510841369629 - moving ave loss 21.78541507320025\n",
            "step 20601 - loss 17.668283462524414 - moving ave loss 21.37370191213267\n",
            "step 20602 - loss 26.395126342773438 - moving ave loss 21.875844355196747\n",
            "step 20603 - loss 21.191497802734375 - moving ave loss 21.80740969995051\n",
            "step 20604 - loss 21.31081199645996 - moving ave loss 21.75774992960146\n",
            "step 20605 - loss 22.95136070251465 - moving ave loss 21.87711100689278\n",
            "step 20606 - loss 21.368844985961914 - moving ave loss 21.826284404799694\n",
            "step 20607 - loss 18.82608985900879 - moving ave loss 21.526264950220604\n",
            "step 20608 - loss 18.74455451965332 - moving ave loss 21.248093907163877\n",
            "step 20609 - loss 25.31728744506836 - moving ave loss 21.655013260954327\n",
            "step 20610 - loss 21.227083206176758 - moving ave loss 21.612220255476572\n",
            "step 20611 - loss 17.34470558166504 - moving ave loss 21.18546878809542\n",
            "step 20612 - loss 21.89093589782715 - moving ave loss 21.256015499068592\n",
            "step 20613 - loss 22.854286193847656 - moving ave loss 21.415842568546502\n",
            "step 20614 - loss 25.45856285095215 - moving ave loss 21.820114596787068\n",
            "step 20615 - loss 20.11490821838379 - moving ave loss 21.649593958946742\n",
            "step 20616 - loss 21.650672912597656 - moving ave loss 21.649701854311836\n",
            "step 20617 - loss 19.619487762451172 - moving ave loss 21.446680445125768\n",
            "step 20618 - loss 18.430166244506836 - moving ave loss 21.145029025063874\n",
            "step 20619 - loss 21.603412628173828 - moving ave loss 21.19086738537487\n",
            "step 20620 - loss 21.188507080078125 - moving ave loss 21.190631354845195\n",
            "step 20621 - loss 24.2989444732666 - moving ave loss 21.501462666687335\n",
            "step 20622 - loss 20.963947296142578 - moving ave loss 21.447711129632857\n",
            "step 20623 - loss 21.055429458618164 - moving ave loss 21.40848296253139\n",
            "step 20624 - loss 23.515432357788086 - moving ave loss 21.61917790205706\n",
            "step 20625 - loss 21.985551834106445 - moving ave loss 21.655815295262\n",
            "step 20626 - loss 25.45894432067871 - moving ave loss 22.03612819780367\n",
            "step 20627 - loss 19.383625030517578 - moving ave loss 21.77087788107506\n",
            "Finish 12 epoch(es)\n",
            "step 20628 - loss 18.84126853942871 - moving ave loss 21.477916946910423\n",
            "step 20629 - loss 20.06125831604004 - moving ave loss 21.336251083823385\n",
            "step 20630 - loss 17.64360809326172 - moving ave loss 20.96698678476722\n",
            "step 20631 - loss 20.657766342163086 - moving ave loss 20.936064740506808\n",
            "step 20632 - loss 21.750011444091797 - moving ave loss 21.017459410865307\n",
            "step 20633 - loss 17.746463775634766 - moving ave loss 20.690359847342254\n",
            "step 20634 - loss 16.565006256103516 - moving ave loss 20.277824488218382\n",
            "step 20635 - loss 19.779783248901367 - moving ave loss 20.22802036428668\n",
            "step 20636 - loss 22.88087272644043 - moving ave loss 20.493305600502055\n",
            "step 20637 - loss 20.64190673828125 - moving ave loss 20.508165714279976\n",
            "step 20638 - loss 23.594205856323242 - moving ave loss 20.816769728484303\n",
            "step 20639 - loss 21.621713638305664 - moving ave loss 20.89726411946644\n",
            "step 20640 - loss 21.248897552490234 - moving ave loss 20.932427462768818\n",
            "step 20641 - loss 19.93219566345215 - moving ave loss 20.83240428283715\n",
            "step 20642 - loss 24.780550003051758 - moving ave loss 21.22721885485861\n",
            "step 20643 - loss 15.941070556640625 - moving ave loss 20.69860402503681\n",
            "step 20644 - loss 25.932817459106445 - moving ave loss 21.222025368443774\n",
            "step 20645 - loss 23.544668197631836 - moving ave loss 21.45428965136258\n",
            "step 20646 - loss 16.799108505249023 - moving ave loss 20.988771536751223\n",
            "step 20647 - loss 23.617374420166016 - moving ave loss 21.2516318250927\n",
            "step 20648 - loss 24.320919036865234 - moving ave loss 21.558560546269955\n",
            "step 20649 - loss 19.560733795166016 - moving ave loss 21.358777871159564\n",
            "step 20650 - loss 17.627107620239258 - moving ave loss 20.985610846067534\n",
            "step 20651 - loss 19.66455841064453 - moving ave loss 20.85350560252523\n",
            "step 20652 - loss 24.968191146850586 - moving ave loss 21.26497415695777\n",
            "step 20653 - loss 24.13719367980957 - moving ave loss 21.55219610924295\n",
            "step 20654 - loss 19.734628677368164 - moving ave loss 21.37043936605547\n",
            "step 20655 - loss 17.715700149536133 - moving ave loss 21.00496544440354\n",
            "step 20656 - loss 23.15590476989746 - moving ave loss 21.220059376952932\n",
            "step 20657 - loss 19.576290130615234 - moving ave loss 21.055682452319164\n",
            "step 20658 - loss 22.38453483581543 - moving ave loss 21.188567690668794\n",
            "step 20659 - loss 19.687044143676758 - moving ave loss 21.03841533596959\n",
            "step 20660 - loss 22.26129150390625 - moving ave loss 21.160702952763256\n",
            "step 20661 - loss 18.01927947998047 - moving ave loss 20.846560605484974\n",
            "step 20662 - loss 19.495826721191406 - moving ave loss 20.71148721705562\n",
            "step 20663 - loss 25.47552490234375 - moving ave loss 21.18789098558443\n",
            "step 20664 - loss 20.50212860107422 - moving ave loss 21.119314747133412\n",
            "step 20665 - loss 22.392854690551758 - moving ave loss 21.246668741475247\n",
            "step 20666 - loss 26.825071334838867 - moving ave loss 21.80450900081161\n",
            "step 20667 - loss 28.072811126708984 - moving ave loss 22.431339213401348\n",
            "step 20668 - loss 19.75728416442871 - moving ave loss 22.163933708504082\n",
            "step 20669 - loss 18.596054077148438 - moving ave loss 21.80714574536852\n",
            "step 20670 - loss 19.429208755493164 - moving ave loss 21.569352046380985\n",
            "step 20671 - loss 23.372203826904297 - moving ave loss 21.749637224433314\n",
            "step 20672 - loss 19.21603012084961 - moving ave loss 21.496276514074946\n",
            "step 20673 - loss 23.234331130981445 - moving ave loss 21.670081975765594\n",
            "Checkpoint at step 20673\n",
            "step 20674 - loss 21.684173583984375 - moving ave loss 21.67149113658747\n",
            "step 20675 - loss 21.894372940063477 - moving ave loss 21.69377931693507\n",
            "step 20676 - loss 21.941503524780273 - moving ave loss 21.71855173771959\n",
            "step 20677 - loss 22.040597915649414 - moving ave loss 21.75075635551257\n",
            "step 20678 - loss 22.09828758239746 - moving ave loss 21.78550947820106\n",
            "step 20679 - loss 22.23069953918457 - moving ave loss 21.83002848429941\n",
            "step 20680 - loss 19.97174835205078 - moving ave loss 21.64420047107455\n",
            "step 20681 - loss 22.89207649230957 - moving ave loss 21.768988073198052\n",
            "step 20682 - loss 18.734272003173828 - moving ave loss 21.46551646619563\n",
            "step 20683 - loss 23.416364669799805 - moving ave loss 21.660601286556048\n",
            "step 20684 - loss 18.965795516967773 - moving ave loss 21.39112070959722\n",
            "step 20685 - loss 22.39366340637207 - moving ave loss 21.491374979274706\n",
            "step 20686 - loss 25.16758155822754 - moving ave loss 21.85899563716999\n",
            "step 20687 - loss 16.418121337890625 - moving ave loss 21.314908207242055\n",
            "step 20688 - loss 19.136945724487305 - moving ave loss 21.09711195896658\n",
            "step 20689 - loss 19.329978942871094 - moving ave loss 20.92039865735703\n",
            "step 20690 - loss 17.672758102416992 - moving ave loss 20.595634601863026\n",
            "step 20691 - loss 23.794981002807617 - moving ave loss 20.91556924195749\n",
            "step 20692 - loss 23.250749588012695 - moving ave loss 21.14908727656301\n",
            "step 20693 - loss 21.688182830810547 - moving ave loss 21.202996831987765\n",
            "step 20694 - loss 17.102174758911133 - moving ave loss 20.7929146246801\n",
            "step 20695 - loss 25.635623931884766 - moving ave loss 21.277185555400568\n",
            "step 20696 - loss 24.79454231262207 - moving ave loss 21.628921231122717\n",
            "step 20697 - loss 22.857072830200195 - moving ave loss 21.751736391030466\n",
            "step 20698 - loss 25.041799545288086 - moving ave loss 22.080742706456228\n",
            "step 20699 - loss 21.374176025390625 - moving ave loss 22.01008603834967\n",
            "step 20700 - loss 21.609272003173828 - moving ave loss 21.970004634832083\n",
            "step 20701 - loss 23.93501853942871 - moving ave loss 22.16650602529175\n",
            "step 20702 - loss 26.372957229614258 - moving ave loss 22.587151145724\n",
            "step 20703 - loss 19.76934051513672 - moving ave loss 22.305370082665274\n",
            "step 20704 - loss 20.999279022216797 - moving ave loss 22.174760976620426\n",
            "step 20705 - loss 23.42246437072754 - moving ave loss 22.299531316031135\n",
            "step 20706 - loss 20.256555557250977 - moving ave loss 22.09523374015312\n",
            "step 20707 - loss 22.963090896606445 - moving ave loss 22.182019455798454\n",
            "step 20708 - loss 19.72466468811035 - moving ave loss 21.936283979029643\n",
            "step 20709 - loss 17.723194122314453 - moving ave loss 21.514974993358127\n",
            "step 20710 - loss 22.864606857299805 - moving ave loss 21.649938179752297\n",
            "step 20711 - loss 17.64046287536621 - moving ave loss 21.24899064931369\n",
            "step 20712 - loss 20.41851043701172 - moving ave loss 21.165942628083492\n",
            "step 20713 - loss 19.071508407592773 - moving ave loss 20.956499206034422\n",
            "step 20714 - loss 23.443843841552734 - moving ave loss 21.205233669586253\n",
            "step 20715 - loss 22.3571834564209 - moving ave loss 21.32042864826972\n",
            "step 20716 - loss 22.17619514465332 - moving ave loss 21.40600529790808\n",
            "step 20717 - loss 23.642568588256836 - moving ave loss 21.62966162694296\n",
            "step 20718 - loss 25.061643600463867 - moving ave loss 21.97285982429505\n",
            "step 20719 - loss 22.157588958740234 - moving ave loss 21.99133273773957\n",
            "step 20720 - loss 18.36039924621582 - moving ave loss 21.628239388587193\n",
            "step 20721 - loss 26.934038162231445 - moving ave loss 22.15881926595162\n",
            "step 20722 - loss 23.19608497619629 - moving ave loss 22.262545836976088\n",
            "step 20723 - loss 19.941280364990234 - moving ave loss 22.030419289777505\n",
            "step 20724 - loss 20.09813690185547 - moving ave loss 21.8371910509853\n",
            "step 20725 - loss 25.22144317626953 - moving ave loss 22.175616263513724\n",
            "step 20726 - loss 17.94724464416504 - moving ave loss 21.752779101578856\n",
            "step 20727 - loss 21.079612731933594 - moving ave loss 21.685462464614332\n",
            "step 20728 - loss 21.1584529876709 - moving ave loss 21.63276151691999\n",
            "step 20729 - loss 20.571779251098633 - moving ave loss 21.526663290337854\n",
            "step 20730 - loss 23.411174774169922 - moving ave loss 21.715114438721063\n",
            "step 20731 - loss 23.510740280151367 - moving ave loss 21.894677022864094\n",
            "step 20732 - loss 17.934879302978516 - moving ave loss 21.498697250875537\n",
            "step 20733 - loss 20.796852111816406 - moving ave loss 21.428512736969626\n",
            "step 20734 - loss 20.98543357849121 - moving ave loss 21.384204821121784\n",
            "step 20735 - loss 18.930810928344727 - moving ave loss 21.138865431844078\n",
            "step 20736 - loss 23.54275131225586 - moving ave loss 21.379254019885256\n",
            "step 20737 - loss 16.172149658203125 - moving ave loss 20.858543583717044\n",
            "step 20738 - loss 24.14853286743164 - moving ave loss 21.187542512088502\n",
            "step 20739 - loss 25.817556381225586 - moving ave loss 21.650543899002212\n",
            "step 20740 - loss 23.32914924621582 - moving ave loss 21.818404433723575\n",
            "step 20741 - loss 25.811351776123047 - moving ave loss 22.217699167963524\n",
            "step 20742 - loss 25.35479164123535 - moving ave loss 22.53140841529071\n",
            "step 20743 - loss 19.250606536865234 - moving ave loss 22.20332822744816\n",
            "step 20744 - loss 27.07318115234375 - moving ave loss 22.69031351993772\n",
            "step 20745 - loss 24.143070220947266 - moving ave loss 22.835589190038675\n",
            "step 20746 - loss 22.81653594970703 - moving ave loss 22.83368386600551\n",
            "step 20747 - loss 20.869617462158203 - moving ave loss 22.63727722562078\n",
            "step 20748 - loss 24.049488067626953 - moving ave loss 22.7784983098214\n",
            "step 20749 - loss 20.998680114746094 - moving ave loss 22.600516490313872\n",
            "step 20750 - loss 23.713642120361328 - moving ave loss 22.71182905331862\n",
            "step 20751 - loss 18.355802536010742 - moving ave loss 22.27622640158783\n",
            "step 20752 - loss 19.4974308013916 - moving ave loss 21.99834684156821\n",
            "step 20753 - loss 21.312685012817383 - moving ave loss 21.92978065869313\n",
            "step 20754 - loss 17.60163116455078 - moving ave loss 21.496965709278896\n",
            "step 20755 - loss 22.883718490600586 - moving ave loss 21.635640987411065\n",
            "step 20756 - loss 19.825010299682617 - moving ave loss 21.454577918638222\n",
            "step 20757 - loss 21.567792892456055 - moving ave loss 21.465899416020005\n",
            "step 20758 - loss 19.660709381103516 - moving ave loss 21.285380412528358\n",
            "step 20759 - loss 23.801307678222656 - moving ave loss 21.53697313909779\n",
            "step 20760 - loss 22.007333755493164 - moving ave loss 21.584009200737327\n",
            "step 20761 - loss 25.89276123046875 - moving ave loss 22.01488440371047\n",
            "step 20762 - loss 19.75572967529297 - moving ave loss 21.78896893086872\n",
            "step 20763 - loss 21.24506378173828 - moving ave loss 21.734578415955674\n",
            "step 20764 - loss 23.115137100219727 - moving ave loss 21.87263428438208\n",
            "step 20765 - loss 21.32659339904785 - moving ave loss 21.818030195848657\n",
            "step 20766 - loss 17.947246551513672 - moving ave loss 21.430951831415157\n",
            "step 20767 - loss 20.45880889892578 - moving ave loss 21.333737538166222\n",
            "step 20768 - loss 25.40883445739746 - moving ave loss 21.74124723008935\n",
            "step 20769 - loss 21.75704002380371 - moving ave loss 21.742826509460787\n",
            "Finish 13 epoch(es)\n",
            "step 20770 - loss 22.31947135925293 - moving ave loss 21.80049099444\n",
            "step 20771 - loss 20.06907081604004 - moving ave loss 21.627348976600008\n",
            "step 20772 - loss 29.062320709228516 - moving ave loss 22.370846149862857\n",
            "step 20773 - loss 16.379655838012695 - moving ave loss 21.77172711867784\n",
            "step 20774 - loss 22.00080680847168 - moving ave loss 21.794635087657227\n",
            "step 20775 - loss 22.109098434448242 - moving ave loss 21.82608142233633\n",
            "step 20776 - loss 21.78095245361328 - moving ave loss 21.821568525464023\n",
            "step 20777 - loss 23.034025192260742 - moving ave loss 21.942814192143697\n",
            "step 20778 - loss 20.944416046142578 - moving ave loss 21.842974377543584\n",
            "step 20779 - loss 19.383520126342773 - moving ave loss 21.597028952423504\n",
            "step 20780 - loss 18.178791046142578 - moving ave loss 21.25520516179541\n",
            "step 20781 - loss 22.59751319885254 - moving ave loss 21.38943596550112\n",
            "step 20782 - loss 17.848966598510742 - moving ave loss 21.035389028802086\n",
            "step 20783 - loss 30.49049949645996 - moving ave loss 21.980900075567877\n",
            "step 20784 - loss 25.308252334594727 - moving ave loss 22.313635301470566\n",
            "step 20785 - loss 20.37649917602539 - moving ave loss 22.11992168892605\n",
            "step 20786 - loss 16.68225860595703 - moving ave loss 21.57615538062915\n",
            "step 20787 - loss 20.124393463134766 - moving ave loss 21.430979188879714\n",
            "step 20788 - loss 20.815706253051758 - moving ave loss 21.36945189529692\n",
            "step 20789 - loss 19.90022087097168 - moving ave loss 21.222528792864395\n",
            "step 20790 - loss 25.739654541015625 - moving ave loss 21.67424136767952\n",
            "step 20791 - loss 23.082592010498047 - moving ave loss 21.815076431961373\n",
            "step 20792 - loss 24.191104888916016 - moving ave loss 22.052679277656836\n",
            "step 20793 - loss 24.97504234313965 - moving ave loss 22.34491558420512\n",
            "step 20794 - loss 20.292659759521484 - moving ave loss 22.139690001736756\n",
            "step 20795 - loss 24.28227996826172 - moving ave loss 22.353948998389253\n",
            "step 20796 - loss 16.102460861206055 - moving ave loss 21.72880018467093\n",
            "step 20797 - loss 14.708438873291016 - moving ave loss 21.02676405353294\n",
            "step 20798 - loss 17.995485305786133 - moving ave loss 20.72363617875826\n",
            "Checkpoint at step 20798\n",
            "step 20799 - loss 22.619232177734375 - moving ave loss 20.91319577865587\n",
            "step 20800 - loss 19.5015869140625 - moving ave loss 20.772034892196533\n",
            "step 20801 - loss 23.147069931030273 - moving ave loss 21.009538396079908\n",
            "step 20802 - loss 21.05314826965332 - moving ave loss 21.013899383437252\n",
            "step 20803 - loss 27.229061126708984 - moving ave loss 21.635415557764425\n",
            "step 20804 - loss 21.69864845275879 - moving ave loss 21.641738847263863\n",
            "step 20805 - loss 22.549243927001953 - moving ave loss 21.732489355237675\n",
            "step 20806 - loss 16.973712921142578 - moving ave loss 21.256611711828167\n",
            "step 20807 - loss 24.549936294555664 - moving ave loss 21.585944170100916\n",
            "step 20808 - loss 23.372724533081055 - moving ave loss 21.764622206398933\n",
            "step 20809 - loss 20.478870391845703 - moving ave loss 21.63604702494361\n",
            "step 20810 - loss 21.541379928588867 - moving ave loss 21.626580315308136\n",
            "step 20811 - loss 22.904102325439453 - moving ave loss 21.754332516321266\n",
            "step 20812 - loss 18.896883010864258 - moving ave loss 21.468587565775568\n",
            "step 20813 - loss 22.006750106811523 - moving ave loss 21.522403819879163\n",
            "step 20814 - loss 19.767311096191406 - moving ave loss 21.346894547510388\n",
            "step 20815 - loss 23.903919219970703 - moving ave loss 21.602597014756423\n",
            "step 20816 - loss 22.13409423828125 - moving ave loss 21.655746737108906\n",
            "step 20817 - loss 22.05967903137207 - moving ave loss 21.696139966535224\n",
            "step 20818 - loss 20.982948303222656 - moving ave loss 21.62482080020397\n",
            "step 20819 - loss 19.296512603759766 - moving ave loss 21.39198998055955\n",
            "step 20820 - loss 18.334524154663086 - moving ave loss 21.086243397969906\n",
            "step 20821 - loss 24.179616928100586 - moving ave loss 21.395580750982976\n",
            "step 20822 - loss 24.115503311157227 - moving ave loss 21.667573007000403\n",
            "step 20823 - loss 19.122468948364258 - moving ave loss 21.413062601136787\n",
            "step 20824 - loss 23.209922790527344 - moving ave loss 21.592748620075845\n",
            "step 20825 - loss 23.71329689025879 - moving ave loss 21.804803447094137\n",
            "step 20826 - loss 18.827526092529297 - moving ave loss 21.507075711637654\n",
            "step 20827 - loss 21.11783790588379 - moving ave loss 21.46815193106227\n",
            "step 20828 - loss 16.167490005493164 - moving ave loss 20.938085738505357\n",
            "step 20829 - loss 24.246597290039062 - moving ave loss 21.26893689365873\n",
            "step 20830 - loss 21.937049865722656 - moving ave loss 21.33574819086512\n",
            "step 20831 - loss 20.327322006225586 - moving ave loss 21.234905572401168\n",
            "step 20832 - loss 24.458751678466797 - moving ave loss 21.55729018300773\n",
            "step 20833 - loss 21.115358352661133 - moving ave loss 21.513096999973072\n",
            "step 20834 - loss 21.723112106323242 - moving ave loss 21.53409851060809\n",
            "step 20835 - loss 17.478052139282227 - moving ave loss 21.128493873475506\n",
            "step 20836 - loss 21.116640090942383 - moving ave loss 21.127308495222195\n",
            "step 20837 - loss 22.541831970214844 - moving ave loss 21.26876084272146\n",
            "step 20838 - loss 21.636953353881836 - moving ave loss 21.3055800938375\n",
            "step 20839 - loss 17.08333969116211 - moving ave loss 20.883356053569962\n",
            "step 20840 - loss 21.281787872314453 - moving ave loss 20.92319923544441\n",
            "step 20841 - loss 22.72995376586914 - moving ave loss 21.103874688486883\n",
            "step 20842 - loss 22.097517013549805 - moving ave loss 21.203238920993176\n",
            "step 20843 - loss 26.00722312927246 - moving ave loss 21.683637341821104\n",
            "step 20844 - loss 20.59575653076172 - moving ave loss 21.57484926071517\n",
            "step 20845 - loss 18.747095108032227 - moving ave loss 21.292073845446875\n",
            "step 20846 - loss 23.616474151611328 - moving ave loss 21.52451387606332\n",
            "step 20847 - loss 23.122623443603516 - moving ave loss 21.684324832817342\n",
            "step 20848 - loss 25.87527847290039 - moving ave loss 22.10342019682565\n",
            "step 20849 - loss 27.302949905395508 - moving ave loss 22.623373167682637\n",
            "step 20850 - loss 22.494897842407227 - moving ave loss 22.610525635155096\n",
            "step 20851 - loss 22.40218734741211 - moving ave loss 22.5896918063808\n",
            "step 20852 - loss 20.91246223449707 - moving ave loss 22.421968849192428\n",
            "step 20853 - loss 16.86590576171875 - moving ave loss 21.86636254044506\n",
            "step 20854 - loss 19.374324798583984 - moving ave loss 21.617158766258953\n",
            "step 20855 - loss 26.562971115112305 - moving ave loss 22.11174000114429\n",
            "step 20856 - loss 23.22337532043457 - moving ave loss 22.222903533073318\n",
            "step 20857 - loss 22.420169830322266 - moving ave loss 22.24263016279821\n",
            "step 20858 - loss 26.61767578125 - moving ave loss 22.68013472464339\n",
            "step 20859 - loss 21.43995475769043 - moving ave loss 22.556116727948094\n",
            "step 20860 - loss 22.983686447143555 - moving ave loss 22.59887369986764\n",
            "step 20861 - loss 25.23792266845703 - moving ave loss 22.862778596726578\n",
            "step 20862 - loss 20.740854263305664 - moving ave loss 22.650586163384485\n",
            "step 20863 - loss 17.54285430908203 - moving ave loss 22.139812977954243\n",
            "step 20864 - loss 18.544227600097656 - moving ave loss 21.780254440168584\n",
            "step 20865 - loss 19.137311935424805 - moving ave loss 21.51596018969421\n",
            "step 20866 - loss 20.65042495727539 - moving ave loss 21.429406666452326\n",
            "step 20867 - loss 19.909456253051758 - moving ave loss 21.277411625112272\n",
            "step 20868 - loss 21.631393432617188 - moving ave loss 21.312809805862763\n",
            "step 20869 - loss 22.777271270751953 - moving ave loss 21.459255952351683\n",
            "step 20870 - loss 20.436342239379883 - moving ave loss 21.356964581054505\n",
            "step 20871 - loss 18.060718536376953 - moving ave loss 21.027339976586752\n",
            "step 20872 - loss 18.45697593688965 - moving ave loss 20.770303572617042\n",
            "step 20873 - loss 26.061668395996094 - moving ave loss 21.299440054954946\n",
            "step 20874 - loss 21.799497604370117 - moving ave loss 21.349445809896462\n",
            "step 20875 - loss 21.485727310180664 - moving ave loss 21.363073959924883\n",
            "step 20876 - loss 23.161916732788086 - moving ave loss 21.542958237211202\n",
            "step 20877 - loss 20.74193572998047 - moving ave loss 21.46285598648813\n",
            "step 20878 - loss 22.610681533813477 - moving ave loss 21.577638541220665\n",
            "step 20879 - loss 19.998355865478516 - moving ave loss 21.41971027364645\n",
            "step 20880 - loss 23.212677001953125 - moving ave loss 21.59900694647712\n",
            "step 20881 - loss 21.924007415771484 - moving ave loss 21.63150699340656\n",
            "step 20882 - loss 20.676286697387695 - moving ave loss 21.535984963804676\n",
            "step 20883 - loss 19.056947708129883 - moving ave loss 21.288081238237197\n",
            "step 20884 - loss 25.347476959228516 - moving ave loss 21.69402081033633\n",
            "step 20885 - loss 22.38958168029785 - moving ave loss 21.763576897332484\n",
            "step 20886 - loss 19.780073165893555 - moving ave loss 21.565226524188592\n",
            "step 20887 - loss 23.91390037536621 - moving ave loss 21.800093909306355\n",
            "step 20888 - loss 24.44409942626953 - moving ave loss 22.064494461002674\n",
            "step 20889 - loss 19.834867477416992 - moving ave loss 21.84153176264411\n",
            "step 20890 - loss 20.048248291015625 - moving ave loss 21.66220341548126\n",
            "step 20891 - loss 18.556663513183594 - moving ave loss 21.351649425251495\n",
            "step 20892 - loss 19.53938865661621 - moving ave loss 21.170423348387967\n",
            "step 20893 - loss 20.57416343688965 - moving ave loss 21.110797357238134\n",
            "step 20894 - loss 21.824649810791016 - moving ave loss 21.18218260259342\n",
            "step 20895 - loss 20.579885482788086 - moving ave loss 21.12195289061289\n",
            "step 20896 - loss 20.783008575439453 - moving ave loss 21.088058459095546\n",
            "step 20897 - loss 15.279394149780273 - moving ave loss 20.50719202816402\n",
            "step 20898 - loss 19.247377395629883 - moving ave loss 20.381210564910607\n",
            "step 20899 - loss 27.595027923583984 - moving ave loss 21.102592300777943\n",
            "step 20900 - loss 27.27419662475586 - moving ave loss 21.719752733175735\n",
            "step 20901 - loss 22.705596923828125 - moving ave loss 21.81833715224097\n",
            "step 20902 - loss 21.663787841796875 - moving ave loss 21.802882221196562\n",
            "step 20903 - loss 16.85310935974121 - moving ave loss 21.307904935051027\n",
            "step 20904 - loss 20.859621047973633 - moving ave loss 21.26307654634329\n",
            "step 20905 - loss 17.522308349609375 - moving ave loss 20.888999726669898\n",
            "step 20906 - loss 28.568681716918945 - moving ave loss 21.6569679256948\n",
            "step 20907 - loss 22.117807388305664 - moving ave loss 21.703051871955886\n",
            "step 20908 - loss 24.028154373168945 - moving ave loss 21.935562122077194\n",
            "step 20909 - loss 20.35114288330078 - moving ave loss 21.777120198199555\n",
            "step 20910 - loss 26.14197540283203 - moving ave loss 22.213605718662805\n",
            "step 20911 - loss 21.07761001586914 - moving ave loss 22.10000614838344\n",
            "Finish 14 epoch(es)\n",
            "step 20912 - loss 21.700077056884766 - moving ave loss 22.060013239233573\n",
            "step 20913 - loss 20.06636619567871 - moving ave loss 21.860648534878088\n",
            "step 20914 - loss 20.123321533203125 - moving ave loss 21.686915834710593\n",
            "step 20915 - loss 22.961484909057617 - moving ave loss 21.814372742145295\n",
            "step 20916 - loss 21.726863861083984 - moving ave loss 21.805621854039167\n",
            "step 20917 - loss 20.226783752441406 - moving ave loss 21.647738043879393\n",
            "step 20918 - loss 21.94623565673828 - moving ave loss 21.677587805165285\n",
            "step 20919 - loss 23.179672241210938 - moving ave loss 21.82779624876985\n",
            "step 20920 - loss 23.47685432434082 - moving ave loss 21.992702056326948\n",
            "step 20921 - loss 19.62249183654785 - moving ave loss 21.75568103434904\n",
            "step 20922 - loss 23.00664710998535 - moving ave loss 21.880777641912672\n",
            "step 20923 - loss 21.383981704711914 - moving ave loss 21.831098048192597\n",
            "Checkpoint at step 20923\n",
            "step 20924 - loss 21.381696701049805 - moving ave loss 21.786157913478316\n",
            "step 20925 - loss 23.7265567779541 - moving ave loss 21.980197799925897\n",
            "step 20926 - loss 22.507244110107422 - moving ave loss 22.032902430944052\n",
            "step 20927 - loss 18.226593017578125 - moving ave loss 21.65227148960746\n",
            "step 20928 - loss 24.558040618896484 - moving ave loss 21.942848402536363\n",
            "step 20929 - loss 24.47500228881836 - moving ave loss 22.196063791164562\n",
            "step 20930 - loss 21.29528045654297 - moving ave loss 22.105985457702403\n",
            "step 20931 - loss 17.619815826416016 - moving ave loss 21.657368494573767\n",
            "step 20932 - loss 19.32292366027832 - moving ave loss 21.423924011144223\n",
            "step 20933 - loss 25.70503807067871 - moving ave loss 21.852035417097674\n",
            "step 20934 - loss 19.0828857421875 - moving ave loss 21.575120449606658\n",
            "step 20935 - loss 18.10497283935547 - moving ave loss 21.22810568858154\n",
            "step 20936 - loss 20.25786590576172 - moving ave loss 21.131081710299558\n",
            "step 20937 - loss 22.471527099609375 - moving ave loss 21.265126249230537\n",
            "step 20938 - loss 24.339372634887695 - moving ave loss 21.572550887796254\n",
            "step 20939 - loss 23.76241683959961 - moving ave loss 21.79153748297659\n",
            "step 20940 - loss 19.10801124572754 - moving ave loss 21.523184859251685\n",
            "step 20941 - loss 27.913328170776367 - moving ave loss 22.162199190404156\n",
            "step 20942 - loss 17.195219039916992 - moving ave loss 21.665501175355438\n",
            "step 20943 - loss 18.404983520507812 - moving ave loss 21.339449409870674\n",
            "step 20944 - loss 14.761738777160645 - moving ave loss 20.68167834659967\n",
            "step 20945 - loss 22.278047561645508 - moving ave loss 20.841315268104257\n",
            "step 20946 - loss 23.946630477905273 - moving ave loss 21.15184678908436\n",
            "step 20947 - loss 21.869726181030273 - moving ave loss 21.223634728278952\n",
            "step 20948 - loss 21.79741668701172 - moving ave loss 21.28101292415223\n",
            "step 20949 - loss 21.98363494873047 - moving ave loss 21.35127512661005\n",
            "step 20950 - loss 21.201082229614258 - moving ave loss 21.336255836910475\n",
            "step 20951 - loss 20.158382415771484 - moving ave loss 21.21846849479658\n",
            "step 20952 - loss 21.215110778808594 - moving ave loss 21.218132723197783\n",
            "step 20953 - loss 21.34699821472168 - moving ave loss 21.231019272350174\n",
            "step 20954 - loss 19.06680679321289 - moving ave loss 21.01459802443645\n",
            "step 20955 - loss 27.012819290161133 - moving ave loss 21.614420151008915\n",
            "step 20956 - loss 18.773845672607422 - moving ave loss 21.330362703168763\n",
            "step 20957 - loss 19.515398025512695 - moving ave loss 21.14886623540316\n",
            "step 20958 - loss 16.86281394958496 - moving ave loss 20.72026100682134\n",
            "step 20959 - loss 29.265600204467773 - moving ave loss 21.574794926585984\n",
            "step 20960 - loss 25.028295516967773 - moving ave loss 21.920144985624162\n",
            "step 20961 - loss 25.65631103515625 - moving ave loss 22.293761590577372\n",
            "step 20962 - loss 22.338315963745117 - moving ave loss 22.298217027894147\n",
            "step 20963 - loss 22.714759826660156 - moving ave loss 22.339871307770746\n",
            "step 20964 - loss 23.490873336791992 - moving ave loss 22.454971510672873\n",
            "step 20965 - loss 20.229108810424805 - moving ave loss 22.232385240648068\n",
            "step 20966 - loss 20.973384857177734 - moving ave loss 22.106485202301034\n",
            "step 20967 - loss 19.9394588470459 - moving ave loss 21.889782566775523\n",
            "step 20968 - loss 21.175512313842773 - moving ave loss 21.818355541482248\n",
            "step 20969 - loss 19.746116638183594 - moving ave loss 21.61113165115238\n",
            "step 20970 - loss 18.598501205444336 - moving ave loss 21.309868606581574\n",
            "step 20971 - loss 21.54490852355957 - moving ave loss 21.33337259827937\n",
            "step 20972 - loss 21.64978790283203 - moving ave loss 21.36501412873464\n",
            "step 20973 - loss 19.663223266601562 - moving ave loss 21.19483504252133\n",
            "step 20974 - loss 23.045137405395508 - moving ave loss 21.379865278808747\n",
            "step 20975 - loss 19.68841552734375 - moving ave loss 21.21072030366225\n",
            "step 20976 - loss 18.736238479614258 - moving ave loss 20.96327212125745\n",
            "step 20977 - loss 19.521066665649414 - moving ave loss 20.819051575696648\n",
            "step 20978 - loss 24.8422908782959 - moving ave loss 21.221375505956573\n",
            "step 20979 - loss 29.149560928344727 - moving ave loss 22.01419404819539\n",
            "step 20980 - loss 25.47610092163086 - moving ave loss 22.360384735538936\n",
            "step 20981 - loss 24.720083236694336 - moving ave loss 22.596354585654478\n",
            "step 20982 - loss 23.604473114013672 - moving ave loss 22.697166438490395\n",
            "step 20983 - loss 25.949996948242188 - moving ave loss 23.022449489465572\n",
            "step 20984 - loss 17.871572494506836 - moving ave loss 22.5073617899697\n",
            "step 20985 - loss 25.79475212097168 - moving ave loss 22.8361008230699\n",
            "step 20986 - loss 20.3829288482666 - moving ave loss 22.59078362558957\n",
            "step 20987 - loss 19.9518985748291 - moving ave loss 22.326895120513523\n",
            "step 20988 - loss 22.211042404174805 - moving ave loss 22.315309848879654\n",
            "step 20989 - loss 21.43372344970703 - moving ave loss 22.227151208962393\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQ1NcSuQWuTU",
        "outputId": "7e80bf6f-548e-4ae9-f4b8-072332c3cf04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3539
        }
      },
      "source": [
        "!flow --model cfg/yolov2-vocmine.cfg --load 18548 --savepb\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Parsing cfg/yolov2-vocmine.cfg\n",
            "Loading None ...\n",
            "Finished in 0.0001494884490966797s\n",
            "\n",
            "Building net ...\n",
            "Source | Train? | Layer description                | Output size\n",
            "-------+--------+----------------------------------+---------------\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "       |        | input                            | (?, 416, 416, 3)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 416, 416, 32)\n",
            " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 208, 208, 32)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 208, 208, 64)\n",
            " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 104, 104, 64)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 104, 104, 128)\n",
            " Init  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 104, 104, 64)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 104, 104, 128)\n",
            " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 52, 52, 128)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 52, 52, 256)\n",
            " Init  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 52, 52, 128)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 52, 52, 256)\n",
            " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 26, 26, 256)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 26, 26, 512)\n",
            " Init  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 26, 26, 256)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 26, 26, 512)\n",
            " Init  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 26, 26, 256)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 26, 26, 512)\n",
            " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 13, 13, 512)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 13, 13, 1024)\n",
            " Init  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 13, 13, 512)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 13, 13, 1024)\n",
            " Init  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 13, 13, 512)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 13, 13, 1024)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 13, 13, 1024)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 13, 13, 1024)\n",
            " Load  |  Yep!  | concat [16]                      | (?, 26, 26, 512)\n",
            " Init  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 26, 26, 64)\n",
            " Load  |  Yep!  | local flatten 2x2                | (?, 13, 13, 256)\n",
            " Load  |  Yep!  | concat [27, 24]                  | (?, 13, 13, 1280)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 13, 13, 1024)\n",
            " Init  |  Yep!  | conv 1x1p0_1    linear           | (?, 13, 13, 30)\n",
            "-------+--------+----------------------------------+---------------\n",
            "Running entirely on CPU\n",
            "2019-04-19 11:29:25.782285: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2019-04-19 11:29:25.782561: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x30535a0 executing computations on platform Host. Devices:\n",
            "2019-04-19 11:29:25.782594: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2019-04-19 11:29:25.965131: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-04-19 11:29:25.965657: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x30532e0 executing computations on platform CUDA. Devices:\n",
            "2019-04-19 11:29:25.965688: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2019-04-19 11:29:25.965874: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-04-19 11:29:25.965891: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      \n",
            "Loading from ./ckpt/yolov2-vocmine-18548\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "2019-04-19 11:29:28.225329: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "totalMemory: 14.73GiB freeMemory: 14.60GiB\n",
            "2019-04-19 11:29:28.225399: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n",
            "2019-04-19 11:29:28.668777: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-04-19 11:29:28.668856: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n",
            "2019-04-19 11:29:28.668877: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n",
            "2019-04-19 11:29:28.669133: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2019-04-19 11:29:28.669185: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14115 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "Resolving old graph def ./ckpt/yolov2-vocmine-18548 (no guarantee)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1334, in _do_call\n",
            "    return fn(*args)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1319, in _run_fn\n",
            "    options, feed_dict, fetch_list, target_list, run_metadata)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1407, in _call_tf_sessionrun\n",
            "    run_metadata)\n",
            "tensorflow.python.framework.errors_impl.InvalidArgumentError: Assign requires shapes of both tensors to match. lhs shape= [30] rhs shape= [75]\n",
            "\t [[{{node save/Assign_100}}]]\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 1276, in restore\n",
            "    {self.saver_def.filename_tensor_name: save_path})\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 929, in run\n",
            "    run_metadata_ptr)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1152, in _run\n",
            "    feed_dict_tensor, options, run_metadata)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1328, in _do_run\n",
            "    run_metadata)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1348, in _do_call\n",
            "    raise type(e)(node_def, op, message)\n",
            "tensorflow.python.framework.errors_impl.InvalidArgumentError: Assign requires shapes of both tensors to match. lhs shape= [30] rhs shape= [75]\n",
            "\t [[node save/Assign_100 (defined at /content/drive/My Drive/darkflow/darkflow/net/build.py:150) ]]\n",
            "\n",
            "Caused by op 'save/Assign_100', defined at:\n",
            "  File \"/usr/local/bin/flow\", line 7, in <module>\n",
            "    exec(compile(f.read(), __file__, 'exec'))\n",
            "  File \"/content/drive/My Drive/darkflow/flow\", line 6, in <module>\n",
            "    cliHandler(sys.argv)\n",
            "  File \"/content/drive/My Drive/darkflow/darkflow/cli.py\", line 26, in cliHandler\n",
            "    tfnet = TFNet(FLAGS)\n",
            "  File \"/content/drive/My Drive/darkflow/darkflow/net/build.py\", line 76, in __init__\n",
            "    self.setup_meta_ops()\n",
            "  File \"/content/drive/My Drive/darkflow/darkflow/net/build.py\", line 150, in setup_meta_ops\n",
            "    max_to_keep = self.FLAGS.keep)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 832, in __init__\n",
            "    self.build()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 844, in build\n",
            "    self._build(self._filename, build_save=True, build_restore=True)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 881, in _build\n",
            "    build_save=build_save, build_restore=build_restore)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 513, in _build_internal\n",
            "    restore_sequentially, reshape)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 354, in _AddRestoreOps\n",
            "    assign_ops.append(saveable.restore(saveable_tensors, shapes))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saving/saveable_object_util.py\", line 73, in restore\n",
            "    self.op.get_shape().is_fully_defined())\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/state_ops.py\", line 223, in assign\n",
            "    validate_shape=validate_shape)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_state_ops.py\", line 64, in assign\n",
            "    use_locking=use_locking, name=name)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n",
            "    op_def=op_def)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n",
            "    op_def=op_def)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n",
            "    self._traceback = tf_stack.extract_stack()\n",
            "\n",
            "InvalidArgumentError (see above for traceback): Assign requires shapes of both tensors to match. lhs shape= [30] rhs shape= [75]\n",
            "\t [[node save/Assign_100 (defined at /content/drive/My Drive/darkflow/darkflow/net/build.py:150) ]]\n",
            "\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/My Drive/darkflow/darkflow/net/help.py\", line 33, in load_from_ckpt\n",
            "    try: self.saver.restore(self.sess, load_point)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 1312, in restore\n",
            "    err, \"a mismatch between the current graph and the graph\")\n",
            "tensorflow.python.framework.errors_impl.InvalidArgumentError: Restoring from checkpoint failed. This is most likely due to a mismatch between the current graph and the graph from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n",
            "\n",
            "Assign requires shapes of both tensors to match. lhs shape= [30] rhs shape= [75]\n",
            "\t [[node save/Assign_100 (defined at /content/drive/My Drive/darkflow/darkflow/net/build.py:150) ]]\n",
            "\n",
            "Caused by op 'save/Assign_100', defined at:\n",
            "  File \"/usr/local/bin/flow\", line 7, in <module>\n",
            "    exec(compile(f.read(), __file__, 'exec'))\n",
            "  File \"/content/drive/My Drive/darkflow/flow\", line 6, in <module>\n",
            "    cliHandler(sys.argv)\n",
            "  File \"/content/drive/My Drive/darkflow/darkflow/cli.py\", line 26, in cliHandler\n",
            "    tfnet = TFNet(FLAGS)\n",
            "  File \"/content/drive/My Drive/darkflow/darkflow/net/build.py\", line 76, in __init__\n",
            "    self.setup_meta_ops()\n",
            "  File \"/content/drive/My Drive/darkflow/darkflow/net/build.py\", line 150, in setup_meta_ops\n",
            "    max_to_keep = self.FLAGS.keep)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 832, in __init__\n",
            "    self.build()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 844, in build\n",
            "    self._build(self._filename, build_save=True, build_restore=True)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 881, in _build\n",
            "    build_save=build_save, build_restore=build_restore)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 513, in _build_internal\n",
            "    restore_sequentially, reshape)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 354, in _AddRestoreOps\n",
            "    assign_ops.append(saveable.restore(saveable_tensors, shapes))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saving/saveable_object_util.py\", line 73, in restore\n",
            "    self.op.get_shape().is_fully_defined())\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/state_ops.py\", line 223, in assign\n",
            "    validate_shape=validate_shape)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_state_ops.py\", line 64, in assign\n",
            "    use_locking=use_locking, name=name)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n",
            "    op_def=op_def)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n",
            "    op_def=op_def)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n",
            "    self._traceback = tf_stack.extract_stack()\n",
            "\n",
            "InvalidArgumentError (see above for traceback): Restoring from checkpoint failed. This is most likely due to a mismatch between the current graph and the graph from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n",
            "\n",
            "Assign requires shapes of both tensors to match. lhs shape= [30] rhs shape= [75]\n",
            "\t [[node save/Assign_100 (defined at /content/drive/My Drive/darkflow/darkflow/net/build.py:150) ]]\n",
            "\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/flow\", line 7, in <module>\n",
            "    exec(compile(f.read(), __file__, 'exec'))\n",
            "  File \"/content/drive/My Drive/darkflow/flow\", line 6, in <module>\n",
            "    cliHandler(sys.argv)\n",
            "  File \"/content/drive/My Drive/darkflow/darkflow/cli.py\", line 26, in cliHandler\n",
            "    tfnet = TFNet(FLAGS)\n",
            "  File \"/content/drive/My Drive/darkflow/darkflow/net/build.py\", line 76, in __init__\n",
            "    self.setup_meta_ops()\n",
            "  File \"/content/drive/My Drive/darkflow/darkflow/net/build.py\", line 151, in setup_meta_ops\n",
            "    if self.FLAGS.load != 0: self.load_from_ckpt()\n",
            "  File \"/content/drive/My Drive/darkflow/darkflow/net/help.py\", line 34, in load_from_ckpt\n",
            "    except: load_old_graph(self, load_point)\n",
            "  File \"/content/drive/My Drive/darkflow/darkflow/net/help.py\", line 53, in load_old_graph\n",
            "    'Cannot find and load {}'.format(var.name)\n",
            "AssertionError: Cannot find and load 52-convolutional/biases:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQHHjBDRW5hO",
        "outputId": "ff02724b-5a66-49b0-dacc-562fd2eb3521",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "annorick  cfg\t    darkflow.egg-info  images\t   preview.png\tsetup.py\n",
            "bin\t  ckpt\t    demo.gif\t       labels.txt  README.md\ttest\n",
            "build\t  darkflow  flow\t       LICENSE\t   sample_img\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u87mZsIsbe1_",
        "outputId": "8af6c2f8-c9e1-422f-d23a-2ddd0c2304d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd darkflow/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/darkflow\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nl7BdZVMbj2H",
        "outputId": "87c8b8ef-a169-4fd9-9905-43038af42d00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4066
        }
      },
      "source": [
        "!flow --model cfg/yolov2-vocmine.cfg --load 19298 --train --annotation annorick/ --dataset images/ --gpu 1.0 "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Parsing cfg/yolov2-vocmine.cfg\n",
            "Loading None ...\n",
            "Finished in 0.00016570091247558594s\n",
            "\n",
            "Building net ...\n",
            "Source | Train? | Layer description                | Output size\n",
            "-------+--------+----------------------------------+---------------\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "       |        | input                            | (?, 416, 416, 3)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 416, 416, 32)\n",
            " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 208, 208, 32)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 208, 208, 64)\n",
            " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 104, 104, 64)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 104, 104, 128)\n",
            " Init  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 104, 104, 64)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 104, 104, 128)\n",
            " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 52, 52, 128)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 52, 52, 256)\n",
            " Init  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 52, 52, 128)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 52, 52, 256)\n",
            " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 26, 26, 256)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 26, 26, 512)\n",
            " Init  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 26, 26, 256)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 26, 26, 512)\n",
            " Init  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 26, 26, 256)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 26, 26, 512)\n",
            " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 13, 13, 512)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 13, 13, 1024)\n",
            " Init  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 13, 13, 512)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 13, 13, 1024)\n",
            " Init  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 13, 13, 512)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 13, 13, 1024)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 13, 13, 1024)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 13, 13, 1024)\n",
            " Load  |  Yep!  | concat [16]                      | (?, 26, 26, 512)\n",
            " Load  |  Yep!  | local flatten 2x2                | (?, 13, 13, 2048)\n",
            " Load  |  Yep!  | concat [26, 24]                  | (?, 13, 13, 3072)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 13, 13, 1024)\n",
            " Init  |  Yep!  | conv 1x1p0_1    linear           | (?, 13, 13, 30)\n",
            "-------+--------+----------------------------------+---------------\n",
            "GPU mode with 1.0 usage\n",
            "cfg/yolov2-vocmine.cfg loss hyper-parameters:\n",
            "\tH       = 13\n",
            "\tW       = 13\n",
            "\tbox     = 5\n",
            "\tclasses = 1\n",
            "\tscales  = [1.0, 5.0, 1.0, 1.0]\n",
            "WARNING:tensorflow:From /content/drive/My Drive/darkflowwww/darkflow/net/yolov2/train.py:87: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Building cfg/yolov2-vocmine.cfg loss\n",
            "Building cfg/yolov2-vocmine.cfg train op\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "2019-05-05 10:01:36.491288: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2019-05-05 10:01:36.491646: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x2ed1180 executing computations on platform Host. Devices:\n",
            "2019-05-05 10:01:36.491682: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2019-05-05 10:01:36.684640: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-05-05 10:01:36.685234: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x2ed0ec0 executing computations on platform CUDA. Devices:\n",
            "2019-05-05 10:01:36.685272: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2019-05-05 10:01:36.685670: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "totalMemory: 14.73GiB freeMemory: 14.60GiB\n",
            "2019-05-05 10:01:36.685697: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n",
            "2019-05-05 10:01:37.036927: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-05-05 10:01:37.037024: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n",
            "2019-05-05 10:01:37.037037: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n",
            "2019-05-05 10:01:37.037288: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2019-05-05 10:01:37.037336: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15079 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "Loading from ./ckpt/yolov2-vocmine-19298\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "2019-05-05 10:01:42.286160: W tensorflow/core/framework/op_kernel.cc:1401] OP_REQUIRES failed at save_restore_v2_ops.cc:184 : Not found: Key 48-convolutional/biases not found in checkpoint\n",
            "2019-05-05 10:01:43.493371: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n",
            "2019-05-05 10:01:43.493446: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-05-05 10:01:43.493461: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n",
            "2019-05-05 10:01:43.493475: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n",
            "2019-05-05 10:01:43.493751: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15079 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "Resolving old graph def ./ckpt/yolov2-vocmine-19298 (no guarantee)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1334, in _do_call\n",
            "    return fn(*args)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1319, in _run_fn\n",
            "    options, feed_dict, fetch_list, target_list, run_metadata)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1407, in _call_tf_sessionrun\n",
            "    run_metadata)\n",
            "tensorflow.python.framework.errors_impl.NotFoundError: Key 48-convolutional/biases not found in checkpoint\n",
            "\t [[{{node save/RestoreV2}}]]\n",
            "\t [[{{node save/RestoreV2}}]]\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 1276, in restore\n",
            "    {self.saver_def.filename_tensor_name: save_path})\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 929, in run\n",
            "    run_metadata_ptr)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1152, in _run\n",
            "    feed_dict_tensor, options, run_metadata)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1328, in _do_run\n",
            "    run_metadata)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1348, in _do_call\n",
            "    raise type(e)(node_def, op, message)\n",
            "tensorflow.python.framework.errors_impl.NotFoundError: Key 48-convolutional/biases not found in checkpoint\n",
            "\t [[node save/RestoreV2 (defined at /content/drive/My Drive/darkflowwww/darkflow/net/build.py:150) ]]\n",
            "\t [[node save/RestoreV2 (defined at /content/drive/My Drive/darkflowwww/darkflow/net/build.py:150) ]]\n",
            "\n",
            "Caused by op 'save/RestoreV2', defined at:\n",
            "  File \"/usr/local/bin/flow\", line 7, in <module>\n",
            "    exec(compile(f.read(), __file__, 'exec'))\n",
            "  File \"/content/drive/My Drive/darkflowwww/flow\", line 6, in <module>\n",
            "    cliHandler(sys.argv)\n",
            "  File \"/content/drive/My Drive/darkflowwww/darkflow/cli.py\", line 26, in cliHandler\n",
            "    tfnet = TFNet(FLAGS)\n",
            "  File \"/content/drive/My Drive/darkflowwww/darkflow/net/build.py\", line 76, in __init__\n",
            "    self.setup_meta_ops()\n",
            "  File \"/content/drive/My Drive/darkflowwww/darkflow/net/build.py\", line 150, in setup_meta_ops\n",
            "    max_to_keep = self.FLAGS.keep)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 832, in __init__\n",
            "    self.build()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 844, in build\n",
            "    self._build(self._filename, build_save=True, build_restore=True)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 881, in _build\n",
            "    build_save=build_save, build_restore=build_restore)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 513, in _build_internal\n",
            "    restore_sequentially, reshape)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 332, in _AddRestoreOps\n",
            "    restore_sequentially)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 580, in bulk_restore\n",
            "    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_io_ops.py\", line 1572, in restore_v2\n",
            "    name=name)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n",
            "    op_def=op_def)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n",
            "    op_def=op_def)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n",
            "    self._traceback = tf_stack.extract_stack()\n",
            "\n",
            "NotFoundError (see above for traceback): Key 48-convolutional/biases not found in checkpoint\n",
            "\t [[node save/RestoreV2 (defined at /content/drive/My Drive/darkflowwww/darkflow/net/build.py:150) ]]\n",
            "\t [[node save/RestoreV2 (defined at /content/drive/My Drive/darkflowwww/darkflow/net/build.py:150) ]]\n",
            "\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 1286, in restore\n",
            "    names_to_keys = object_graph_key_mapping(save_path)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 1591, in object_graph_key_mapping\n",
            "    checkpointable.OBJECT_GRAPH_PROTO_KEY)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 370, in get_tensor\n",
            "    status)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/errors_impl.py\", line 528, in __exit__\n",
            "    c_api.TF_GetCode(self.status.status))\n",
            "tensorflow.python.framework.errors_impl.NotFoundError: Key _CHECKPOINTABLE_OBJECT_GRAPH not found in checkpoint\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/My Drive/darkflowwww/darkflow/net/help.py\", line 33, in load_from_ckpt\n",
            "    try: self.saver.restore(self.sess, load_point)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 1292, in restore\n",
            "    err, \"a Variable name or other graph key that is missing\")\n",
            "tensorflow.python.framework.errors_impl.NotFoundError: Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n",
            "\n",
            "Key 48-convolutional/biases not found in checkpoint\n",
            "\t [[node save/RestoreV2 (defined at /content/drive/My Drive/darkflowwww/darkflow/net/build.py:150) ]]\n",
            "\t [[node save/RestoreV2 (defined at /content/drive/My Drive/darkflowwww/darkflow/net/build.py:150) ]]\n",
            "\n",
            "Caused by op 'save/RestoreV2', defined at:\n",
            "  File \"/usr/local/bin/flow\", line 7, in <module>\n",
            "    exec(compile(f.read(), __file__, 'exec'))\n",
            "  File \"/content/drive/My Drive/darkflowwww/flow\", line 6, in <module>\n",
            "    cliHandler(sys.argv)\n",
            "  File \"/content/drive/My Drive/darkflowwww/darkflow/cli.py\", line 26, in cliHandler\n",
            "    tfnet = TFNet(FLAGS)\n",
            "  File \"/content/drive/My Drive/darkflowwww/darkflow/net/build.py\", line 76, in __init__\n",
            "    self.setup_meta_ops()\n",
            "  File \"/content/drive/My Drive/darkflowwww/darkflow/net/build.py\", line 150, in setup_meta_ops\n",
            "    max_to_keep = self.FLAGS.keep)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 832, in __init__\n",
            "    self.build()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 844, in build\n",
            "    self._build(self._filename, build_save=True, build_restore=True)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 881, in _build\n",
            "    build_save=build_save, build_restore=build_restore)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 513, in _build_internal\n",
            "    restore_sequentially, reshape)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 332, in _AddRestoreOps\n",
            "    restore_sequentially)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 580, in bulk_restore\n",
            "    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_io_ops.py\", line 1572, in restore_v2\n",
            "    name=name)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n",
            "    op_def=op_def)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n",
            "    op_def=op_def)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n",
            "    self._traceback = tf_stack.extract_stack()\n",
            "\n",
            "NotFoundError (see above for traceback): Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n",
            "\n",
            "Key 48-convolutional/biases not found in checkpoint\n",
            "\t [[node save/RestoreV2 (defined at /content/drive/My Drive/darkflowwww/darkflow/net/build.py:150) ]]\n",
            "\t [[node save/RestoreV2 (defined at /content/drive/My Drive/darkflowwww/darkflow/net/build.py:150) ]]\n",
            "\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/flow\", line 7, in <module>\n",
            "    exec(compile(f.read(), __file__, 'exec'))\n",
            "  File \"/content/drive/My Drive/darkflowwww/flow\", line 6, in <module>\n",
            "    cliHandler(sys.argv)\n",
            "  File \"/content/drive/My Drive/darkflowwww/darkflow/cli.py\", line 26, in cliHandler\n",
            "    tfnet = TFNet(FLAGS)\n",
            "  File \"/content/drive/My Drive/darkflowwww/darkflow/net/build.py\", line 76, in __init__\n",
            "    self.setup_meta_ops()\n",
            "  File \"/content/drive/My Drive/darkflowwww/darkflow/net/build.py\", line 151, in setup_meta_ops\n",
            "    if self.FLAGS.load != 0: self.load_from_ckpt()\n",
            "  File \"/content/drive/My Drive/darkflowwww/darkflow/net/help.py\", line 34, in load_from_ckpt\n",
            "    except: load_old_graph(self, load_point)\n",
            "  File \"/content/drive/My Drive/darkflowwww/darkflow/net/help.py\", line 53, in load_old_graph\n",
            "    'Cannot find and load {}'.format(var.name)\n",
            "AssertionError: Cannot find and load 48-convolutional/biases:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQ1BohHwcN5d",
        "outputId": "3990be7b-6f35-4070-f07d-989aac424426",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 15575
        }
      },
      "source": [
        "!flow --model cfg/yolorick.cfg --load 658 --train --annotation SelectiveBDDnew/ --dataset SelectiveBDD/ --gpu 1.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Parsing cfg/yolorick.cfg\n",
            "Loading None ...\n",
            "Finished in 0.0001289844512939453s\n",
            "\n",
            "Building net ...\n",
            "Source | Train? | Layer description                | Output size\n",
            "-------+--------+----------------------------------+---------------\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "       |        | input                            | (?, 416, 416, 3)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 416, 416, 32)\n",
            " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 208, 208, 32)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 208, 208, 64)\n",
            " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 104, 104, 64)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 104, 104, 128)\n",
            " Init  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 104, 104, 64)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 104, 104, 128)\n",
            " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 52, 52, 128)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 52, 52, 256)\n",
            " Init  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 52, 52, 128)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 52, 52, 256)\n",
            " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 26, 26, 256)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 26, 26, 512)\n",
            " Init  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 26, 26, 256)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 26, 26, 512)\n",
            " Init  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 26, 26, 256)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 26, 26, 512)\n",
            " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 13, 13, 512)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 13, 13, 1024)\n",
            " Init  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 13, 13, 512)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 13, 13, 1024)\n",
            " Init  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 13, 13, 512)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 13, 13, 1024)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 13, 13, 1024)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 13, 13, 1024)\n",
            " Load  |  Yep!  | concat [16]                      | (?, 26, 26, 512)\n",
            " Init  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 26, 26, 64)\n",
            " Load  |  Yep!  | local flatten 2x2                | (?, 13, 13, 256)\n",
            " Load  |  Yep!  | concat [27, 24]                  | (?, 13, 13, 1280)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 13, 13, 1024)\n",
            " Init  |  Yep!  | conv 1x1p0_1    linear           | (?, 13, 13, 80)\n",
            "-------+--------+----------------------------------+---------------\n",
            "GPU mode with 1.0 usage\n",
            "cfg/yolorick.cfg loss hyper-parameters:\n",
            "\tH       = 13\n",
            "\tW       = 13\n",
            "\tbox     = 5\n",
            "\tclasses = 11\n",
            "\tscales  = [1.0, 5.0, 1.0, 1.0]\n",
            "WARNING:tensorflow:From /content/drive/My Drive/darkflow/darkflow/net/yolov2/train.py:87: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Building cfg/yolorick.cfg loss\n",
            "Building cfg/yolorick.cfg train op\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "2019-05-14 05:56:54.923486: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n",
            "2019-05-14 05:56:54.923779: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x36735a0 executing computations on platform Host. Devices:\n",
            "2019-05-14 05:56:54.923811: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2019-05-14 05:56:55.091441: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-05-14 05:56:55.091924: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x36732e0 executing computations on platform CUDA. Devices:\n",
            "2019-05-14 05:56:55.091953: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2019-05-14 05:56:55.092307: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "totalMemory: 14.73GiB freeMemory: 14.60GiB\n",
            "2019-05-14 05:56:55.092331: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n",
            "2019-05-14 05:56:55.450712: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-05-14 05:56:55.450770: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n",
            "2019-05-14 05:56:55.450785: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n",
            "2019-05-14 05:56:55.451069: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2019-05-14 05:56:55.451153: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15079 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "Loading from ./ckpt/yolorick-658\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "Finished in 15.241526365280151s\n",
            "\n",
            "Enter training ...\n",
            "\n",
            "cfg/yolorick.cfg parsing SelectiveBDDnew/\n",
            "Parsing for ['bus', 'traffic light', 'traffic sign', 'person', 'bike', 'truck', 'motor', 'car', 'train', 'rider', 'rickshaw'] \n",
            "[====================>]100%  627.xml\n",
            "Statistics:\n",
            "traffic light: 33\n",
            "traffic sign: 43\n",
            "car: 76\n",
            "bus: 6\n",
            "truck: 4\n",
            "bike: 6\n",
            "rider: 6\n",
            "person: 27\n",
            "motor: 7\n",
            "train: 1\n",
            "rickshaw: 10\n",
            "Dataset size: 13\n",
            "Dataset of 13 instance(s)\n",
            "Training statistics: \n",
            "\tLearning rate : 1e-05\n",
            "\tBatch size    : 13\n",
            "\tEpoch number  : 1000\n",
            "\tBackup every  : 2000\n",
            "step 659 - loss 8.48977279663086 - moving ave loss 8.48977279663086\n",
            "Finish 1 epoch(es)\n",
            "step 660 - loss 8.68228530883789 - moving ave loss 8.509024047851563\n",
            "Finish 2 epoch(es)\n",
            "step 661 - loss 9.364615440368652 - moving ave loss 8.594583187103272\n",
            "Finish 3 epoch(es)\n",
            "step 662 - loss 8.54239559173584 - moving ave loss 8.58936442756653\n",
            "Finish 4 epoch(es)\n",
            "step 663 - loss 9.17404556274414 - moving ave loss 8.647832541084291\n",
            "Finish 5 epoch(es)\n",
            "step 664 - loss 11.470593452453613 - moving ave loss 8.930108632221224\n",
            "Finish 6 epoch(es)\n",
            "step 665 - loss 9.191054344177246 - moving ave loss 8.956203203416827\n",
            "Finish 7 epoch(es)\n",
            "step 666 - loss 9.716897010803223 - moving ave loss 9.032272584155466\n",
            "Finish 8 epoch(es)\n",
            "step 667 - loss 9.15456485748291 - moving ave loss 9.04450181148821\n",
            "Finish 9 epoch(es)\n",
            "step 668 - loss 11.761378288269043 - moving ave loss 9.316189459166294\n",
            "Finish 10 epoch(es)\n",
            "step 669 - loss 8.91291618347168 - moving ave loss 9.275862131596833\n",
            "Finish 11 epoch(es)\n",
            "step 670 - loss 11.59244155883789 - moving ave loss 9.507520074320938\n",
            "Finish 12 epoch(es)\n",
            "step 671 - loss 9.319528579711914 - moving ave loss 9.488720924860036\n",
            "Finish 13 epoch(es)\n",
            "step 672 - loss 8.667912483215332 - moving ave loss 9.406640080695567\n",
            "Finish 14 epoch(es)\n",
            "step 673 - loss 8.45812702178955 - moving ave loss 9.311788774804967\n",
            "Finish 15 epoch(es)\n",
            "step 674 - loss 11.249371528625488 - moving ave loss 9.505547050187019\n",
            "Finish 16 epoch(es)\n",
            "step 675 - loss 8.363397598266602 - moving ave loss 9.391332104994978\n",
            "Finish 17 epoch(es)\n",
            "step 676 - loss 8.412690162658691 - moving ave loss 9.29346791076135\n",
            "Finish 18 epoch(es)\n",
            "step 677 - loss 10.197359085083008 - moving ave loss 9.383857028193516\n",
            "Finish 19 epoch(es)\n",
            "step 678 - loss 10.830924034118652 - moving ave loss 9.528563728786029\n",
            "Finish 20 epoch(es)\n",
            "step 679 - loss 7.930870532989502 - moving ave loss 9.368794409206377\n",
            "Finish 21 epoch(es)\n",
            "step 680 - loss 9.708491325378418 - moving ave loss 9.40276410082358\n",
            "Finish 22 epoch(es)\n",
            "step 681 - loss 8.4128999710083 - moving ave loss 9.303777687842052\n",
            "Finish 23 epoch(es)\n",
            "step 682 - loss 10.588460922241211 - moving ave loss 9.432246011281968\n",
            "Finish 24 epoch(es)\n",
            "step 683 - loss 8.118563652038574 - moving ave loss 9.300877775357629\n",
            "Finish 25 epoch(es)\n",
            "step 684 - loss 8.395190238952637 - moving ave loss 9.21030902171713\n",
            "Finish 26 epoch(es)\n",
            "step 685 - loss 10.211202621459961 - moving ave loss 9.310398381691412\n",
            "Finish 27 epoch(es)\n",
            "step 686 - loss 8.770760536193848 - moving ave loss 9.256434597141656\n",
            "Finish 28 epoch(es)\n",
            "step 687 - loss 10.697808265686035 - moving ave loss 9.400571963996095\n",
            "Finish 29 epoch(es)\n",
            "step 688 - loss 9.07949161529541 - moving ave loss 9.368463929126026\n",
            "Finish 30 epoch(es)\n",
            "step 689 - loss 9.026213645935059 - moving ave loss 9.334238900806929\n",
            "Finish 31 epoch(es)\n",
            "step 690 - loss 8.235478401184082 - moving ave loss 9.224362850844644\n",
            "Finish 32 epoch(es)\n",
            "step 691 - loss 10.130552291870117 - moving ave loss 9.314981794947192\n",
            "Finish 33 epoch(es)\n",
            "step 692 - loss 7.995649337768555 - moving ave loss 9.183048549229328\n",
            "Finish 34 epoch(es)\n",
            "step 693 - loss 10.417159080505371 - moving ave loss 9.306459602356933\n",
            "Finish 35 epoch(es)\n",
            "step 694 - loss 8.799321174621582 - moving ave loss 9.255745759583396\n",
            "Finish 36 epoch(es)\n",
            "step 695 - loss 8.423544883728027 - moving ave loss 9.172525671997859\n",
            "Finish 37 epoch(es)\n",
            "step 696 - loss 12.237469673156738 - moving ave loss 9.479020072113748\n",
            "Finish 38 epoch(es)\n",
            "step 697 - loss 10.59028148651123 - moving ave loss 9.590146213553497\n",
            "Finish 39 epoch(es)\n",
            "step 698 - loss 10.284076690673828 - moving ave loss 9.65953926126553\n",
            "Finish 40 epoch(es)\n",
            "step 699 - loss 11.560678482055664 - moving ave loss 9.849653183344545\n",
            "Finish 41 epoch(es)\n",
            "step 700 - loss 11.711873054504395 - moving ave loss 10.03587517046053\n",
            "Finish 42 epoch(es)\n",
            "step 701 - loss 8.953240394592285 - moving ave loss 9.927611692873706\n",
            "Finish 43 epoch(es)\n",
            "step 702 - loss 9.124316215515137 - moving ave loss 9.84728214513785\n",
            "Finish 44 epoch(es)\n",
            "step 703 - loss 7.9433441162109375 - moving ave loss 9.656888342245159\n",
            "Finish 45 epoch(es)\n",
            "step 704 - loss 9.056382179260254 - moving ave loss 9.596837725946669\n",
            "Finish 46 epoch(es)\n",
            "step 705 - loss 10.97911548614502 - moving ave loss 9.735065501966503\n",
            "Finish 47 epoch(es)\n",
            "step 706 - loss 8.993814468383789 - moving ave loss 9.660940398608233\n",
            "Finish 48 epoch(es)\n",
            "step 707 - loss 9.585299491882324 - moving ave loss 9.653376307935643\n",
            "Finish 49 epoch(es)\n",
            "step 708 - loss 7.577922344207764 - moving ave loss 9.445830911562854\n",
            "Finish 50 epoch(es)\n",
            "step 709 - loss 11.051036834716797 - moving ave loss 9.606351503878248\n",
            "Finish 51 epoch(es)\n",
            "step 710 - loss 9.682011604309082 - moving ave loss 9.613917513921331\n",
            "Finish 52 epoch(es)\n",
            "step 711 - loss 9.156105995178223 - moving ave loss 9.56813636204702\n",
            "Finish 53 epoch(es)\n",
            "step 712 - loss 9.049036979675293 - moving ave loss 9.516226423809849\n",
            "Finish 54 epoch(es)\n",
            "step 713 - loss 10.692798614501953 - moving ave loss 9.63388364287906\n",
            "Finish 55 epoch(es)\n",
            "step 714 - loss 10.086100578308105 - moving ave loss 9.679105336421966\n",
            "Finish 56 epoch(es)\n",
            "step 715 - loss 11.558073997497559 - moving ave loss 9.867002202529525\n",
            "Finish 57 epoch(es)\n",
            "step 716 - loss 8.928653717041016 - moving ave loss 9.773167353980673\n",
            "Finish 58 epoch(es)\n",
            "step 717 - loss 9.596293449401855 - moving ave loss 9.755479963522792\n",
            "Finish 59 epoch(es)\n",
            "step 718 - loss 10.549694061279297 - moving ave loss 9.834901373298441\n",
            "Finish 60 epoch(es)\n",
            "step 719 - loss 8.932784080505371 - moving ave loss 9.744689644019136\n",
            "Finish 61 epoch(es)\n",
            "step 720 - loss 6.436777591705322 - moving ave loss 9.413898438787756\n",
            "Finish 62 epoch(es)\n",
            "step 721 - loss 11.155681610107422 - moving ave loss 9.588076755919722\n",
            "Finish 63 epoch(es)\n",
            "step 722 - loss 9.160592079162598 - moving ave loss 9.54532828824401\n",
            "Finish 64 epoch(es)\n",
            "step 723 - loss 8.48767375946045 - moving ave loss 9.439562835365653\n",
            "Finish 65 epoch(es)\n",
            "step 724 - loss 10.050045013427734 - moving ave loss 9.50061105317186\n",
            "Finish 66 epoch(es)\n",
            "step 725 - loss 8.701019287109375 - moving ave loss 9.420651876565612\n",
            "Finish 67 epoch(es)\n",
            "step 726 - loss 8.116816520690918 - moving ave loss 9.290268340978143\n",
            "Finish 68 epoch(es)\n",
            "step 727 - loss 10.127809524536133 - moving ave loss 9.374022459333943\n",
            "Finish 69 epoch(es)\n",
            "step 728 - loss 6.371976375579834 - moving ave loss 9.073817850958534\n",
            "Finish 70 epoch(es)\n",
            "step 729 - loss 13.173556327819824 - moving ave loss 9.483791698644664\n",
            "Finish 71 epoch(es)\n",
            "step 730 - loss 10.521986961364746 - moving ave loss 9.587611224916673\n",
            "Finish 72 epoch(es)\n",
            "step 731 - loss 9.973599433898926 - moving ave loss 9.626210045814897\n",
            "Finish 73 epoch(es)\n",
            "step 732 - loss 8.556539535522461 - moving ave loss 9.519242994785653\n",
            "Finish 74 epoch(es)\n",
            "step 733 - loss 7.885502338409424 - moving ave loss 9.35586892914803\n",
            "Finish 75 epoch(es)\n",
            "step 734 - loss 10.163041114807129 - moving ave loss 9.43658614771394\n",
            "Finish 76 epoch(es)\n",
            "step 735 - loss 10.560212135314941 - moving ave loss 9.548948746474041\n",
            "Finish 77 epoch(es)\n",
            "step 736 - loss 10.485289573669434 - moving ave loss 9.64258282919358\n",
            "Finish 78 epoch(es)\n",
            "step 737 - loss 8.737381935119629 - moving ave loss 9.552062739786185\n",
            "Finish 79 epoch(es)\n",
            "step 738 - loss 8.561678886413574 - moving ave loss 9.453024354448925\n",
            "Finish 80 epoch(es)\n",
            "step 739 - loss 8.89266300201416 - moving ave loss 9.396988219205449\n",
            "Finish 81 epoch(es)\n",
            "step 740 - loss 10.125011444091797 - moving ave loss 9.469790541694085\n",
            "Finish 82 epoch(es)\n",
            "step 741 - loss 9.15522575378418 - moving ave loss 9.438334062903095\n",
            "Finish 83 epoch(es)\n",
            "step 742 - loss 9.597694396972656 - moving ave loss 9.45427009631005\n",
            "Finish 84 epoch(es)\n",
            "step 743 - loss 10.37334156036377 - moving ave loss 9.546177242715423\n",
            "Finish 85 epoch(es)\n",
            "step 744 - loss 7.5886549949646 - moving ave loss 9.350425017940342\n",
            "Finish 86 epoch(es)\n",
            "step 745 - loss 9.676796913146973 - moving ave loss 9.383062207461005\n",
            "Finish 87 epoch(es)\n",
            "step 746 - loss 7.375450134277344 - moving ave loss 9.18230100014264\n",
            "Finish 88 epoch(es)\n",
            "step 747 - loss 10.638197898864746 - moving ave loss 9.327890690014852\n",
            "Finish 89 epoch(es)\n",
            "step 748 - loss 8.733367919921875 - moving ave loss 9.268438413005555\n",
            "Finish 90 epoch(es)\n",
            "step 749 - loss 8.532666206359863 - moving ave loss 9.194861192340987\n",
            "Finish 91 epoch(es)\n",
            "step 750 - loss 9.585521697998047 - moving ave loss 9.233927242906693\n",
            "Finish 92 epoch(es)\n",
            "step 751 - loss 7.660994052886963 - moving ave loss 9.07663392390472\n",
            "Finish 93 epoch(es)\n",
            "step 752 - loss 8.266457557678223 - moving ave loss 8.99561628728207\n",
            "Finish 94 epoch(es)\n",
            "step 753 - loss 8.312580108642578 - moving ave loss 8.92731266941812\n",
            "Finish 95 epoch(es)\n",
            "step 754 - loss 10.42552661895752 - moving ave loss 9.077134064372059\n",
            "Finish 96 epoch(es)\n",
            "step 755 - loss 8.103883743286133 - moving ave loss 8.979809032263468\n",
            "Finish 97 epoch(es)\n",
            "step 756 - loss 7.634574890136719 - moving ave loss 8.845285618050793\n",
            "Finish 98 epoch(es)\n",
            "step 757 - loss 9.97443962097168 - moving ave loss 8.958201018342882\n",
            "Finish 99 epoch(es)\n",
            "step 758 - loss 9.179421424865723 - moving ave loss 8.980323058995166\n",
            "Finish 100 epoch(es)\n",
            "step 759 - loss 9.952407836914062 - moving ave loss 9.077531536787056\n",
            "Finish 101 epoch(es)\n",
            "step 760 - loss 8.750885009765625 - moving ave loss 9.044866884084914\n",
            "Finish 102 epoch(es)\n",
            "step 761 - loss 7.116615295410156 - moving ave loss 8.852041725217438\n",
            "Finish 103 epoch(es)\n",
            "step 762 - loss 10.18095874786377 - moving ave loss 8.984933427482071\n",
            "Finish 104 epoch(es)\n",
            "step 763 - loss 9.019277572631836 - moving ave loss 8.988367841997048\n",
            "Finish 105 epoch(es)\n",
            "step 764 - loss 9.246689796447754 - moving ave loss 9.014200037442118\n",
            "Finish 106 epoch(es)\n",
            "step 765 - loss 7.450933933258057 - moving ave loss 8.857873427023712\n",
            "Finish 107 epoch(es)\n",
            "step 766 - loss 7.7775726318359375 - moving ave loss 8.749843347504935\n",
            "Finish 108 epoch(es)\n",
            "step 767 - loss 7.374790191650391 - moving ave loss 8.612338031919482\n",
            "Finish 109 epoch(es)\n",
            "step 768 - loss 9.65507698059082 - moving ave loss 8.716611926786616\n",
            "Finish 110 epoch(es)\n",
            "step 769 - loss 8.87547492980957 - moving ave loss 8.73249822708891\n",
            "Finish 111 epoch(es)\n",
            "step 770 - loss 10.088850021362305 - moving ave loss 8.86813340651625\n",
            "Finish 112 epoch(es)\n",
            "step 771 - loss 8.556161880493164 - moving ave loss 8.836936253913942\n",
            "Finish 113 epoch(es)\n",
            "step 772 - loss 8.688176155090332 - moving ave loss 8.822060244031581\n",
            "Finish 114 epoch(es)\n",
            "step 773 - loss 10.266035079956055 - moving ave loss 8.966457727624029\n",
            "Finish 115 epoch(es)\n",
            "step 774 - loss 9.483654975891113 - moving ave loss 9.018177452450738\n",
            "Finish 116 epoch(es)\n",
            "step 775 - loss 8.744304656982422 - moving ave loss 8.990790172903907\n",
            "Finish 117 epoch(es)\n",
            "step 776 - loss 12.022871017456055 - moving ave loss 9.293998257359123\n",
            "Finish 118 epoch(es)\n",
            "step 777 - loss 8.38701343536377 - moving ave loss 9.203299775159588\n",
            "Finish 119 epoch(es)\n",
            "step 778 - loss 10.3735933303833 - moving ave loss 9.320329130681959\n",
            "Finish 120 epoch(es)\n",
            "step 779 - loss 10.3964204788208 - moving ave loss 9.427938265495843\n",
            "Finish 121 epoch(es)\n",
            "step 780 - loss 7.562081813812256 - moving ave loss 9.241352620327485\n",
            "Finish 122 epoch(es)\n",
            "step 781 - loss 9.796606063842773 - moving ave loss 9.296877964679013\n",
            "Finish 123 epoch(es)\n",
            "step 782 - loss 8.869817733764648 - moving ave loss 9.254171941587577\n",
            "Finish 124 epoch(es)\n",
            "step 783 - loss 11.313570022583008 - moving ave loss 9.46011174968712\n",
            "Finish 125 epoch(es)\n",
            "step 784 - loss 11.174201965332031 - moving ave loss 9.631520771251612\n",
            "Finish 126 epoch(es)\n",
            "step 785 - loss 8.360605239868164 - moving ave loss 9.504429218113268\n",
            "Finish 127 epoch(es)\n",
            "step 786 - loss 8.309798240661621 - moving ave loss 9.384966120368103\n",
            "Finish 128 epoch(es)\n",
            "step 787 - loss 9.80051326751709 - moving ave loss 9.426520835083004\n",
            "Finish 129 epoch(es)\n",
            "step 788 - loss 9.215761184692383 - moving ave loss 9.405444870043942\n",
            "Finish 130 epoch(es)\n",
            "step 789 - loss 7.54341459274292 - moving ave loss 9.21924184231384\n",
            "Finish 131 epoch(es)\n",
            "step 790 - loss 9.308492660522461 - moving ave loss 9.228166924134701\n",
            "Finish 132 epoch(es)\n",
            "step 791 - loss 9.55888557434082 - moving ave loss 9.261238789155314\n",
            "Finish 133 epoch(es)\n",
            "step 792 - loss 9.496370315551758 - moving ave loss 9.284751941794958\n",
            "Finish 134 epoch(es)\n",
            "step 793 - loss 8.941502571105957 - moving ave loss 9.250427004726058\n",
            "Finish 135 epoch(es)\n",
            "step 794 - loss 8.296022415161133 - moving ave loss 9.154986545769566\n",
            "Finish 136 epoch(es)\n",
            "step 795 - loss 8.923467636108398 - moving ave loss 9.13183465480345\n",
            "Finish 137 epoch(es)\n",
            "step 796 - loss 9.892547607421875 - moving ave loss 9.207905950065294\n",
            "Finish 138 epoch(es)\n",
            "step 797 - loss 7.992500305175781 - moving ave loss 9.086365385576343\n",
            "Finish 139 epoch(es)\n",
            "step 798 - loss 8.513172149658203 - moving ave loss 9.02904606198453\n",
            "Finish 140 epoch(es)\n",
            "step 799 - loss 7.27105712890625 - moving ave loss 8.853247168676702\n",
            "Finish 141 epoch(es)\n",
            "step 800 - loss 7.352329254150391 - moving ave loss 8.703155377224071\n",
            "Finish 142 epoch(es)\n",
            "step 801 - loss 10.00536823272705 - moving ave loss 8.83337666277437\n",
            "Finish 143 epoch(es)\n",
            "step 802 - loss 8.805943489074707 - moving ave loss 8.830633345404404\n",
            "Finish 144 epoch(es)\n",
            "step 803 - loss 7.6165852546691895 - moving ave loss 8.709228536330883\n",
            "Finish 145 epoch(es)\n",
            "step 804 - loss 6.9846510887146 - moving ave loss 8.536770791569255\n",
            "Finish 146 epoch(es)\n",
            "step 805 - loss 9.397929191589355 - moving ave loss 8.622886631571266\n",
            "Finish 147 epoch(es)\n",
            "step 806 - loss 9.73517894744873 - moving ave loss 8.734115863159012\n",
            "Finish 148 epoch(es)\n",
            "step 807 - loss 10.949918746948242 - moving ave loss 8.955696151537936\n",
            "Finish 149 epoch(es)\n",
            "step 808 - loss 8.133393287658691 - moving ave loss 8.873465865150012\n",
            "Finish 150 epoch(es)\n",
            "step 809 - loss 6.7982072830200195 - moving ave loss 8.665940006937012\n",
            "Finish 151 epoch(es)\n",
            "step 810 - loss 7.0222086906433105 - moving ave loss 8.501566875307642\n",
            "Finish 152 epoch(es)\n",
            "step 811 - loss 9.152199745178223 - moving ave loss 8.5666301622947\n",
            "Checkpoint at step 811\n",
            "Finish 153 epoch(es)\n",
            "step 812 - loss 7.684563636779785 - moving ave loss 8.478423509743209\n",
            "Finish 154 epoch(es)\n",
            "step 813 - loss 8.811199188232422 - moving ave loss 8.51170107759213\n",
            "Finish 155 epoch(es)\n",
            "step 814 - loss 7.614349365234375 - moving ave loss 8.421965906356355\n",
            "Finish 156 epoch(es)\n",
            "step 815 - loss 6.842801094055176 - moving ave loss 8.264049425126238\n",
            "Finish 157 epoch(es)\n",
            "step 816 - loss 8.48080062866211 - moving ave loss 8.285724545479825\n",
            "Finish 158 epoch(es)\n",
            "step 817 - loss 8.734004974365234 - moving ave loss 8.330552588368366\n",
            "Finish 159 epoch(es)\n",
            "step 818 - loss 9.916810989379883 - moving ave loss 8.489178428469518\n",
            "Finish 160 epoch(es)\n",
            "step 819 - loss 8.662408828735352 - moving ave loss 8.506501468496102\n",
            "Finish 161 epoch(es)\n",
            "step 820 - loss 9.876191139221191 - moving ave loss 8.643470435568611\n",
            "Finish 162 epoch(es)\n",
            "step 821 - loss 8.544830322265625 - moving ave loss 8.633606424238312\n",
            "Finish 163 epoch(es)\n",
            "step 822 - loss 6.245075702667236 - moving ave loss 8.394753352081205\n",
            "Finish 164 epoch(es)\n",
            "step 823 - loss 12.792452812194824 - moving ave loss 8.834523298092567\n",
            "Finish 165 epoch(es)\n",
            "step 824 - loss 9.886815071105957 - moving ave loss 8.939752475393906\n",
            "Finish 166 epoch(es)\n",
            "step 825 - loss 9.039589881896973 - moving ave loss 8.949736216044212\n",
            "Finish 167 epoch(es)\n",
            "step 826 - loss 9.77371883392334 - moving ave loss 9.032134477832123\n",
            "Finish 168 epoch(es)\n",
            "step 827 - loss 7.157622337341309 - moving ave loss 8.844683263783041\n",
            "Finish 169 epoch(es)\n",
            "step 828 - loss 8.124157905578613 - moving ave loss 8.772630727962598\n",
            "Finish 170 epoch(es)\n",
            "step 829 - loss 9.62403392791748 - moving ave loss 8.857771047958087\n",
            "Finish 171 epoch(es)\n",
            "step 830 - loss 8.552833557128906 - moving ave loss 8.827277298875169\n",
            "Finish 172 epoch(es)\n",
            "step 831 - loss 7.549986362457275 - moving ave loss 8.699548205233379\n",
            "Finish 173 epoch(es)\n",
            "step 832 - loss 6.816778182983398 - moving ave loss 8.51127120300838\n",
            "Finish 174 epoch(es)\n",
            "step 833 - loss 8.474109649658203 - moving ave loss 8.507555047673364\n",
            "Finish 175 epoch(es)\n",
            "step 834 - loss 8.255102157592773 - moving ave loss 8.482309758665306\n",
            "Finish 176 epoch(es)\n",
            "step 835 - loss 9.711872100830078 - moving ave loss 8.605265992881783\n",
            "Finish 177 epoch(es)\n",
            "step 836 - loss 8.6012544631958 - moving ave loss 8.604864839913185\n",
            "Finish 178 epoch(es)\n",
            "step 837 - loss 8.447724342346191 - moving ave loss 8.589150790156486\n",
            "Finish 179 epoch(es)\n",
            "step 838 - loss 7.595361232757568 - moving ave loss 8.489771834416594\n",
            "Finish 180 epoch(es)\n",
            "step 839 - loss 9.821619033813477 - moving ave loss 8.622956554356282\n",
            "Finish 181 epoch(es)\n",
            "step 840 - loss 6.507656574249268 - moving ave loss 8.411426556345582\n",
            "Finish 182 epoch(es)\n",
            "step 841 - loss 7.605863571166992 - moving ave loss 8.330870257827723\n",
            "Finish 183 epoch(es)\n",
            "step 842 - loss 11.537703514099121 - moving ave loss 8.651553583454863\n",
            "Finish 184 epoch(es)\n",
            "step 843 - loss 9.028939247131348 - moving ave loss 8.689292149822512\n",
            "Finish 185 epoch(es)\n",
            "step 844 - loss 8.71341609954834 - moving ave loss 8.691704544795094\n",
            "Finish 186 epoch(es)\n",
            "step 845 - loss 8.705491065979004 - moving ave loss 8.693083196913484\n",
            "Finish 187 epoch(es)\n",
            "step 846 - loss 8.286116600036621 - moving ave loss 8.652386537225798\n",
            "Finish 188 epoch(es)\n",
            "step 847 - loss 7.670166015625 - moving ave loss 8.554164485065717\n",
            "Finish 189 epoch(es)\n",
            "step 848 - loss 8.763690948486328 - moving ave loss 8.57511713140778\n",
            "Finish 190 epoch(es)\n",
            "step 849 - loss 7.926285743713379 - moving ave loss 8.510233992638339\n",
            "Finish 191 epoch(es)\n",
            "step 850 - loss 9.562747955322266 - moving ave loss 8.615485388906732\n",
            "Finish 192 epoch(es)\n",
            "step 851 - loss 8.270706176757812 - moving ave loss 8.58100746769184\n",
            "Finish 193 epoch(es)\n",
            "step 852 - loss 7.972773551940918 - moving ave loss 8.520184076116749\n",
            "Finish 194 epoch(es)\n",
            "step 853 - loss 9.708486557006836 - moving ave loss 8.639014324205759\n",
            "Finish 195 epoch(es)\n",
            "step 854 - loss 7.483371734619141 - moving ave loss 8.523450065247097\n",
            "Finish 196 epoch(es)\n",
            "step 855 - loss 7.927680492401123 - moving ave loss 8.4638731079625\n",
            "Finish 197 epoch(es)\n",
            "step 856 - loss 10.632370948791504 - moving ave loss 8.6807228920454\n",
            "Finish 198 epoch(es)\n",
            "step 857 - loss 10.447759628295898 - moving ave loss 8.857426565670451\n",
            "Finish 199 epoch(es)\n",
            "step 858 - loss 7.910333633422852 - moving ave loss 8.762717272445691\n",
            "Finish 200 epoch(es)\n",
            "step 859 - loss 7.72812032699585 - moving ave loss 8.659257577900707\n",
            "Finish 201 epoch(es)\n",
            "step 860 - loss 10.383058547973633 - moving ave loss 8.831637674908\n",
            "Finish 202 epoch(es)\n",
            "step 861 - loss 8.887688636779785 - moving ave loss 8.837242771095179\n",
            "Finish 203 epoch(es)\n",
            "step 862 - loss 10.145870208740234 - moving ave loss 8.968105514859685\n",
            "Finish 204 epoch(es)\n",
            "step 863 - loss 6.167403697967529 - moving ave loss 8.68803533317047\n",
            "Finish 205 epoch(es)\n",
            "step 864 - loss 10.164770126342773 - moving ave loss 8.8357088124877\n",
            "Finish 206 epoch(es)\n",
            "step 865 - loss 9.484514236450195 - moving ave loss 8.90058935488395\n",
            "Finish 207 epoch(es)\n",
            "step 866 - loss 8.06468677520752 - moving ave loss 8.816999096916307\n",
            "Finish 208 epoch(es)\n",
            "step 867 - loss 5.8699049949646 - moving ave loss 8.522289686721136\n",
            "Finish 209 epoch(es)\n",
            "step 868 - loss 8.402031898498535 - moving ave loss 8.510263907898876\n",
            "Finish 210 epoch(es)\n",
            "step 869 - loss 8.012893676757812 - moving ave loss 8.46052688478477\n",
            "Finish 211 epoch(es)\n",
            "step 870 - loss 9.660160064697266 - moving ave loss 8.58049020277602\n",
            "Finish 212 epoch(es)\n",
            "step 871 - loss 6.275027275085449 - moving ave loss 8.349943910006962\n",
            "Finish 213 epoch(es)\n",
            "step 872 - loss 9.330155372619629 - moving ave loss 8.44796505626823\n",
            "Finish 214 epoch(es)\n",
            "step 873 - loss 8.275705337524414 - moving ave loss 8.430739084393847\n",
            "Finish 215 epoch(es)\n",
            "step 874 - loss 8.250598907470703 - moving ave loss 8.412725066701533\n",
            "Finish 216 epoch(es)\n",
            "step 875 - loss 7.090282440185547 - moving ave loss 8.280480804049935\n",
            "Finish 217 epoch(es)\n",
            "step 876 - loss 5.236371040344238 - moving ave loss 7.976069827679365\n",
            "Finish 218 epoch(es)\n",
            "step 877 - loss 7.662859916687012 - moving ave loss 7.94474883658013\n",
            "Finish 219 epoch(es)\n",
            "step 878 - loss 9.492263793945312 - moving ave loss 8.099500332316648\n",
            "Finish 220 epoch(es)\n",
            "step 879 - loss 6.621760368347168 - moving ave loss 7.951726335919701\n",
            "Finish 221 epoch(es)\n",
            "step 880 - loss 7.261327266693115 - moving ave loss 7.882686428997042\n",
            "Finish 222 epoch(es)\n",
            "step 881 - loss 8.984025001525879 - moving ave loss 7.992820286249926\n",
            "Finish 223 epoch(es)\n",
            "step 882 - loss 8.39437198638916 - moving ave loss 8.032975456263848\n",
            "Finish 224 epoch(es)\n",
            "step 883 - loss 9.522760391235352 - moving ave loss 8.181953949760999\n",
            "Finish 225 epoch(es)\n",
            "step 884 - loss 9.589184761047363 - moving ave loss 8.322677030889635\n",
            "Finish 226 epoch(es)\n",
            "step 885 - loss 8.7452392578125 - moving ave loss 8.364933253581922\n",
            "Finish 227 epoch(es)\n",
            "step 886 - loss 8.638171195983887 - moving ave loss 8.392257047822119\n",
            "Finish 228 epoch(es)\n",
            "step 887 - loss 6.860743522644043 - moving ave loss 8.23910569530431\n",
            "Finish 229 epoch(es)\n",
            "step 888 - loss 9.332376480102539 - moving ave loss 8.348432773784134\n",
            "Finish 230 epoch(es)\n",
            "step 889 - loss 8.31870174407959 - moving ave loss 8.34545967081368\n",
            "Finish 231 epoch(es)\n",
            "step 890 - loss 8.449042320251465 - moving ave loss 8.35581793575746\n",
            "Finish 232 epoch(es)\n",
            "step 891 - loss 7.46798849105835 - moving ave loss 8.267034991287549\n",
            "Finish 233 epoch(es)\n",
            "step 892 - loss 8.926787376403809 - moving ave loss 8.333010229799175\n",
            "Finish 234 epoch(es)\n",
            "step 893 - loss 8.08877182006836 - moving ave loss 8.308586388826093\n",
            "Finish 235 epoch(es)\n",
            "step 894 - loss 8.152774810791016 - moving ave loss 8.293005231022585\n",
            "Finish 236 epoch(es)\n",
            "step 895 - loss 7.450315952301025 - moving ave loss 8.20873630315043\n",
            "Finish 237 epoch(es)\n",
            "step 896 - loss 5.894473552703857 - moving ave loss 7.977310028105772\n",
            "Finish 238 epoch(es)\n",
            "step 897 - loss 6.1233906745910645 - moving ave loss 7.791918092754301\n",
            "Finish 239 epoch(es)\n",
            "step 898 - loss 7.928684234619141 - moving ave loss 7.805594706940785\n",
            "Finish 240 epoch(es)\n",
            "step 899 - loss 8.218194007873535 - moving ave loss 7.84685463703406\n",
            "Finish 241 epoch(es)\n",
            "step 900 - loss 5.165923595428467 - moving ave loss 7.5787615328735\n",
            "Finish 242 epoch(es)\n",
            "step 901 - loss 6.898316860198975 - moving ave loss 7.510717065606048\n",
            "Finish 243 epoch(es)\n",
            "step 902 - loss 8.982518196105957 - moving ave loss 7.6578971786560395\n",
            "Finish 244 epoch(es)\n",
            "step 903 - loss 6.115848064422607 - moving ave loss 7.5036922672326964\n",
            "Finish 245 epoch(es)\n",
            "step 904 - loss 7.2262396812438965 - moving ave loss 7.475947008633817\n",
            "Finish 246 epoch(es)\n",
            "step 905 - loss 6.311607837677002 - moving ave loss 7.359513091538135\n",
            "Finish 247 epoch(es)\n",
            "step 906 - loss 7.55440616607666 - moving ave loss 7.379002398991988\n",
            "Finish 248 epoch(es)\n",
            "step 907 - loss 9.352187156677246 - moving ave loss 7.576320874760514\n",
            "Finish 249 epoch(es)\n",
            "step 908 - loss 7.135374069213867 - moving ave loss 7.532226194205849\n",
            "Finish 250 epoch(es)\n",
            "step 909 - loss 9.307880401611328 - moving ave loss 7.709791614946397\n",
            "Finish 251 epoch(es)\n",
            "step 910 - loss 7.123280048370361 - moving ave loss 7.651140458288793\n",
            "Finish 252 epoch(es)\n",
            "step 911 - loss 7.288072109222412 - moving ave loss 7.614833623382156\n",
            "Finish 253 epoch(es)\n",
            "step 912 - loss 7.486819744110107 - moving ave loss 7.602032235454951\n",
            "Finish 254 epoch(es)\n",
            "step 913 - loss 7.1115193367004395 - moving ave loss 7.552980945579501\n",
            "Finish 255 epoch(es)\n",
            "step 914 - loss 6.645700454711914 - moving ave loss 7.462252896492743\n",
            "Finish 256 epoch(es)\n",
            "step 915 - loss 7.775029182434082 - moving ave loss 7.493530525086877\n",
            "Finish 257 epoch(es)\n",
            "step 916 - loss 6.246524333953857 - moving ave loss 7.368829905973575\n",
            "Finish 258 epoch(es)\n",
            "step 917 - loss 8.050378799438477 - moving ave loss 7.436984795320066\n",
            "Finish 259 epoch(es)\n",
            "step 918 - loss 7.274227142333984 - moving ave loss 7.420709030021458\n",
            "Finish 260 epoch(es)\n",
            "step 919 - loss 5.441520690917969 - moving ave loss 7.2227901961111085\n",
            "Finish 261 epoch(es)\n",
            "step 920 - loss 6.849444389343262 - moving ave loss 7.185455615434324\n",
            "Finish 262 epoch(es)\n",
            "step 921 - loss 7.416161060333252 - moving ave loss 7.208526159924217\n",
            "Finish 263 epoch(es)\n",
            "step 922 - loss 6.823892593383789 - moving ave loss 7.1700628032701745\n",
            "Finish 264 epoch(es)\n",
            "step 923 - loss 6.134877681732178 - moving ave loss 7.066544291116375\n",
            "Finish 265 epoch(es)\n",
            "step 924 - loss 6.234297275543213 - moving ave loss 6.983319589559059\n",
            "Finish 266 epoch(es)\n",
            "step 925 - loss 7.534900188446045 - moving ave loss 7.038477649447758\n",
            "Finish 267 epoch(es)\n",
            "step 926 - loss 7.774400234222412 - moving ave loss 7.112069907925224\n",
            "Finish 268 epoch(es)\n",
            "step 927 - loss 5.9453277587890625 - moving ave loss 6.9953956930116075\n",
            "Finish 269 epoch(es)\n",
            "step 928 - loss 8.333342552185059 - moving ave loss 7.129190378928953\n",
            "Finish 270 epoch(es)\n",
            "step 929 - loss 7.713493347167969 - moving ave loss 7.1876206757528545\n",
            "Finish 271 epoch(es)\n",
            "step 930 - loss 8.95069694519043 - moving ave loss 7.363928302696612\n",
            "Finish 272 epoch(es)\n",
            "step 931 - loss 5.803439140319824 - moving ave loss 7.2078793864589334\n",
            "Finish 273 epoch(es)\n",
            "step 932 - loss 6.820981025695801 - moving ave loss 7.169189550382621\n",
            "Finish 274 epoch(es)\n",
            "step 933 - loss 8.32799243927002 - moving ave loss 7.285069839271361\n",
            "Finish 275 epoch(es)\n",
            "step 934 - loss 8.94713306427002 - moving ave loss 7.4512761617712275\n",
            "Finish 276 epoch(es)\n",
            "step 935 - loss 5.4731526374816895 - moving ave loss 7.253463809342274\n",
            "Finish 277 epoch(es)\n",
            "step 936 - loss 11.073759078979492 - moving ave loss 7.635493336305996\n",
            "Finish 278 epoch(es)\n",
            "step 937 - loss 8.555028915405273 - moving ave loss 7.727446894215923\n",
            "Finish 279 epoch(es)\n",
            "step 938 - loss 7.933996200561523 - moving ave loss 7.748101824850483\n",
            "Finish 280 epoch(es)\n",
            "step 939 - loss 7.176673889160156 - moving ave loss 7.690959031281451\n",
            "Finish 281 epoch(es)\n",
            "step 940 - loss 5.566914081573486 - moving ave loss 7.4785545363106545\n",
            "Finish 282 epoch(es)\n",
            "step 941 - loss 8.48164176940918 - moving ave loss 7.5788632596205066\n",
            "Finish 283 epoch(es)\n",
            "step 942 - loss 7.166581153869629 - moving ave loss 7.537635049045419\n",
            "Finish 284 epoch(es)\n",
            "step 943 - loss 7.225091934204102 - moving ave loss 7.506380737561288\n",
            "Finish 285 epoch(es)\n",
            "step 944 - loss 6.054122447967529 - moving ave loss 7.361154908601912\n",
            "Finish 286 epoch(es)\n",
            "step 945 - loss 8.643770217895508 - moving ave loss 7.489416439531271\n",
            "Finish 287 epoch(es)\n",
            "step 946 - loss 6.387520790100098 - moving ave loss 7.379226874588154\n",
            "Finish 288 epoch(es)\n",
            "step 947 - loss 7.872854709625244 - moving ave loss 7.428589658091863\n",
            "Finish 289 epoch(es)\n",
            "step 948 - loss 8.576285362243652 - moving ave loss 7.543359228507042\n",
            "Finish 290 epoch(es)\n",
            "step 949 - loss 7.98427152633667 - moving ave loss 7.587450458290005\n",
            "Finish 291 epoch(es)\n",
            "step 950 - loss 8.144867897033691 - moving ave loss 7.643192202164373\n",
            "Finish 292 epoch(es)\n",
            "step 951 - loss 7.46972131729126 - moving ave loss 7.6258451136770615\n",
            "Finish 293 epoch(es)\n",
            "step 952 - loss 7.049566268920898 - moving ave loss 7.568217229201446\n",
            "Finish 294 epoch(es)\n",
            "step 953 - loss 7.7898993492126465 - moving ave loss 7.590385441202566\n",
            "Finish 295 epoch(es)\n",
            "step 954 - loss 9.24251937866211 - moving ave loss 7.755598834948521\n",
            "Finish 296 epoch(es)\n",
            "step 955 - loss 7.612300395965576 - moving ave loss 7.741268991050227\n",
            "Finish 297 epoch(es)\n",
            "step 956 - loss 7.01771879196167 - moving ave loss 7.668913971141372\n",
            "Finish 298 epoch(es)\n",
            "step 957 - loss 8.489825248718262 - moving ave loss 7.751005098899061\n",
            "Finish 299 epoch(es)\n",
            "step 958 - loss 7.049783229827881 - moving ave loss 7.680882911991944\n",
            "Finish 300 epoch(es)\n",
            "step 959 - loss 10.610565185546875 - moving ave loss 7.973851139347437\n",
            "Finish 301 epoch(es)\n",
            "step 960 - loss 8.372052192687988 - moving ave loss 8.013671244681493\n",
            "Finish 302 epoch(es)\n",
            "step 961 - loss 6.80874490737915 - moving ave loss 7.893178610951259\n",
            "Finish 303 epoch(es)\n",
            "step 962 - loss 7.978087425231934 - moving ave loss 7.901669492379327\n",
            "Finish 304 epoch(es)\n",
            "step 963 - loss 7.536867618560791 - moving ave loss 7.8651893049974735\n",
            "Finish 305 epoch(es)\n",
            "step 964 - loss 8.28824234008789 - moving ave loss 7.907494608506515\n",
            "Checkpoint at step 964\n",
            "Finish 306 epoch(es)\n",
            "step 965 - loss 8.353551864624023 - moving ave loss 7.952100334118266\n",
            "Finish 307 epoch(es)\n",
            "step 966 - loss 7.78790807723999 - moving ave loss 7.935681108430439\n",
            "Finish 308 epoch(es)\n",
            "step 967 - loss 7.618229389190674 - moving ave loss 7.903935936506462\n",
            "Finish 309 epoch(es)\n",
            "step 968 - loss 9.62640380859375 - moving ave loss 8.076182723715192\n",
            "Finish 310 epoch(es)\n",
            "step 969 - loss 7.772832870483398 - moving ave loss 8.045847738392013\n",
            "Finish 311 epoch(es)\n",
            "step 970 - loss 7.565807342529297 - moving ave loss 7.997843698805742\n",
            "Finish 312 epoch(es)\n",
            "step 971 - loss 8.712857246398926 - moving ave loss 8.06934505356506\n",
            "Finish 313 epoch(es)\n",
            "step 972 - loss 6.5671000480651855 - moving ave loss 7.919120553015073\n",
            "Finish 314 epoch(es)\n",
            "step 973 - loss 9.639596939086914 - moving ave loss 8.091168191622257\n",
            "Finish 315 epoch(es)\n",
            "step 974 - loss 10.199240684509277 - moving ave loss 8.30197544091096\n",
            "Finish 316 epoch(es)\n",
            "step 975 - loss 9.306121826171875 - moving ave loss 8.402390079437051\n",
            "Finish 317 epoch(es)\n",
            "step 976 - loss 6.914440155029297 - moving ave loss 8.253595086996276\n",
            "Finish 318 epoch(es)\n",
            "step 977 - loss 7.6659255027771 - moving ave loss 8.19482812857436\n",
            "Finish 319 epoch(es)\n",
            "step 978 - loss 8.526094436645508 - moving ave loss 8.227954759381475\n",
            "Finish 320 epoch(es)\n",
            "step 979 - loss 6.717550754547119 - moving ave loss 8.07691435889804\n",
            "Finish 321 epoch(es)\n",
            "step 980 - loss 9.079140663146973 - moving ave loss 8.177136989322934\n",
            "Finish 322 epoch(es)\n",
            "step 981 - loss 6.758160591125488 - moving ave loss 8.03523934950319\n",
            "Finish 323 epoch(es)\n",
            "step 982 - loss 8.432412147521973 - moving ave loss 8.074956629305067\n",
            "Finish 324 epoch(es)\n",
            "step 983 - loss 7.145854949951172 - moving ave loss 7.982046461369678\n",
            "Finish 325 epoch(es)\n",
            "step 984 - loss 8.458511352539062 - moving ave loss 8.029692950486616\n",
            "Finish 326 epoch(es)\n",
            "step 985 - loss 8.417076110839844 - moving ave loss 8.068431266521939\n",
            "Finish 327 epoch(es)\n",
            "step 986 - loss 8.101795196533203 - moving ave loss 8.071767659523067\n",
            "Finish 328 epoch(es)\n",
            "step 987 - loss 7.709197998046875 - moving ave loss 8.035510693375448\n",
            "Finish 329 epoch(es)\n",
            "step 988 - loss 8.705748558044434 - moving ave loss 8.102534479842348\n",
            "Finish 330 epoch(es)\n",
            "step 989 - loss 7.221518039703369 - moving ave loss 8.01443283582845\n",
            "Finish 331 epoch(es)\n",
            "step 990 - loss 9.089950561523438 - moving ave loss 8.121984608397948\n",
            "Finish 332 epoch(es)\n",
            "step 991 - loss 9.678651809692383 - moving ave loss 8.277651328527392\n",
            "Finish 333 epoch(es)\n",
            "step 992 - loss 7.874451160430908 - moving ave loss 8.237331311717744\n",
            "Finish 334 epoch(es)\n",
            "step 993 - loss 8.370316505432129 - moving ave loss 8.250629831089183\n",
            "Finish 335 epoch(es)\n",
            "step 994 - loss 6.823194980621338 - moving ave loss 8.107886346042399\n",
            "Finish 336 epoch(es)\n",
            "step 995 - loss 5.645323753356934 - moving ave loss 7.861630086773852\n",
            "Finish 337 epoch(es)\n",
            "step 996 - loss 7.860325813293457 - moving ave loss 7.861499659425813\n",
            "Finish 338 epoch(es)\n",
            "step 997 - loss 10.306192398071289 - moving ave loss 8.105968933290361\n",
            "Finish 339 epoch(es)\n",
            "step 998 - loss 10.269774436950684 - moving ave loss 8.322349483656394\n",
            "Finish 340 epoch(es)\n",
            "step 999 - loss 7.757591247558594 - moving ave loss 8.265873660046614\n",
            "Finish 341 epoch(es)\n",
            "step 1000 - loss 8.955769538879395 - moving ave loss 8.334863247929892\n",
            "Finish 342 epoch(es)\n",
            "step 1001 - loss 6.453115940093994 - moving ave loss 8.146688517146302\n",
            "Finish 343 epoch(es)\n",
            "step 1002 - loss 8.509462356567383 - moving ave loss 8.18296590108841\n",
            "Finish 344 epoch(es)\n",
            "step 1003 - loss 8.211289405822754 - moving ave loss 8.185798251561845\n",
            "Finish 345 epoch(es)\n",
            "step 1004 - loss 6.225676536560059 - moving ave loss 7.989786080061667\n",
            "Finish 346 epoch(es)\n",
            "step 1005 - loss 9.538996696472168 - moving ave loss 8.144707141702717\n",
            "Finish 347 epoch(es)\n",
            "step 1006 - loss 7.028197765350342 - moving ave loss 8.03305620406748\n",
            "Finish 348 epoch(es)\n",
            "step 1007 - loss 6.907129287719727 - moving ave loss 7.920463512432704\n",
            "Finish 349 epoch(es)\n",
            "step 1008 - loss 8.224464416503906 - moving ave loss 7.950863602839824\n",
            "Finish 350 epoch(es)\n",
            "step 1009 - loss 7.684504508972168 - moving ave loss 7.924227693453059\n",
            "Finish 351 epoch(es)\n",
            "step 1010 - loss 6.273322582244873 - moving ave loss 7.75913718233224\n",
            "Finish 352 epoch(es)\n",
            "step 1011 - loss 6.1357269287109375 - moving ave loss 7.596796156970109\n",
            "Finish 353 epoch(es)\n",
            "step 1012 - loss 6.960581302642822 - moving ave loss 7.533174671537381\n",
            "Finish 354 epoch(es)\n",
            "step 1013 - loss 6.689024925231934 - moving ave loss 7.448759696906837\n",
            "Finish 355 epoch(es)\n",
            "step 1014 - loss 7.303117275238037 - moving ave loss 7.434195454739957\n",
            "Finish 356 epoch(es)\n",
            "step 1015 - loss 7.7260212898254395 - moving ave loss 7.463378038248505\n",
            "Finish 357 epoch(es)\n",
            "step 1016 - loss 6.641851425170898 - moving ave loss 7.381225376940744\n",
            "Finish 358 epoch(es)\n",
            "step 1017 - loss 6.197625160217285 - moving ave loss 7.262865355268399\n",
            "Finish 359 epoch(es)\n",
            "step 1018 - loss 7.423820495605469 - moving ave loss 7.278960869302106\n",
            "Finish 360 epoch(es)\n",
            "step 1019 - loss 8.113407135009766 - moving ave loss 7.362405495872872\n",
            "Finish 361 epoch(es)\n",
            "step 1020 - loss 6.744525909423828 - moving ave loss 7.300617537227968\n",
            "Finish 362 epoch(es)\n",
            "step 1021 - loss 6.786523342132568 - moving ave loss 7.249208117718428\n",
            "Finish 363 epoch(es)\n",
            "step 1022 - loss 7.227147102355957 - moving ave loss 7.247002016182181\n",
            "Finish 364 epoch(es)\n",
            "step 1023 - loss 7.165544033050537 - moving ave loss 7.238856217869017\n",
            "Finish 365 epoch(es)\n",
            "step 1024 - loss 6.858190536499023 - moving ave loss 7.200789649732019\n",
            "Finish 366 epoch(es)\n",
            "step 1025 - loss 8.56721019744873 - moving ave loss 7.33743170450369\n",
            "Finish 367 epoch(es)\n",
            "step 1026 - loss 7.778203010559082 - moving ave loss 7.381508835109229\n",
            "Finish 368 epoch(es)\n",
            "step 1027 - loss 8.03132152557373 - moving ave loss 7.446490104155679\n",
            "Finish 369 epoch(es)\n",
            "step 1028 - loss 8.199638366699219 - moving ave loss 7.521804930410033\n",
            "Finish 370 epoch(es)\n",
            "step 1029 - loss 8.281938552856445 - moving ave loss 7.597818292654675\n",
            "Finish 371 epoch(es)\n",
            "step 1030 - loss 5.935920715332031 - moving ave loss 7.431628534922411\n",
            "Finish 372 epoch(es)\n",
            "step 1031 - loss 7.745116710662842 - moving ave loss 7.462977352496454\n",
            "Finish 373 epoch(es)\n",
            "step 1032 - loss 8.846015930175781 - moving ave loss 7.6012812102643865\n",
            "Finish 374 epoch(es)\n",
            "step 1033 - loss 6.402897834777832 - moving ave loss 7.481442872715731\n",
            "Finish 375 epoch(es)\n",
            "step 1034 - loss 6.196671962738037 - moving ave loss 7.352965781717963\n",
            "Finish 376 epoch(es)\n",
            "step 1035 - loss 7.598596572875977 - moving ave loss 7.377528860833765\n",
            "Finish 377 epoch(es)\n",
            "step 1036 - loss 9.26938533782959 - moving ave loss 7.566714508533348\n",
            "Finish 378 epoch(es)\n",
            "step 1037 - loss 10.08568000793457 - moving ave loss 7.81861105847347\n",
            "Finish 379 epoch(es)\n",
            "step 1038 - loss 6.5537896156311035 - moving ave loss 7.692128914189234\n",
            "Finish 380 epoch(es)\n",
            "step 1039 - loss 9.654167175292969 - moving ave loss 7.8883327402996075\n",
            "Finish 381 epoch(es)\n",
            "step 1040 - loss 6.800055980682373 - moving ave loss 7.779505064337884\n",
            "Finish 382 epoch(es)\n",
            "step 1041 - loss 7.043252468109131 - moving ave loss 7.705879804715009\n",
            "Finish 383 epoch(es)\n",
            "step 1042 - loss 5.862308025360107 - moving ave loss 7.521522626779519\n",
            "Finish 384 epoch(es)\n",
            "step 1043 - loss 9.389619827270508 - moving ave loss 7.708332346828618\n",
            "Finish 385 epoch(es)\n",
            "step 1044 - loss 7.68187952041626 - moving ave loss 7.705687064187383\n",
            "Finish 386 epoch(es)\n",
            "step 1045 - loss 6.248321056365967 - moving ave loss 7.559950463405241\n",
            "Finish 387 epoch(es)\n",
            "step 1046 - loss 8.459132194519043 - moving ave loss 7.649868636516621\n",
            "Finish 388 epoch(es)\n",
            "step 1047 - loss 7.370566368103027 - moving ave loss 7.621938409675263\n",
            "Finish 389 epoch(es)\n",
            "step 1048 - loss 7.076715469360352 - moving ave loss 7.5674161156437725\n",
            "Finish 390 epoch(es)\n",
            "step 1049 - loss 8.009774208068848 - moving ave loss 7.611651924886281\n",
            "Finish 391 epoch(es)\n",
            "step 1050 - loss 8.154948234558105 - moving ave loss 7.665981555853463\n",
            "Finish 392 epoch(es)\n",
            "step 1051 - loss 6.8506083488464355 - moving ave loss 7.584444235152761\n",
            "Finish 393 epoch(es)\n",
            "step 1052 - loss 6.522118091583252 - moving ave loss 7.47821162079581\n",
            "Finish 394 epoch(es)\n",
            "step 1053 - loss 8.525818824768066 - moving ave loss 7.582972341193036\n",
            "Finish 395 epoch(es)\n",
            "step 1054 - loss 6.684423446655273 - moving ave loss 7.493117451739261\n",
            "Finish 396 epoch(es)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/flow\", line 7, in <module>\n",
            "    exec(compile(f.read(), __file__, 'exec'))\n",
            "  File \"/content/drive/My Drive/darkflow/flow\", line 6, in <module>\n",
            "    cliHandler(sys.argv)\n",
            "  File \"/content/drive/My Drive/darkflow/darkflow/cli.py\", line 33, in cliHandler\n",
            "    print('Enter training ...'); tfnet.train()\n",
            "  File \"/content/drive/My Drive/darkflow/darkflow/net/flow.py\", line 39, in train\n",
            "    for i, (x_batch, datum) in enumerate(batches):\n",
            "  File \"/content/drive/My Drive/darkflow/darkflow/net/yolo/data.py\", line 114, in shuffle\n",
            "    inp, new_feed = self._batch(train_instance)\n",
            "  File \"/content/drive/My Drive/darkflow/darkflow/net/yolov2/data.py\", line 27, in _batch\n",
            "    img = self.preprocess(path, allobj)\n",
            "  File \"/content/drive/My Drive/darkflow/darkflow/net/yolo/predict.py\", line 62, in preprocess\n",
            "^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "siy7S98Rtn74",
        "outputId": "13fd7e68-8e11-45fc-ec13-49c7e051283e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1108
        }
      },
      "source": [
        "!flow --imgdir SelectiveBDD/ --model cfg/yolorick.cfg --load 658\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Parsing cfg/yolorick.cfg\n",
            "Loading None ...\n",
            "Finished in 0.0001685619354248047s\n",
            "\n",
            "Building net ...\n",
            "Source | Train? | Layer description                | Output size\n",
            "-------+--------+----------------------------------+---------------\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "       |        | input                            | (?, 416, 416, 3)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 416, 416, 32)\n",
            " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 208, 208, 32)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 208, 208, 64)\n",
            " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 104, 104, 64)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 104, 104, 128)\n",
            " Init  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 104, 104, 64)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 104, 104, 128)\n",
            " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 52, 52, 128)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 52, 52, 256)\n",
            " Init  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 52, 52, 128)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 52, 52, 256)\n",
            " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 26, 26, 256)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 26, 26, 512)\n",
            " Init  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 26, 26, 256)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 26, 26, 512)\n",
            " Init  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 26, 26, 256)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 26, 26, 512)\n",
            " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 13, 13, 512)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 13, 13, 1024)\n",
            " Init  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 13, 13, 512)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 13, 13, 1024)\n",
            " Init  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 13, 13, 512)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 13, 13, 1024)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 13, 13, 1024)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 13, 13, 1024)\n",
            " Load  |  Yep!  | concat [16]                      | (?, 26, 26, 512)\n",
            " Init  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 26, 26, 64)\n",
            " Load  |  Yep!  | local flatten 2x2                | (?, 13, 13, 256)\n",
            " Load  |  Yep!  | concat [27, 24]                  | (?, 13, 13, 1280)\n",
            " Init  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 13, 13, 1024)\n",
            " Init  |  Yep!  | conv 1x1p0_1    linear           | (?, 13, 13, 80)\n",
            "-------+--------+----------------------------------+---------------\n",
            "Running entirely on CPU\n",
            "2019-05-14 07:19:36.428153: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n",
            "2019-05-14 07:19:36.428447: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x36af5a0 executing computations on platform Host. Devices:\n",
            "2019-05-14 07:19:36.428483: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2019-05-14 07:19:36.601671: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-05-14 07:19:36.602263: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x36af2e0 executing computations on platform CUDA. Devices:\n",
            "2019-05-14 07:19:36.602318: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2019-05-14 07:19:36.602511: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-05-14 07:19:36.602531: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      \n",
            "Loading from ./ckpt/yolorick-658\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "Finished in 7.044406890869141s\n",
            "\n",
            "Forwarding 13 inputs ...\n",
            "Total time = 8.594692945480347s / 13 inps = 1.5125613075957824 ips\n",
            "Post processing 13 inputs ...\n",
            "Total time = 0.22308683395385742s / 13 inps = 58.273273099966445 ips\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "801JzQ8i-C9V"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}